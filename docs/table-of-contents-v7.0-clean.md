# LLM推理优化实战 - 目录（V2+V3融合版·简洁版）

**创建日期**：2025-01-27
**版本**：V2.0 + V3.0 融合版
**总字数目标**：约35,000字
**章节数**：10章 + 3个附录

---

## 第一部分：动机与路径篇

### 第1章 AI推理的文明级意义

#### 1.1 开篇震撼：50,000倍效率革命
- 1.1.1 "人类当量"概念
- 1.1.2 具体数字对比
- 1.1.3 推理 = 智能生产的核心

#### 1.2 为什么是现在：四重证据
- 1.2.1 历史证据：马尔萨斯式的简单公式
- 1.2.2 市场证据：训练$100B vs 推理$1.4T
- 1.2.3 需求证据：成本↓99% → 需求爆炸
- 1.2.4 经济学证据：打破150年GDP趋势的可能性

#### 1.3 真实案例：从理论到现实
- 1.3.1 Toast：100倍ROI的AI客服
- 1.3.2 DeepSeek：AI民主化的关键一步
- 1.3.3 虚拟劳动力：AI作为经济学引擎
- 1.3.4 这些案例说明什么

#### 1.4 技术可行：300倍效率提升已验证
- 1.4.1 历史证明：2018-2023效率飞跃
- 1.4.2 未来潜力：还有86%下降空间
- 1.4.3 成本曲线：每年10倍下降的指数级趋势
- 1.4.4 投资回报

---

### 第2章 技术全景与学习路径

#### 2.1 五大优化方向速览
- 2.1.1 快速评估矩阵
- 2.1.2 技术选型决策树
- 2.1.3 本书结构

#### 2.2 谁应该读这本书
- 2.2.1 核心读者
- 2.2.2 前置要求
- 2.2.3 学习路径

#### 2.3 配套资源
- 2.3.1 你将获得
- 2.3.2 阅前检查
- 2.3.3 让我们开始

---

## 第二部分：基础篇

### 第3章 GPU基础

#### 3.1 CPU vs GPU：本质差异
#### 3.2 GPU架构详解
#### 3.3 显存计算公式
#### 3.4 GPU性能监控
#### 3.5 性能瓶颈诊断
#### 3.6 常见GPU规格对比

#### 常见误区专栏
#### 实战检查清单
#### 动手练习

---

### 第4章 环境搭建

#### 4.1 开发环境概览
#### 4.2 基础环境安装
#### 4.3 vLLM快速入门
#### 4.4 Docker容器化部署
#### 4.5 基础推理示例
#### 4.6 开发工具推荐
#### 4.7 常见问题排查

#### 常见误区专栏
#### 实战检查清单
#### 动手练习

---

## 第三部分：核心技术篇

### 第5章 KV Cache优化

#### 5.1 Transformer回顾
#### 5.2 KV Cache原理
#### 5.3 KV Cache实现
#### 5.4 KV Cache优化技术
#### 5.5 KV Cache的代价
#### 5.6 实战对比

#### 常见误区专栏
#### 实战检查清单
#### 动手练习

---

### 第6章 请求调度策略

#### 6.1 调度的必要性
#### 6.2 基础调度策略
#### 6.3 动态批处理 (Continuous Batching)
#### 6.4 vLLM的调度器实现
#### 6.5 高级调度策略
#### 6.6 实战配置

#### 常见误区专栏
#### 实战检查清单
#### 动手练习

---

### 第7章 量化技术

#### 7.1 量化基础
- 7.1.1 什么是量化
- 7.1.2 量化原理：从FP32到INT8
- 7.1.3 为什么量化有效
- 7.1.4 量化的优势和代价

#### 7.2 量化方法分类
- 7.2.1 PTQ (Post-Training Quantization)
  - 训练后量化，无需重新训练
  - 速度快，适合快速部署
  - 可能有一定精度损失
- 7.2.2 QAT (Quantization-Aware Training) ⭐
  - 量化感知训练，在训练时模拟量化
  - 精度损失更小，train-infer一致性好
  - 需要完整训练周期
- 7.2.3 QLoRA vs Native Quantized Training vs QAT
  - 对比三种低精度训练技术
  - 适用场景和选择建议
- 7.2.4 量化方法选择决策树

#### 7.3 常用量化格式
- 7.3.1 INT8：经典的8位整数量化
- 7.3.2 INT4 (W4A16) ⭐
  - 4位权重，16位激活
  - 广泛的硬件支持
  - 工业界"足够好"的标准
- 7.3.3 FP4 vs INT4
  - 精度、性能、生态对比
  - 硬件支持差异
- 7.3.4 FP8 / NVFP4：未来方向
- 7.3.5 AWQ / GPTQ：流行的INT4格式

#### 7.4 流行的量化框架
- 7.4.1 vLLM量化支持
- 7.4.2 SGLang INT4推理 ⭐
  - Marlin内核支持
  - W4A16高效推理
  - MoE算子深度融合
- 7.4.3 NVIDIA Model Optimizer ⭐
  - QAT训练支持
  - Megatron-LM集成
- 7.4.4 AutoGPTQ / llama.cpp

#### 7.5 KV Cache量化
- 7.5.1 为什么KV Cache需要量化
- 7.5.2 KV Cache量化方法
- 7.5.3 精度与速度平衡

#### 7.6 实战：量化部署
- 7.6.1 使用vLLM进行量化推理
- 7.6.2 使用SGLang部署INT4模型
- 7.6.3 性能对比测试

#### 7.7 量化进阶：INT4 QAT实战 ⭐
- 7.7.1 什么是QAT
  - Fake Quantization + STE原理
  - train-infer一致性的重要性
- 7.7.2 INT4 QAT完整Pipeline
  - Stage 1: QAT训练（模拟量化）
  - Stage 2: 权重转换（真量化）
  - Stage 3: W4A16推理
- 7.7.3 训练端实现
  - Fake Quantization和STE
  - 权重更新和格式适配
  - 消融实验：QAT的必要性
- 7.7.4 推理端实现
  - SGLang W4A16推理
  - Bit packing和高效解包
  - MoE算子深度融合
- 7.7.5 实战案例：1TB模型压缩到单H200
  - Qwen3-235B-A22B实践
  - Kimi-K2-Thinking实践
  - 性能对比：BF16 vs FP8 vs INT4
- 7.7.6 QAT的适用场景
  - ✅ 大规模RL训练
  - ✅ 单节点部署超大模型
  - ✅ 需要train-infer一致性
  - ⚠️ 训练成本较高

#### 7.8 量化技术总结与展望

#### 常见误区专栏
#### 实战检查清单
#### 动手练习

---

### 第8章 投机采样

#### 8.1 生成加速的基本思路
#### 8.2 投机采样原理
#### 8.3 投机采样变体
- 8.3.1 Speculative Decoding
- 8.3.2 Assisted Decoding
- 8.3.3 Lookahead Decoding
- 8.3.4 Eagle系列：Eagle、Eagle 2、Eagle 3 ⭐
#### 8.4 草稿模型选择
#### 8.5 性能分析
#### 8.6 实战：vLLM投机采样
#### 8.7 实战：Eagle 3 with SGLang ⭐

#### 常见误区专栏
#### 实战检查清单
#### 动手练习

---

## 第四部分：生产部署篇

### 第9章 生产环境部署

#### 9.1 生产环境vs开发环境
#### 9.2 部署架构设计
#### 9.3 Kubernetes部署
#### 9.4 监控与可观测性
#### 9.5 性能调优实战
#### 9.6 成本优化
#### 9.7 ROI监控与成本追踪
#### 9.8 安全性考虑
#### 9.9 灾备与容错

#### 常见误区专栏
#### 实战检查清单
#### 动手练习

---

### 第10章 高级话题

#### 10.1 MoE模型推理优化
#### 10.2 多模态模型推理
#### 10.3 Torch Compile优化
#### 10.4 Flash Attention
#### 10.5 自定义算子开发
#### 10.6 边缘部署
#### 10.7 前沿技术展望

#### 常见误区专栏
#### 实战检查清单

---

## 附录

### 附录A：工具与资源

#### A.1 推理框架对比
#### A.2 模型资源
#### A.3 开发工具集
#### A.4 学习资源
#### A.5 术语表

---

### 附录B：故障排查指南

#### B.1 常见错误及解决
#### B.2 调试技巧
#### B.3 性能问题诊断清单

---

### 附录C：性能基准测试与ROI案例

#### C.1 测试环境说明
#### C.2 模型性能对比
#### C.3 优化技术效果对比
#### C.4 真实场景基准
#### C.5 ROI案例集

---

## 完整统计

### 内容规模
- **总章节数**：10章 + 3个附录
- **总节数**：约160节
- **总小节数**：约420小节
- **预计总字数**：35,000-45,000字

### 特色内容
- **常见误区专栏**：每章1个
- **实战检查清单**：每章1个
- **动手练习**：每章2个
- **成本影响说明**：每章1个
- **ROI案例**：贯穿全书
- **文明视角**：人类当量理论

### 配套资源
- **代码示例**：每章对应代码目录
- **Docker配置**：一键运行
- **视频教程**：30个视频
- **社区支持**：Discord讨论

---

**本书特色**：
- 📊 数据驱动：震撼数字建立动机
- 💼 商业导向：ROI案例证明价值
- 🏛️ 文明视角：人类当量理论
- 🔧 实战导向：每项技术都有代码
- 📈 成本意识：连接优化与价值
- 🎯 结构清晰：动机→路径→技术→部署
