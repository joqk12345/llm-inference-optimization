# LLMæ¨ç†ä¼˜åŒ–å®æˆ˜ - å®Œæ•´ç›®å½•ï¼ˆV2+V3èåˆç‰ˆï¼‰

**åˆ›å»ºæ—¥æœŸ**ï¼š2025-01-27
**ç‰ˆæœ¬**ï¼šV2.0 + V3.0 èåˆç‰ˆ
**æ€»å­—æ•°ç›®æ ‡**ï¼šçº¦35,000å­—ï¼ˆæ‰©å¤§ï¼‰
**ç« èŠ‚æ•°**ï¼š10ç« ï¼ˆæ–°å¢1ç« ï¼‰+ 3ä¸ªé™„å½•

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šåŠ¨æœºä¸è·¯å¾„ç¯‡ (Part 1: Motivation & Path)

### ç¬¬1ç«  AIæ¨ç†çš„æ–‡æ˜çº§æ„ä¹‰

#### 1.1 å¼€ç¯‡éœ‡æ’¼ï¼š50,000å€æ•ˆç‡é©å‘½
- 1.1.1 "äººç±»å½“é‡"æ¦‚å¿µ
- 1.1.2 å…·ä½“æ•°å­—å¯¹æ¯”
- 1.1.3 æ¨ç† = æ™ºèƒ½ç”Ÿäº§çš„æ ¸å¿ƒ

#### 1.2 ä¸ºä»€ä¹ˆæ˜¯ç°åœ¨ï¼šå››é‡è¯æ®
- 1.2.1 å†å²è¯æ®ï¼šé©¬å°”è¨æ–¯å¼çš„ç®€å•å…¬å¼
- 1.2.2 å¸‚åœºè¯æ®ï¼šè®­ç»ƒ$100B vs æ¨ç†$1.4T
- 1.2.3 éœ€æ±‚è¯æ®ï¼šæˆæœ¬â†“99% â†’ éœ€æ±‚çˆ†ç‚¸
- 1.2.4 ç»æµå­¦è¯æ®ï¼šæ‰“ç ´150å¹´GDPè¶‹åŠ¿çš„å¯èƒ½æ€§

#### 1.3 çœŸå®æ¡ˆä¾‹ï¼šä»ç†è®ºåˆ°ç°å®
- 1.3.1 Toastï¼š100å€ROIçš„AIå®¢æœ
- 1.3.2 DeepSeekï¼šAIæ°‘ä¸»åŒ–çš„å…³é”®ä¸€æ­¥
- 1.3.3 è™šæ‹ŸåŠ³åŠ¨åŠ›ï¼šAIä½œä¸ºç»æµå­¦å¼•æ“
- 1.3.4 è¿™äº›æ¡ˆä¾‹è¯´æ˜ä»€ä¹ˆ

#### 1.4 æŠ€æœ¯å¯è¡Œï¼š300å€æ•ˆç‡æå‡å·²éªŒè¯
- 1.4.1 å†å²è¯æ˜ï¼š2018-2023æ•ˆç‡é£è·ƒ
- 1.4.2 æœªæ¥æ½œåŠ›ï¼šè¿˜æœ‰86%ä¸‹é™ç©ºé—´
- 1.4.3 æˆæœ¬æ›²çº¿ï¼šæ¯å¹´10å€ä¸‹é™çš„æŒ‡æ•°çº§è¶‹åŠ¿
- 1.4.4 æŠ•èµ„å›æŠ¥

---

### ç¬¬2ç«  æŠ€æœ¯å…¨æ™¯ä¸è¶‹åŠ¿

> **ğŸ’° å•†ä¸šåŠ¨æœº**ï¼šäº†è§£æŠ€æœ¯å…¨æ™¯æ˜¯åšå‡ºæ­£ç¡®é€‰å‹çš„åŸºç¡€ã€‚é”™è¯¯çš„æ¶æ„é€‰æ‹©å¯èƒ½å¯¼è‡´åæœŸéœ€è¦æ¨å€’é‡æ¥ï¼Œæµªè´¹æ•°æœˆæ—¶é—´å’Œæ•°åä¸‡ç¾å…ƒæˆæœ¬ã€‚é”™è¿‡2025å¹´çš„å…³é”®æŠ€æœ¯è¶‹åŠ¿ï¼ˆå¦‚PDåˆ†ç¦»ã€RL infoï¼‰ï¼Œå¯èƒ½åœ¨ç«äº‰ä¸­è½åã€‚

#### 2.1 æŠ€æœ¯è¶‹åŠ¿æ¦‚è§ˆ â­
- 2.1.1 DeepSeek V3ï¼šMoEèŒƒå¼çš„é©å‘½
  - ç¬¬ä¸€æ¬¡åª²ç¾ChatGPTçš„å¼€æºæ¨¡å‹
  - å¤§è§„æ¨¡MoEçš„è®­ç»ƒå’Œæ¨ç†èŒƒå¼
  - ç®—åŠ›+infra+ç®—æ³•+dataçš„co-designæ‰æ˜¯ç‹é“
- 2.1.2 PDåˆ†ç¦»ï¼ˆPrefill-Decodeåˆ†ç¦»ï¼‰ï¼šä»æ¦‚å¿µåˆ°ç”Ÿäº§
  - 2025å¹´åˆï¼šæ¦‚å¿µæå‡º
  - 2025å¹´ä¸­ï¼šç¤¾åŒºåˆä½œï¼ˆvLLMã€SGLangï¼‰
  - 2025å¹´åº•ï¼šå‡ ä¹æ‰€æœ‰å‚å•†éƒ½åœ¨ç”¨
  - ä¸ºä»€ä¹ˆæˆä¸ºæ ‡å‡†æ¶æ„ï¼Ÿ
- 2.1.3 RL Infoçš„å…´èµ·
  - ä¸ŠåŠå¹´ï¼šæ¨ç†é›†ç¾¤åŒ–
  - ä¸‹åŠå¹´ï¼šRL infoå¦‚ä½•scaling up/scaling out
  - æ¡†æ¶æ¶Œç°ï¼šslimeã€verlã€areweã€veRL
  - è®­ç»ƒå’Œæ¨ç†çš„æ·±åº¦ç»“åˆ
- 2.1.4 Agentå’Œå¤šæ¨¡æ€çš„çˆ†å‘
  - Google: Gemini 2.0ã€NotebookLMã€Nanoç³»åˆ—
  - åŸç”Ÿå¤šæ¨¡èƒ½åŠ›çš„æ’¬åŠ¨æ æ†
  - è®­ç»ƒæˆæœ¬æŒ‡æ•°çº§ä¸‹é™
  - AIä½œä¸ºç§‘ç ”åŠ©æ‰‹çš„ç°å®
- 2.1.5 ä»SPMDåˆ°MPMD
  - ä¹‹å‰ï¼šPretrainçš„SPMDèŒƒå¼
  - ç°åœ¨ï¼šRLçš„MPMDå¼‚æ„å½¢æ€
  - ä»Workflowåˆ°Event Driven
  - æŠ€æœ¯æ ˆè¶Šæ¥è¶Šæ·±

#### 2.2 äº”å¤§ä¼˜åŒ–æ–¹å‘é€Ÿè§ˆ
- 2.2.1 å¿«é€Ÿè¯„ä¼°çŸ©é˜µ
- 2.2.2 æŠ€æœ¯é€‰å‹å†³ç­–æ ‘
- 2.2.3 æœ¬ä¹¦ç»“æ„

#### 2.3 è°åº”è¯¥è¯»è¿™æœ¬ä¹¦
- 2.3.1 æ ¸å¿ƒè¯»è€…
- 2.3.2 å‰ç½®è¦æ±‚
- 2.3.3 å­¦ä¹ è·¯å¾„

#### 2.4 é…å¥—èµ„æº
- 2.4.1 ä½ å°†è·å¾—
- 2.4.2 é˜…å‰æ£€æŸ¥
- 2.4.3 è®©æˆ‘ä»¬å¼€å§‹

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€ç¯‡ (Part 2: Foundations)

### ç¬¬3ç«  GPUåŸºç¡€

> **ğŸ’° å•†ä¸šåŠ¨æœº**ï¼šç†è§£GPUæ˜¯é™ä½æ¨ç†æˆæœ¬çš„åŸºç¡€ã€‚æ ¹æ®ARKç ”ç©¶ï¼Œç¡¬ä»¶é…ç½®ä¸å½“ä¼šå¯¼è‡´æ¨ç†æˆæœ¬æé«˜3-5å€ã€‚é€‰æ‹©åˆé€‚çš„GPUå¯ä»¥èŠ‚çœæ•°åƒç¾å…ƒçš„æœˆåº¦è¿è¥æˆæœ¬ã€‚

#### 3.1 CPU vs GPUï¼šæœ¬è´¨å·®å¼‚
- 3.1.1 ç±»æ¯”ï¼šæ•°å­¦æ•™æˆvså°å­¦ç”Ÿå›¢é˜Ÿ
- 3.1.2 å¹¶è¡Œè®¡ç®—vsä¸²è¡Œè®¡ç®—
- 3.1.3 ä¸ºä»€ä¹ˆGPUé€‚åˆçŸ©é˜µè¿ç®—
- 3.1.4 GPUä¸é€‚åˆçš„ä»»åŠ¡ç±»å‹

#### 3.2 GPUæ¶æ„è¯¦è§£
- 3.2.1 æµå¼å¤šå¤„ç†å™¨(SM)ï¼šGPUçš„æ ¸å¿ƒå•å…ƒ
- 3.2.2 æ˜¾å­˜(VRAM)ï¼šå®¹é‡vså¸¦å®½
- 3.2.3 å†…å­˜å±‚æ¬¡ç»“æ„ï¼šL1/L2 cache
- 3.2.4 å¸¦å®½ï¼šæ¨ç†çš„çœŸæ­£ç“¶é¢ˆ
- 3.2.5 PCIeé€šé“ï¼šGPUä¸CPUçš„æ¡¥æ¢

#### 3.3 æ˜¾å­˜è®¡ç®—å…¬å¼
- 3.3.1 æ¨¡å‹æƒé‡è®¡ç®—
- 3.3.2 KV Cacheæ˜¾å­˜å ç”¨
- 3.3.3 æ¿€æ´»å€¼æ˜¾å­˜
- 3.3.4 CUDAå¼€é”€
- 3.3.5 å®æˆ˜è®¡ç®—ï¼šLlama-3-8Béœ€è¦å¤šå°‘æ˜¾å­˜
- 3.3.6 å®æˆ˜è®¡ç®—ï¼šLlama-3-70Bå¦‚ä½•æ”¾å¾—ä¸‹

#### 3.4 GPUæ€§èƒ½ç›‘æ§
- 3.4.1 nvidia-smiè¯¦è§£
- 3.4.2 æŒç»­ç›‘æ§å·¥å…·
- 3.4.3 Pythonç›‘æ§ï¼špynvmlåº“
- 3.4.4 æ€§èƒ½è®¡æ•°å™¨

#### 3.5 æ€§èƒ½ç“¶é¢ˆè¯Šæ–­
- 3.5.1 ä¸‰å¤§ç“¶é¢ˆç±»å‹
- 3.5.2 è¯Šæ–­æµç¨‹å›¾
- 3.5.3 å®æˆ˜æ¡ˆä¾‹ï¼šåˆ†æçœŸå®çš„æ¨ç†ç“¶é¢ˆ

#### 3.6 å¸¸è§GPUè§„æ ¼å¯¹æ¯”
- 3.6.1 æ¶ˆè´¹çº§GPUï¼šRTXç³»åˆ—
- 3.6.2 æ•°æ®ä¸­å¿ƒGPUï¼šA100ã€H100
- 3.6.3 äº‘GPUé€‰æ‹©æŒ‡å—
- 3.6.4 æ€§ä»·æ¯”åˆ†æ

#### å¸¸è§è¯¯åŒºä¸“æ 
#### å®æˆ˜æ£€æŸ¥æ¸…å•
#### åŠ¨æ‰‹ç»ƒä¹ 
- ç»ƒä¹ 3.1ï¼šè®¡ç®—ä¸åŒæ¨¡å‹çš„æ˜¾å­˜éœ€æ±‚
- ç»ƒä¹ 3.2ï¼šç›‘æ§çœŸå®æ¨ç†ä»»åŠ¡çš„GPUä½¿ç”¨

---

### ç¬¬4ç«  ç¯å¢ƒæ­å»º

> **ğŸ’° å•†ä¸šåŠ¨æœº**ï¼šæ­£ç¡®çš„ç¯å¢ƒé…ç½®å¯ä»¥é¿å…80%çš„éƒ¨ç½²é—®é¢˜ã€‚æ ¹æ®è¡Œä¸šæ•°æ®ï¼Œç¯å¢ƒä¸å½“å¯¼è‡´çš„æ•…éšœå¹³å‡æ’æŸ¥æ—¶é—´ä¸º4-8å°æ—¶ï¼Œè€Œæ­£ç¡®é…ç½®å¯ä»¥åœ¨30åˆ†é’Ÿå†…å®Œæˆéƒ¨ç½²ã€‚

#### 4.1 å¼€å‘ç¯å¢ƒæ¦‚è§ˆ
- 4.1.1 ä¸ºä»€ä¹ˆä½¿ç”¨Docker
- 4.1.2 ç¯å¢ƒä¸€è‡´æ€§ï¼šæœ¬åœ°vsç”Ÿäº§
- 4.1.3 å®Œæ•´æŠ€æœ¯æ ˆ

#### 4.2 åŸºç¡€ç¯å¢ƒå®‰è£…
- 4.2.1 NVIDIAé©±åŠ¨å®‰è£…
- 4.2.2 CUDA Toolkité…ç½®
- 4.2.3 Dockerä¸NVIDIA Container Toolkit
- 4.2.4 Pythonç¯å¢ƒç®¡ç†

#### 4.3 vLLMå¿«é€Ÿå…¥é—¨
- 4.3.1 ä»€ä¹ˆæ˜¯vLLM
- 4.3.2 vLLM vså…¶ä»–æ¨ç†æ¡†æ¶
- 4.3.3 å®‰è£…vLLM
- 4.3.4 å¯åŠ¨ç¬¬ä¸€ä¸ªæ¨ç†æœåŠ¡

#### 4.4 Dockerå®¹å™¨åŒ–éƒ¨ç½²
- 4.4.1 Dockerfileç¼–å†™
- 4.4.2 Docker Composeé…ç½®
- 4.4.3 å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–
- 4.4.4 æ•°æ®å·ç®¡ç†

#### 4.5 åŸºç¡€æ¨ç†ç¤ºä¾‹
- 4.5.1 å•æ¬¡æ¨ç†
- 4.5.2 æ‰¹é‡æ¨ç†
- 4.5.3 æµå¼è¾“å‡º
- 4.5.4 æ€§èƒ½åŸºå‡†æµ‹è¯•

#### 4.6 å¼€å‘å·¥å…·æ¨è
- 4.6.1 ä»£ç ç¼–è¾‘å™¨é…ç½®
- 4.6.2 è°ƒè¯•å·¥å…·
- 4.6.3 æ€§èƒ½åˆ†æå·¥å…·
- 4.6.4 å¯è§†åŒ–å·¥å…·

#### 4.7 å¸¸è§é—®é¢˜æ’æŸ¥
- 4.7.1 CUDAç‰ˆæœ¬ä¸å…¼å®¹
- 4.7.2 Docker GPUè®¿é—®é—®é¢˜
- 4.7.3 ç«¯å£å†²çªå¤„ç†
- 4.7.4 ä¾èµ–å®‰è£…å¤±è´¥

#### å¸¸è§è¯¯åŒºä¸“æ 
#### å®æˆ˜æ£€æŸ¥æ¸…å•
#### åŠ¨æ‰‹ç»ƒä¹ 
- ç»ƒä¹ 4.1ï¼šä»é›¶æ­å»ºvLLMå¼€å‘ç¯å¢ƒ
- ç»ƒä¹ 4.2ï¼šDockeråŒ–ä¸€ä¸ªæ¨ç†æœåŠ¡

---

### ç¬¬5ç«  LLMæ¨ç†åŸºç¡€ â­ æ–°å¢

> **ğŸ’¡ æ•™å­¦ç†å¿µ**ï¼ˆå‚è€ƒï¼šHugging Face "Continuous batching from first principles"ï¼‰
>
> **æ ¸å¿ƒæ€è·¯**ï¼šä»ç¬¬ä¸€æ€§åŸç†å‡ºå‘ï¼Œç†è§£LLMæ¨ç†çš„åŸºæœ¬æµç¨‹å’Œä¼˜åŒ–åŠ¨æœºã€‚
>
> **å­¦ä¹ è·¯å¾„**ï¼šAttention â†’ KV Cache â†’ Chunked Prefill â†’ Continuous Batching

#### 5.1 LLMå¦‚ä½•ç”Ÿæˆæ–‡æœ¬

- 5.1.1 è‡ªå›å½’ç”Ÿæˆçš„åŸºæœ¬è¿‡ç¨‹
  - **LLMçš„æœ¬è´¨**ï¼š fancy next token predictors
  - **ç”Ÿæˆè¿‡ç¨‹**ï¼š
    - è¾“å…¥æ•´ä¸ªprompt â†’ ç”Ÿæˆç¬¬ä¸€ä¸ªtoken
    - é€ä¸ªæ·»åŠ tokenï¼Œæ¯æ¬¡è¯»å–ä¹‹å‰æ‰€æœ‰å†…å®¹
    - ç›´åˆ°å†³å®šç”Ÿæˆç»“æŸ
  - **è§‚å¯Ÿ**ï¼šç¬¬ä¸€ä¸ªtokenå‡ºç°æ…¢ï¼ˆTTFTï¼‰ï¼Œä¹‹åtokené€ä¸ªå‡ºç°

- 5.1.2 Prefillé˜¶æ®µï¼šå¹¶è¡Œå¤„ç†prompt
  - **å®šä¹‰**ï¼šå¤„ç†åˆå§‹promptï¼Œç”Ÿæˆç¬¬ä¸€ä¸ªtoken
  - **ç‰¹ç‚¹**ï¼šè®¡ç®—å¯†é›†ï¼Œå¯ä»¥å¹¶è¡Œå¤„ç†
  - **æ—¶é—´**ï¼šTTFTï¼ˆTime To First Tokenï¼‰
  - **ç¤ºä¾‹**ï¼špromptæœ‰100ä¸ªtokenï¼Œä¸€æ¬¡forward passå¤„ç†å…¨éƒ¨

- 5.1.3 Decodeé˜¶æ®µï¼šé€tokenç”Ÿæˆ
  - **å®šä¹‰**ï¼šé€ä¸ªç”Ÿæˆåç»­token
  - **ç‰¹ç‚¹**ï¼šå†…å­˜å¸¦å®½å¯†é›†ï¼Œæ¯æ¬¡åªç”Ÿæˆ1ä¸ªtoken
  - **æ—¶é—´**ï¼šTBTï¼ˆTime Between Tokensï¼‰
  - **ç¤ºä¾‹**ï¼šç”Ÿæˆ100ä¸ªtokenéœ€è¦100æ¬¡forward pass

- 5.1.4 å›¾è§£å®Œæ•´æµç¨‹
  - å¯è§†åŒ–ï¼šPrefill â†’ Decode[1] â†’ Decode[2] â†’ ... â†’ Decode[n]
  - æ ‡æ³¨æ¯ä¸ªé˜¶æ®µçš„ç‰¹ç‚¹å’Œä¼˜åŒ–æ–¹å‘

#### 5.2 Attentionæœºåˆ¶è¯¦è§£

> **ğŸ’¡ ä¸ºä»€ä¹ˆé‡è¦**ï¼šAttentionæ˜¯å”¯ä¸€è®©ä¸åŒtokenäº§ç”Ÿäº¤äº’çš„åœ°æ–¹ã€‚ç†è§£Attentionï¼Œå°±ç†è§£äº†LLMçš„æ ¸å¿ƒã€‚

- 5.2.1 Tokençš„è¡¨ç¤ºï¼šå‘é‡ä¸hidden dimension
  - **Tokenization**ï¼šæ–‡æœ¬ â†’ tokenåºåˆ—
  - **Embedding**ï¼šæ¯ä¸ªtoken â†’ dç»´å‘é‡ï¼ˆhidden dimensionï¼‰
  - **Tensorå½¢çŠ¶**ï¼š[batch_size, sequence_length, hidden_dim]
  - **ç¤ºä¾‹**ï¼š7ä¸ªtoken â†’ [1, 7, d]ï¼ˆbatch=1ï¼‰

- 5.2.2 Queryã€Keyã€ValueæŠ•å½±
  - **ä¸‰ä¸ªæƒé‡çŸ©é˜µ**ï¼šWqã€Wkã€Wv
  - **æŠ•å½±æ“ä½œ**ï¼šQ = xÂ·Wq, K = xÂ·Wk, V = xÂ·Wv
  - **è¾“å‡ºå½¢çŠ¶**ï¼š[1, n, A]ï¼ˆA = attention head dimensionï¼‰
  - **ç‰©ç†æ„ä¹‰**ï¼š
    - Qï¼šè¿™ä¸ªtokenæƒ³æ‰¾ä»€ä¹ˆï¼Ÿ
    - Kï¼šè¿™ä¸ªtokenèƒ½æä¾›ä»€ä¹ˆï¼Ÿ
    - Vï¼šè¿™ä¸ªtokençš„å®é™…å†…å®¹

- 5.2.3 Attentionè®¡ç®—ï¼šQK^Tä¸äºŒæ¬¡å¤æ‚åº¦
  - **è®¡ç®—æ­¥éª¤**ï¼š
    1. QÂ·K^T â†’ ç›¸ä¼¼åº¦çŸ©é˜µ [n, n]
    2. é™¤ä»¥âˆšdï¼ˆç¼©æ”¾ï¼‰
    3. Softmaxï¼ˆå½’ä¸€åŒ–ï¼‰
    4. ä¹˜ä»¥V
  - **å¤æ‚åº¦**ï¼šO(nÂ²Â·d)
  - **å…³é”®æ´å¯Ÿ**ï¼šAttentionçš„äºŒæ¬¡å¤æ‚åº¦æ˜¯æ€§èƒ½ç“¶é¢ˆ

- 5.2.4 Attention Maskï¼šæ§åˆ¶tokenäº¤äº’
  - **ä»€ä¹ˆæ˜¯Mask**ï¼šå¸ƒå°”çŸ©é˜µï¼Œå†³å®šå“ªäº›tokenå¯ä»¥äº¤äº’
  - **å½¢çŠ¶**ï¼šä¸QK^Tç›¸åŒ [n, n]
  - **ä½œç”¨**ï¼šMask=Falseçš„ä½ç½®ï¼Œattentionæƒé‡=0
  - **å¯è§†åŒ–æ–¹æ³•**ï¼š
    - ç»¿è‰²æ–¹å— = Trueï¼ˆå¯ä»¥äº¤äº’ï¼‰
    - ç™½è‰²æ–¹å— = Falseï¼ˆä¸èƒ½äº¤äº’ï¼‰

- 5.2.5 Causal Maskï¼šå› æœå…³ç³»çš„å¯è§†åŒ–
  - **å®šä¹‰**ï¼šæ¯ä¸ªtokenåªèƒ½ä¸ä¹‹å‰çš„tokenäº¤äº’
  - **ç›´è§‰**ï¼šå› å¿…é¡»åœ¨æœä¹‹å‰
  - **Maskå½¢çŠ¶**ï¼šä¸‹ä¸‰è§’çŸ©é˜µ
  - **å¯è§†åŒ–ç¤ºä¾‹**ï¼š
    ```
    Token:  <bos>  I     am    sure
    <bos>:  [âœ“]   [âœ“]   [âœ“]   [âœ“]
    I:      [ ]    [âœ“]   [âœ“]   [âœ“]
    am:     [ ]    [ ]    [âœ“]   [âœ“]
    sure:   [ ]    [ ]    [ ]    [âœ“]
    ```
  - **è¯»maskæ–¹æ³•**ï¼šè¡Œ=å½“å‰tokenï¼Œåˆ—=å†å²token

- 5.2.6 ä¸ºä»€ä¹ˆAttentionæ˜¯å”¯ä¸€è®©tokenäº¤äº’çš„åœ°æ–¹
  - **å…¶ä»–æ“ä½œ**ï¼štoken-wiseï¼Œæ¯ä¸ªtokenç‹¬ç«‹å¤„ç†
    - Layer normalization
    - æ¿€æ´»å‡½æ•°
    - çŸ©é˜µä¹˜æ³•
  - **Attentionçš„ä½œç”¨**ï¼šè®©tokenä¹‹é—´"äº¤æµ"
  - **ç»“è®º**ï¼šç†è§£äº†attention maskï¼Œå°±ç†è§£äº†LLMçš„ä¿¡æ¯æµ

#### 5.3 ä»æœ´ç´ ç”Ÿæˆåˆ°KV Cache

- 5.3.1 æœ´ç´ æ–¹æ³•ï¼šæ¯æ¬¡é‡æ–°è®¡ç®—ï¼ˆO(nÂ²)ï¼‰
  - **é—®é¢˜åœºæ™¯**ï¼šç”Ÿæˆç¬¬n+1ä¸ªtoken
  - **æœ´ç´ åšæ³•**ï¼š
    1. å°†æ‰€æœ‰n+1ä¸ªtokené‡æ–°è¾“å…¥æ¨¡å‹
    2. é‡æ–°è®¡ç®—æ‰€æœ‰tokençš„Kå’ŒV
    3. åªä½¿ç”¨æœ€åä¸€ä¸ªtokençš„è¾“å‡º
  - **è®¡ç®—å¤æ‚åº¦**ï¼šO((n+1)Â²) â†’ éšåºåˆ—é•¿åº¦äºŒæ¬¡å¢é•¿
  - **å¯è§†åŒ–æµªè´¹**ï¼šç°è‰²tokençš„Kã€Vè¢«é‡å¤è®¡ç®—

- 5.3.2 é‡å¤è®¡ç®—é—®é¢˜çš„å¯è§†åŒ–
  - **å…³é”®è§‚å¯Ÿ**ï¼šæ–°tokenï¼ˆå¦‚"will"ï¼‰ä¸å½±å“æ—§tokençš„attentionè®¡ç®—
  - **åŸå› **ï¼šCausal maskï¼Œæœªæ¥tokenä¸å½±å“è¿‡å»
  - **å›¾ç¤º**ï¼šæœ€åä¸€ä¸ªtokenåªå…³å¿ƒè‡ªå·±çš„é¢„æµ‹ï¼Œä¸å½±å“å…¶ä»–token

- 5.3.3 KV Cacheçš„æ ¸å¿ƒæ€æƒ³
  - **æ ¸å¿ƒæ´å¯Ÿ**ï¼šæ—§tokençš„Kã€Vå·²ç»è®¡ç®—è¿‡ï¼Œç¼“å­˜èµ·æ¥ï¼
  - **åšæ³•**ï¼š
    - Prefillé˜¶æ®µï¼šè®¡ç®—å¹¶å­˜å‚¨æ‰€æœ‰tokençš„Kã€V
    - Decodeé˜¶æ®µï¼šåªè®¡ç®—æ–°tokençš„Kã€Vï¼Œå¤ç”¨ç¼“å­˜çš„Kã€V
  - **æ•ˆæœ**ï¼šé¿å…é‡å¤è®¡ç®—
  - **ä»£ä»·**ï¼šæ˜¾å­˜å ç”¨ O(n)

- 5.3.4 è®¡ç®—å¤æ‚åº¦é™ä½ï¼šä»O(nÂ²)åˆ°O(n)
  - **æ— KV Cache**ï¼šæ¯ä¸ªtoken O(nÂ²)
  - **æœ‰KV Cache**ï¼šç¬¬ä¸€ä¸ªtoken O(nÂ²)ï¼Œåç»­token O(n)
  - **å¹³å‡å¤æ‚åº¦**ï¼šO(n)
  - **åŠ é€Ÿæ•ˆæœ**ï¼šåºåˆ—è¶Šé•¿ï¼ŒåŠ é€Ÿè¶Šæ˜æ˜¾

- 5.3.5 æ˜¾å­˜ä»£ä»·ï¼šæ¯ä¸ªtokenéœ€è¦å¤šå°‘æ˜¾å­˜ï¼Ÿ
  - **å•tokençš„cacheå¤§å°**ï¼š2Â·LÂ·HÂ·Aï¼ˆKå’ŒVï¼‰
    - L = å±‚æ•°ï¼ˆå¦‚32ï¼‰
    - H = headsæ•°ï¼ˆå¦‚32ï¼‰
    - A = head dimensionï¼ˆå¦‚128ï¼‰
  - **ç¤ºä¾‹è®¡ç®—**ï¼š
    - Llama-2-7Bï¼š2 Ã— 32 Ã— 128 Ã— 2 bytes = 16 KB/token
    - 1000 tokens = 16 MB
    - 10000 tokens = 160 MB
  - **æƒè¡¡**ï¼šç”¨æ˜¾å­˜æ¢è®¡ç®—

#### 5.4 Chunked Prefillï¼šå¤„ç†é•¿prompt

- 5.4.1 é—®é¢˜ï¼šå¤§promptè¶…è¿‡æ˜¾å­˜
  - **åœºæ™¯**ï¼šCursoræ·»åŠ æ•´ä¸ªä»£ç ä»“åº“åˆ°prompt
  - **é—®é¢˜**ï¼šnä¸ªtokençš„æ¿€æ´»å€¼è¶…è¿‡GPUæ˜¾å­˜
  - **çº¦æŸ**ï¼šæ¯æ¬¡forward passæœ€å¤šå¤„ç†mä¸ªtoken

- 5.4.2 è§£å†³æ–¹æ¡ˆï¼šåˆ†å—å¤„ç†
  - **æ€è·¯**ï¼šå°†nä¸ªtokençš„promptåˆ†æˆâŒˆn/mâŒ‰ä¸ªchunks
  - **ç¤ºä¾‹**ï¼šn=7, m=4 â†’ åˆ†æˆ2ä¸ªchunks
    - Chunk 1ï¼štokens[0:4]
    - Chunk 2ï¼štokens[4:7]
  - **å…³é”®**ï¼šå¦‚ä½•ä¿æŒä¿¡æ¯è¿ç»­æ€§ï¼Ÿ

- 5.4.3 KV Cacheåœ¨chunked prefillä¸­çš„ä½œç”¨
  - **Chunk 1**ï¼š
    - å¤„ç†tokens[0:4]
    - è®¡ç®—å¹¶ç¼“å­˜Kã€V
  - **Chunk 2**ï¼š
    - å¤„ç†tokens[4:7]
    - å¤ç”¨Chunk 1ç¼“å­˜çš„Kã€V
    - æ‹¼æ¥ï¼šKV_cached + KV_new
  - **Attention maskè°ƒæ•´**ï¼šç¡®ä¿è·¨chunkçš„tokenæ­£ç¡®äº¤äº’

- 5.4.4 å›¾è§£åˆ†å—å¤„ç†æµç¨‹
  - **æ— chunked prefill**ï¼šä¸€æ¬¡æ€§å¤„ç†ï¼Œmemoryä¸å¤Ÿ
  - **æœ‰chunked prefill**ï¼š
    - Chunk 1: [tokens 0-3] â†’ cache KV
    - Chunk 2: [cached KV] + [tokens 4-6] â†’ cache KV
  - **çµæ´»æ€§**ï¼šå¯æ ¹æ®å†…å­˜çº¦æŸåŠ¨æ€è°ƒæ•´chunkå¤§å°

#### 5.5 æ‰¹å¤„ç†çš„æŒ‘æˆ˜ï¼šä»é™æ€åˆ°åŠ¨æ€

- 5.5.1 é™æ€æ‰¹å¤„ç†
  - **ç›®æ ‡**ï¼šæé«˜ååé‡ï¼ˆthroughputï¼‰
  - **æ–¹æ³•**ï¼šå°†å¤šä¸ªpromptæ‰“åŒ…æˆä¸€ä¸ªbatch
  - **çº¦æŸ**ï¼šæ‰€æœ‰promptå¿…é¡»æœ‰ç›¸åŒé•¿åº¦
  - **è§£å†³æ–¹æ¡ˆ**ï¼šå·¦ä¾§paddingï¼Œå³ä¾§å¯¹é½

- 5.5.2 Paddingçš„é—®é¢˜ï¼šè®¡ç®—æµªè´¹
  - **Paddingä½ç½®**ï¼šå·¦ä¾§ï¼ˆæ·»åŠ `<pad>` tokenï¼‰
  - **Attention mask**ï¼špaddingä½ç½®è®¾ä¸ºFalse
  - **é—®é¢˜**ï¼špadding tokenå ç”¨äº†è®¡ç®—èµ„æºï¼Œä½†æ²¡æœ‰å®é™…è´¡çŒ®
  - **ç¤ºä¾‹**ï¼š2ä¸ªpromptï¼Œé•¿åº¦3å’Œ7 â†’ éœ€è¦paddingåˆ°7
    - Prompt 1: `<pad><pad><pad><token1><token2><token3><eos>`
    - Prompt 2: `<token1><token2><token3><token4><token5><token6><token7>`

- 5.5.3 ä¸åŒåºåˆ—é•¿åº¦çš„å›°å¢ƒ
  - **åœºæ™¯**ï¼šbatchä¸­æœ‰å¤šä¸ªpromptï¼Œé•¿åº¦å·®å¼‚å¤§
  - **é—®é¢˜1**ï¼šçŸ­promptå®Œæˆåï¼Œé•¿promptè¿˜åœ¨ç”Ÿæˆ
    - çŸ­promptçš„è®¡ç®—æµªè´¹ï¼ˆpaddingï¼‰
  - **é—®é¢˜2**ï¼šåŠ¨æ€è°ƒåº¦å¼•å…¥å¤§é‡padding
    - æ–°åŠ å…¥çš„promptéœ€è¦prefill
    - æ­£åœ¨decodeçš„promptæ¯æ¬¡åªåŠ 1ä¸ªtoken
    - Paddingæ•°é‡ = (n-1) Ã— (B-1)

- 5.5.4 ç¤ºä¾‹ï¼šä¸ºä»€ä¹ˆpaddingæˆæœ¬éšbatchå’Œé•¿åº¦äºŒæ¬¡å¢é•¿
  - **å‚æ•°**ï¼š
    - B = 8ï¼ˆbatchä¸­8ä¸ªpromptåœ¨decodeï¼‰
    - n = 100ï¼ˆæ–°promptæœ‰100ä¸ªtokenï¼‰
  - **Paddingæ•°é‡**ï¼š(100-1) Ã— (8-1) = 99 Ã— 7 = 693ä¸ªpadding tokensï¼
  - **ç»“è®º**ï¼šåŠ¨æ€è°ƒåº¦ + ä¼ ç»Ÿbatching = ç¾éš¾

#### 5.6 Continuous Batchingå…¥é—¨ â­

> **ğŸ’¡ æ ¸å¿ƒæ´å¯Ÿ**ï¼šå»æ‰batchç»´åº¦ï¼Œç”¨attention maskæ§åˆ¶tokenäº¤äº’ï¼Œè®©GPUæ—¶åˆ»æ»¡è½½ã€‚

- 5.6.1 æ ¸å¿ƒæ€æƒ³ï¼šå»æ‰batchç»´åº¦
  - **é—®é¢˜æ ¹æº**ï¼šbatchç»´åº¦å¼•å…¥äº†padding
  - **æ¿€è¿›æƒ³æ³•**ï¼šä¸è¦batchç»´åº¦ï¼
  - **æ›¿ä»£æ–¹æ¡ˆ**ï¼šæ‹¼æ¥æ‰€æœ‰prompt
  - **æ–°é—®é¢˜**ï¼šå¦‚ä½•é˜²æ­¢ä¸åŒpromptçš„tokenäº’ç›¸å¹²æ‰°ï¼Ÿ

- 5.6.2 Ragged Batchingï¼šç”¨attention maskæ§åˆ¶äº¤äº’
  - **æ–¹æ³•**ï¼š
    1. å°†å¤šä¸ªpromptæ‹¼æ¥æˆä¸€ä¸ªåºåˆ—
    2. ç”¨attention maskæ§åˆ¶tokenäº¤äº’
    3. Prompt Açš„tokenä¸èƒ½attend to Prompt Bçš„token
  - **Maskå½¢çŠ¶**ï¼šå—å¯¹è§’çŸ©é˜µï¼ˆblock-diagonalï¼‰
  - **å¯è§†åŒ–**ï¼š
    ```
    Prompt A (3 tokens): [A1, A2, A3]
    Prompt B (2 tokens): [B1, B2]

    Attention Mask:
    A1:  [âœ“] [  ] [  ] [  ] [  ]
    A2:  [âœ“] [âœ“] [  ] [  ] [  ]
    A3:  [âœ“] [âœ“] [âœ“] [  ] [  ]
    B1:  [  ] [  ] [  ] [âœ“] [  ]
    B2:  [  ] [  ] [  ] [âœ“] [âœ“]
    ```
  - **ä¼˜åŠ¿**ï¼šæ— paddingï¼Œæ‰€æœ‰è®¡ç®—éƒ½æœ‰æ„ä¹‰

- 5.6.3 Dynamic Schedulingï¼šåŠ¨æ€æ›¿æ¢å®Œæˆçš„è¯·æ±‚
  - **åœºæ™¯**ï¼šæŸä¸ªpromptç”Ÿæˆ`<eos>`
  - **åŠ¨ä½œ**ï¼š
    1. ç«‹å³ä»batchä¸­ç§»é™¤
    2. ç”¨ç­‰å¾…ä¸­çš„promptæ›¿æ¢
    3. é‡æ–°æ„å»ºattention mask
  - **ç›®æ ‡**ï¼šä¿æŒGPUæ—¶åˆ»æ»¡è½½
  - **å…³é”®**ï¼šRagged batchingè®©æ›¿æ¢æˆæœ¬ä½

- 5.6.4 æ··åˆPrefillå’ŒDecodeï¼šæœ€å¤§åŒ–throughput
  - **æŒ‘æˆ˜**ï¼š
    - Decodeé˜¶æ®µçš„promptæ¯æ¬¡åªåŠ 1ä¸ªtoken
    - æ–°åŠ å…¥çš„promptéœ€è¦prefillå¾ˆå¤štoken
  - **è°ƒåº¦ç®—æ³•**ï¼š
    1. ç›®æ ‡ï¼šæ¯ä¸ªbatchè¾¾åˆ°mä¸ªtokenï¼ˆmemory budgetï¼‰
    2. ä¼˜å…ˆï¼šæ‰€æœ‰decode promptåŠ å…¥ï¼ˆæ¯ä¸ªå 1ä¸ªtokenï¼‰
    3. å¡«å……ï¼šç”¨chunked prefillåŠ å…¥æ–°prompt
  - **ç¤ºä¾‹**ï¼š
    - Memory budget: m=1000
    - 10ä¸ªdecode prompts â†’ å ç”¨10ä¸ªtoken
    - å‰©ä½™990ä¸ªtoken â†’ ç”¨äºprefillæ–°è¯·æ±‚

- 5.6.5 å®Œæ•´çš„Continuous Batchingæµç¨‹å›¾
  - **æ­¥éª¤1**ï¼šåˆå§‹batchï¼ˆå¤šä¸ªdecodeé˜¶æ®µçš„è¯·æ±‚ï¼‰
  - **æ­¥éª¤2**ï¼šæŸä¸ªè¯·æ±‚å®Œæˆ â†’ ç§»é™¤
  - **æ­¥éª¤3**ï¼šæ–°è¯·æ±‚åŠ å…¥ â†’ chunked prefill
  - **æ­¥éª¤4**ï¼šé‡å»ºattention mask â†’ ragged batching
  - **æ­¥éª¤5**ï¼šforward pass â†’ ç”Ÿæˆtoken
  - **å¾ªç¯**ï¼šå›åˆ°æ­¥éª¤2

- 5.6.6 Continuous Batching vs ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”
  - **Static Batching**ï¼š
    - ä¼˜ç‚¹ï¼šç®€å•
    - ç¼ºç‚¹ï¼šå¤§é‡paddingï¼Œååé‡ä½
  - **Dynamic Batching**ï¼š
    - ä¼˜ç‚¹ï¼šåŠ¨æ€è°ƒæ•´
    - ç¼ºç‚¹ï¼špaddingä»ç„¶ä¸¥é‡
  - **Continuous Batching**ï¼š
    - ä¼˜ç‚¹ï¼šæ— paddingï¼ŒGPUåˆ©ç”¨ç‡æœ€é«˜
    - ç¼ºç‚¹ï¼šå®ç°å¤æ‚ï¼Œéœ€è¦åŠ¨æ€ç®¡ç†attention mask

#### å¸¸è§è¯¯åŒºä¸“æ 
- è¯¯åŒº1ï¼š"Attentionå¾ˆå¤æ‚ï¼Œå¾ˆéš¾ç†è§£" â†’ å…¶å®æ ¸å¿ƒå°±æ˜¯QK^T
- è¯¯åŒº2ï¼š"KV Cacheæ€»æ˜¯å¥½çš„" â†’ æ˜¾å­˜æ¢è®¡ç®—ï¼Œé•¿åºåˆ—æ˜¾å­˜å‹åŠ›å¤§
- è¯¯åŒº3ï¼š"Batchè¶Šå¤§è¶Šå¥½" â†’ paddingæµªè´¹ï¼Œcontinuous batchingæ‰æ˜¯æ­£è§£
- è¯¯åŒº4ï¼š"Prefillå’ŒDecodeåº”è¯¥åˆ†å¼€å¤„ç†" â†’ æ··åˆå¤„ç†æ‰èƒ½æœ€å¤§åŒ–throughput

#### å®æˆ˜æ£€æŸ¥æ¸…å•
- [ ] ç†è§£Attentionçš„Qã€Kã€VæŠ•å½±
- [ ] èƒ½å¤Ÿç”»å‡ºCausal Maskçš„å¯è§†åŒ–
- [ ] è®¡ç®—ç»™å®šæ¨¡å‹çš„KV Cacheæ˜¾å­˜å ç”¨
- [ ] ç†è§£Chunked Prefillçš„åº”ç”¨åœºæ™¯
- [ ] ç†è§£Ragged Batchingçš„attention maskæ„å»º
- [ ] èƒ½å¤Ÿè§£é‡ŠContinuous Batchingçš„å®Œæ•´æµç¨‹

#### åŠ¨æ‰‹ç»ƒä¹ 
- ç»ƒä¹ 5.1ï¼šæ‰‹åŠ¨è®¡ç®—ä¸€ä¸ªç®€å•æ¨¡å‹çš„KV Cacheå¤§å°
- ç»ƒä¹ 5.2ï¼šå¯è§†åŒ–ä¸åŒbatchingç­–ç•¥çš„attention mask
- ç»ƒä¹ 5.3ï¼šå¯¹æ¯”static batchingå’Œcontinuous batchingçš„paddingæ•°é‡
- ç»ƒä¹ 5.4ï¼šï¼ˆè¿›é˜¶ï¼‰å®ç°ä¸€ä¸ªç®€å•çš„continuous batchingè°ƒåº¦å™¨

#### 5.7 vLLMæ¶æ„å…¨æ™¯ â­â­â­ 2025æ–°å¢

> **ğŸ’¡ æ¥æº**ï¼š[Berkeley EECS-2025-192 - Deconstructing vLLM](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2025/EECS-2025-192.pdf)
>
> **æ ¸å¿ƒä»·å€¼**ï¼šç³»ç»Ÿæ€§ç†è§£vLLMçš„ä¸‰å±‚æ¶æ„â€”â€”Interfaceã€Model Authoringã€Runtimeï¼Œä¸ºåç»­ç« èŠ‚é“ºå«æ¶æ„çŸ¥è¯†ã€‚
>
> **ä¸ºä»€ä¹ˆé‡è¦**ï¼š
> - ä»"ä¼šç”¨vLLM"åˆ°"ç†è§£vLLM"çš„å…³é”®è½¬å˜
> - è°ƒè¯•é—®é¢˜ã€æ€§èƒ½ä¼˜åŒ–ã€æ‰©å±•å¼€å‘çš„åŸºç¡€
> - ä¸ºç¬¬6ç« ï¼ˆKV Cacheï¼‰ã€ç¬¬7ç« ï¼ˆè°ƒåº¦ï¼‰ã€ç¬¬10ç« ï¼ˆéƒ¨ç½²ï¼‰é“ºå«

**5.7.1 vLLMçš„ä¸‰å±‚æ¶æ„**

- **Layer 1: Interfaces** ï¼ˆç”¨æˆ·äº¤äº’å±‚ï¼‰
  ```
  User Request â†’ OpenAI Server â†’ API Server â†’ LLMEngine
  ```

  - **LLMEngine**: æ ¸å¿ƒå¼•æ“
    - ä½œç”¨ï¼šåè°ƒæ‰€æœ‰ç»„ä»¶
    - èŒè´£ï¼šè¯·æ±‚ç®¡ç†ã€èµ„æºåˆ†é…ã€ç»“æœè¿”å›
    - æ¥å£ï¼š`generate()`, `encode()`

  - **API Server**: HTTPæœåŠ¡
    - ä½œç”¨ï¼šæä¾›REST API
    - èŒè´£ï¼šè¯·æ±‚è·¯ç”±ã€è®¤è¯ã€é™æµ
    - åè®®ï¼šHTTP/REST

  - **OpenAI-Compatible Server**: æ ‡å‡†æ¥å£
    - ä½œç”¨ï¼šå…¼å®¹OpenAI API
    - èŒè´£ï¼š`/v1/chat/completions`ç­‰æ¥å£
    - ä»·å€¼ï¼šé›¶ä»£ç è¿ç§»

- **Layer 2: Model Authoring** ï¼ˆæ¨¡å‹æŠ½è±¡å±‚ï¼‰
  ```
  LLMEngine â†’ ModelExecutor â†’ BlockManager + Scheduler
  ```

  - **ModelExecutor**: æ¨¡å‹æ‰§è¡Œå™¨
    - ä½œç”¨ï¼šæ‰§è¡Œæ¨¡å‹forward pass
    - æŠ½è±¡ï¼šæ”¯æŒä¸åŒæ¨¡å‹æ¶æ„
    - æ¥å£ï¼š`execute_model()`, `profile()`
    - è¯¦è§ï¼š10.6 Model Authoring

  - **BlockManager**: å†…å­˜å—ç®¡ç†
    - ä½œç”¨ï¼šç®¡ç†KV Cacheçš„physical blocks
    - èŒè´£ï¼šåˆ†é…ã€é‡Šæ”¾ã€è¿ç§»blocks
    - æŠ½è±¡ï¼šPhysical vs Logical blocks
    - è¯¦è§ï¼š6.3.2 PagedAttentionåŸç†

  - **Scheduler**: è¯·æ±‚è°ƒåº¦å™¨
    - ä½œç”¨ï¼šå†³å®šå“ªäº›è¯·æ±‚å¯ä»¥æ‰§è¡Œ
    - ç­–ç•¥ï¼šFIFOã€Priorityã€SJF
    - è¾“å‡ºï¼šScheduled requests
    - è¯¦è§ï¼š7.4 vLLMçš„è°ƒåº¦å™¨å®ç°

- **Layer 3: Runtime** ï¼ˆè¿è¡Œæ—¶å±‚ï¼‰
  ```
  Scheduler â†’ CacheEngine â†’ Worker (GPU)
  ```

  - **CacheEngine**: KVç¼“å­˜å¼•æ“
    - ä½œç”¨ï¼šç®¡ç†KV Cacheçš„ç‰©ç†å­˜å‚¨
    - æ•°æ®ç»“æ„ï¼šBlock table
    - åŠŸèƒ½ï¼šHash-based lookup
    - è¯¦è§ï¼š6.3.3 å†…å­˜ç®¡ç†æ·±åº¦å‰–æ

  - **Worker**: å·¥ä½œè¿›ç¨‹
    - ä½œç”¨ï¼šåœ¨GPUä¸Šæ‰§è¡Œè®¡ç®—
    - èŒè´£ï¼šæ¨¡å‹æ¨ç†ã€kernelæ‰§è¡Œ
    - é€šä¿¡ï¼šä¸ä¸»è¿›ç¨‹é€šä¿¡

**5.7.2 ç”¨æˆ·è¯·æ±‚çš„å®Œæ•´æµç¨‹**

- **æ­¥éª¤1ï¼šç”¨æˆ·å‘é€è¯·æ±‚**
  ```bash
  curl http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{"model": "llama2", "messages": [...]}'
  ```

- **æ­¥éª¤2ï¼šOpenAI Serveræ¥æ”¶**
  - è§£æè¯·æ±‚
  - éªŒè¯å‚æ•°
  - è½¬å‘ç»™API Server

- **æ­¥éª¤3ï¼šAPI Serverå¤„ç†**
  - è¯·æ±‚è·¯ç”±
  - é™æµæ£€æŸ¥
  - è°ƒç”¨LLMEngine.generate()

- **æ­¥éª¤4ï¼šLLMEngineè°ƒåº¦**
  - åˆ›å»ºè¯·æ±‚å¯¹è±¡
  - æäº¤ç»™Scheduler
  - ç­‰å¾…è°ƒåº¦ç»“æœ

- **æ­¥éª¤5ï¼šSchedulerå†³ç­–**
  - æ£€æŸ¥èµ„æºï¼ˆGPU memoryã€computeï¼‰
  - é€‰æ‹©å¯æ‰§è¡Œçš„è¯·æ±‚
  - è¿”å›scheduled requests

- **æ­¥éª¤6ï¼šModelExecutoræ‰§è¡Œ**
  - å‡†å¤‡input data
  - è°ƒç”¨Worker.execute_model()
  - ç­‰å¾…GPUè¿”å›ç»“æœ

- **æ­¥éª¤7ï¼šWorkeråœ¨GPUä¸Šæ‰§è¡Œ**
  - åŠ è½½æ¨¡å‹weights
  - æ‰§è¡ŒPagedAttention kernels
  - è¿”å›generated tokens

- **æ­¥éª¤8ï¼šç»“æœè¿”å›**
  - Worker â†’ ModelExecutor â†’ LLMEngine
  - LLMEngine â†’ API Server â†’ OpenAI Server
  - OpenAI Server â†’ ç”¨æˆ·

**5.7.3 æ¶æ„å›¾**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Layer 1: Interfaces               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  OpenAI Server  â†’  API Server  â†’  LLMEngine    â”‚
â”‚  (HTTP)            (REST)         (Core)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Layer 2: Model Authoring             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ModelExecutor  â†  Scheduler  â†  BlockManager   â”‚
â”‚  (Execution)      (Policy)       (Memory)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Layer 3: Runtime                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CacheEngine  â†’  Worker  â†’  GPU Kernels         â”‚
â”‚  (KV Cache)      (Compute)    (CUDA)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**5.7.4 ä¸åç»­ç« èŠ‚çš„å…³è”**

- **ç¬¬6ç«  KV Cacheä¼˜åŒ–**ï¼š
  - BlockManagerçš„è¯¦ç»†å®ç°ï¼ˆ6.3.2ï¼‰
  - CacheEngineçš„å†…å­˜ç®¡ç†ï¼ˆ6.3.3ï¼‰
  - PagedAttentionçš„æ ¸å¿ƒåˆ›æ–°ï¼ˆ6.3.2ï¼‰

- **ç¬¬7ç«  è¯·æ±‚è°ƒåº¦ç­–ç•¥**ï¼š
  - Schedulerçš„è°ƒåº¦ç®—æ³•ï¼ˆ7.4ï¼‰
  - Iteration-level schedulingï¼ˆ7.4.2ï¼‰
  - CPU overheadsåˆ†æï¼ˆ7.4.3ï¼‰

- **ç¬¬10ç«  ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²**ï¼š
  - Interfaceå±‚éƒ¨ç½²æ¨¡å¼ï¼ˆ10.2-10.4ï¼‰
  - Model Authoringå®æˆ˜ï¼ˆ10.6ï¼‰
  - æ€§èƒ½åˆ†æä¸è°ƒä¼˜ï¼ˆ10.5ï¼‰

**5.7.5 å®æˆ˜ï¼šå¯åŠ¨vLLMå¹¶è§‚å¯Ÿæ¶æ„**

- **å¯åŠ¨vLLM server**ï¼š
  ```bash
  vllm serve meta-llama/Llama-2-7b-hf \
    --port 8000 \
    --host 0.0.0.0
  ```

- **æŸ¥çœ‹å¯åŠ¨è¿‡ç¨‹**ï¼š
  ```
  INFO:     Started server process
  INFO:     Waiting for vLLM engine to initialize
  INFO:     Initializing an LLM engine with config
  INFO:     Loading model weights
  INFO:     GPU memory: 15.50 GB
  INFO:     Model loaded
  ```

- **å‘é€è¯·æ±‚**ï¼š
  ```bash
  curl http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
      "model": "meta-llama/Llama-2-7b-hf",
      "messages": [{"role": "user", "content": "Hello!"}]
    }'
  ```

**5.7.6 æ¶æ„ç†è§£æ£€æŸ¥ç‚¹**

- [ ] èƒ½è§£é‡ŠvLLMçš„ä¸‰å±‚æ¶æ„
- [ ] èƒ½æè¿°ç”¨æˆ·è¯·æ±‚çš„å®Œæ•´æµç¨‹ï¼ˆ8æ­¥éª¤ï¼‰
- [ ] ç†è§£LLMEngineã€ModelExecutorã€Workerçš„èŒè´£
- [ ] çŸ¥é“BlockManagerå’ŒSchedulerçš„ä½œç”¨
- [ ] ç†è§£PagedAttentionåœ¨æ¶æ„ä¸­çš„ä½ç½®

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ ¸å¿ƒæŠ€æœ¯ç¯‡ (Part 3: Core Techniques)

### ç¬¬6ç«  KV Cacheä¼˜åŒ–

> **ğŸ’° æˆæœ¬å½±å“**ï¼ˆåŸºäºè¡Œä¸šæ•°æ®ï¼‰
> - **æ˜¾å­˜èŠ‚çœ**ï¼šKV Cacheä¼˜åŒ–å¯å‡å°‘æ˜¾å­˜å ç”¨50-70%
> - **ååæå‡**ï¼šåœ¨åŒæ ·ç¡¬ä»¶ä¸Šå¯æœåŠ¡2-3å€æ›´å¤šç”¨æˆ·
> - **æˆæœ¬èŠ‚çœ**ï¼šå…¸å‹åœºæ™¯ä»$0.002/tokené™åˆ°$0.001/token

#### 6.1 Transformerå›é¡¾
- 6.1.1 æ³¨æ„åŠ›æœºåˆ¶åŸç†
- 6.1.2 Kã€Vã€Qæ˜¯ä»€ä¹ˆ
- 6.1.3 ä¸ºä»€ä¹ˆéœ€è¦ç¼“å­˜

#### 6.2 KV CacheåŸç†
- 6.2.1 ç”Ÿæˆè¿‡ç¨‹çš„é‡å¤è®¡ç®—é—®é¢˜
- 6.2.2 KV Cacheçš„æ ¸å¿ƒæ€æƒ³
- 6.2.3 å¦‚ä½•å‡å°‘è®¡ç®—é‡
- 6.2.4 å›¾è§£KV Cacheå·¥ä½œæµç¨‹

#### 6.3 KV Cacheå®ç°
- 6.3.1 æœ´ç´ å®ç°æ–¹å¼
- 6.3.2 PagedAttentionåŸç†ï¼ˆvLLMçš„æ ¸å¿ƒï¼‰âš¡ï¸ 2025æ·±åº¦æ‰©å±•

  > **ğŸ’¡ æ·±åº¦æ¥æº**ï¼š[Berkeley EECS-2025-192](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2025/EECS-2025-192.pdf)
  >
  > **æ ¸å¿ƒæ´å¯Ÿ**ï¼šPagedAttentionå€Ÿé‰´æ“ä½œç³»ç»Ÿçš„è™šæ‹Ÿå†…å­˜æœºåˆ¶ï¼Œå°†KV Cacheåˆ†æˆå›ºå®šå¤§å°çš„pagesï¼Œå®ç°é«˜æ•ˆçš„å†…å­˜ç®¡ç†ã€‚
  >
  > **ä¸ºä»€ä¹ˆé‡è¦**ï¼š
  > - vLLMæœ€æ ¸å¿ƒçš„åˆ›æ–°ï¼ˆè®ºæ–‡å¼•ç”¨2000+ï¼‰
  > - å†…å­˜åˆ©ç”¨ç‡ä»60-70%æå‡åˆ°90-95%
  > - Prefix Cachingçš„åº•å±‚åŸºç¡€

  **6.3.2.1 ä¼ ç»ŸKV Cacheçš„é—®é¢˜**

  - **è¿ç»­å†…å­˜åˆ†é…çš„ç¼ºé™·**ï¼š
    ```
    Request 1: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 1000 tokens â†’ è¿ç»­åˆ†é…1000 tokenç©ºé—´
    Request 2: [â–ˆâ–ˆâ–ˆâ–ˆ] 500 tokens â†’ è¿ç»­åˆ†é…500 tokenç©ºé—´
    Request 1å®Œæˆ â†’ é‡Šæ”¾1000 tokens
    Request 3éœ€è¦800 tokens â†’ æ— æ³•ä½¿ç”¨Request 1çš„ç©ºé—´ï¼ˆç¢ç‰‡åŒ–ï¼ï¼‰
    ```

  - **å†…å­˜ç¢ç‰‡åŒ–**ï¼š
    - **External fragmentation**: è¯·æ±‚ä¹‹é—´çš„å°ç©ºéš™æ— æ³•åˆ©ç”¨
      ```
      GPU Memory: [Req1: 1000][ç©ºéš™: 200][Req2: 500][ç©ºéš™: 300]
      Request 3éœ€è¦800 tokens â†’ å¤±è´¥ï¼ï¼ˆç©ºéš™ä¸å¤Ÿå¤§ï¼‰
      ```
    - **Internal fragmentation**: é¢„åˆ†é…çš„å›ºå®šå¤§å°å¯èƒ½æµªè´¹
      ```
      é¢„åˆ†é…2048 tokens â†’ å®é™…ä½¿ç”¨1000 tokens â†’ æµªè´¹1048 tokens
      ```

  - **é™æ€å†…å­˜åˆ†é…çš„é—®é¢˜**ï¼š
    - å¿…é¡»é¢„å…ˆçŸ¥é“æœ€å¤§batch sizeå’Œæœ€å¤§åºåˆ—é•¿åº¦
    - æ— æ³•åŠ¨æ€è°ƒæ•´å†…å­˜ä½¿ç”¨
    - GPUåˆ©ç”¨ç‡ä½ï¼ˆå¤§é‡å†…å­˜æµªè´¹ï¼‰

  **6.3.2.2 PagedAttentionçš„è®¾è®¡æ€æƒ³**

  - **çµæ„Ÿæ¥æºï¼šOSè™šæ‹Ÿå†…å­˜**
    ```
    OS Virtual Memory:  Pages (4KB) + Page Table
    vLLM KV Cache:      Blocks (16 tokens) + Block Table
    ```

  - **æ ¸å¿ƒæ¦‚å¿µ**ï¼š
    - **Logical blocks**: é€»è¾‘ä¸Šçš„è¿ç»­åºåˆ—ï¼ˆç”¨æˆ·è§†è§’ï¼‰
    - **Physical blocks**: GPUå†…å­˜ä¸­çš„å®é™…å—ï¼ˆç³»ç»Ÿè§†è§’ï¼‰
    - **Block table**: æ˜ å°„å…³ç³»ï¼ˆlogical â†’ physicalï¼‰

  - **å·¥ä½œåŸç†**ï¼š
    ```
    Request: [token1-16][token17-32][token33-48][...]
    Logical:  Block 0      Block 1       Block 2
    Physical: Block 15     Block 7       Block 23
             (åˆ†æ•£åœ¨ç‰©ç†å†…å­˜ä¸­ï¼Œä½†é€»è¾‘ä¸Šè¿ç»­)
    ```

  - **å…³é”®ä¼˜åŠ¿**ï¼š
    - ä¸éœ€è¦è¿ç»­å†…å­˜
    - ç‰©ç†blockså¯ä»¥åˆ†æ•£åœ¨GPUå†…å­˜ä»»æ„ä½ç½®
    - é€»è¾‘ä¸Šè¿ç»­ï¼Œç‰©ç†ä¸Šåˆ†æ•£

  **6.3.2.3 Block Allocationç­–ç•¥**

  - **é¢„åˆ†é…ç­–ç•¥**ï¼š
    ```python
    # vLLMçš„å¯åŠ¨æ—¶åˆ†é…
    def allocate_at_startup():
        # è®¡ç®—å¯ç”¨GPUå†…å­˜
        gpu_memory = get_gpu_memory()
        # é¢„åˆ†é…90%ç»™KV Cacheï¼ˆä¿ç•™10%ç»™æ¨¡å‹weightsï¼‰
        num_blocks = (gpu_memory * 0.9) / BLOCK_SIZE
        # åˆ›å»ºblock pool
        block_pool = BlockPool(num_blocks)
        return block_pool
    ```

  - **åŠ¨æ€åˆ†é…ç®—æ³•**ï¼š
    ```python
    def allocate_blocks(request, num_tokens):
        num_blocks = ceil(num_tokens / BLOCK_SIZE)  # 16 tokens/block
        for i in range(num_blocks):
            block = find_free_block()
            if block is None:
                # å†…å­˜ä¸è¶³ï¼Œè§¦å‘eviction
                trigger_eviction_policy()
                block = find_free_block()
            request.blocks.append(block)
        return request.blocks
    ```

  - **Blockçš„å¤§å°é€‰æ‹©**ï¼š
    - é»˜è®¤ï¼š16 tokens/block
    - ä¸ºä»€ä¹ˆæ˜¯16ï¼Ÿ
      - å¤ªå°ï¼ˆå¦‚8ï¼‰ï¼šblock tableå¤ªå¤§ï¼Œç®¡ç†å¼€é”€é«˜
      - å¤ªå¤§ï¼ˆå¦‚32ï¼‰ï¼šinternal fragmentationä¸¥é‡
      - 16æ˜¯ç»éªŒæœ€ä¼˜å€¼ï¼ˆå¹³è¡¡å¼€é”€å’Œæµªè´¹ï¼‰

  **6.3.2.4 Block Evictionç­–ç•¥**

  - **LRU (Least Recently Used)**ï¼š
    ```python
    class LRU_Eviction:
        def __init__(self):
            self.access_time = {}  # block_id â†’ timestamp

        def evict(self, num_blocks):
            # æŒ‰è®¿é—®æ—¶é—´æ’åº
            sorted_blocks = sorted(
                self.access_time.items(),
                key=lambda x: x[1]  # æŒ‰æ—¶é—´å‡åº
            )
            # é©±é€æœ€ä¹…æœªä½¿ç”¨çš„blocks
            return [block[0] for block in sorted_blocks[:num_blocks]]
    ```
    - é€‚ç”¨åœºæ™¯ï¼šå¤§å¤šæ•°è¯·æ±‚å…·æœ‰æ—¶é—´å±€éƒ¨æ€§
    - ä¼˜åŠ¿ï¼šç®€å•ï¼Œæœ‰æ•ˆ
    - åŠ£åŠ¿ï¼šä¸è€ƒè™‘è®¿é—®é¢‘ç‡

  - **LFU (Least Frequently Used)**ï¼š
    ```python
    class LFU_Eviction:
        def __init__(self):
            self.access_count = {}  # block_id â†’ count

        def evict(self, num_blocks):
            # æŒ‰è®¿é—®é¢‘ç‡æ’åº
            sorted_blocks = sorted(
                self.access_count.items(),
                key=lambda x: x[1]  # æŒ‰é¢‘ç‡å‡åº
            )
            # é©±é€è®¿é—®é¢‘ç‡æœ€ä½çš„blocks
            return [block[0] for block in sorted_blocks[:num_blocks]]
    ```
    - é€‚ç”¨åœºæ™¯ï¼šæŸäº›prefixè¢«é¢‘ç¹å¤ç”¨ï¼ˆå¦‚ç³»ç»Ÿæç¤ºè¯ï¼‰
    - ä¼˜åŠ¿ï¼šä¿ç•™çƒ­ç‚¹æ•°æ®
    - åŠ£åŠ¿ï¼šå†·å¯åŠ¨æ—¶æ•ˆæœå·®

  - **vLLMçš„æ··åˆç­–ç•¥**ï¼š
    ```python
    class HybridEviction:
        def evict(self, num_blocks):
            # Prefix cache blocks: ä½¿ç”¨LFU
            # ï¼ˆç³»ç»Ÿæç¤ºè¯ç­‰ï¼Œè¢«é¢‘ç¹å¤ç”¨ï¼‰
            prefix_blocks = self.get_prefix_blocks()
            prefix_evict = lfu_evict(prefix_blocks, num_blocks // 2)

            # Decode blocks: ä½¿ç”¨LRU
            # ï¼ˆæ–°ç”Ÿæˆçš„tokensï¼Œæ—¶é—´å±€éƒ¨æ€§ï¼‰
            decode_blocks = self.get_decode_blocks()
            decode_evict = lru_evict(decode_blocks, num_blocks // 2)

            return prefix_evict + decode_evict
    ```
    - ä¼˜åŠ¿ï¼šå…¼é¡¾cache hit rateå’Œå†…å­˜æ•ˆç‡
    - ç»“æœï¼šä¼˜äºå•ä¸€ç­–ç•¥

  **6.3.2.5 Memory Managerå®ç°**

  - **CacheEngineçš„æ ¸å¿ƒèŒè´£**ï¼š
    ```python
    class CacheEngine:
        def __init__(self, block_size, num_gpu_blocks):
            self.block_size = block_size  # 16 tokens
            self.num_gpu_blocks = num_gpu_blocks
            self.free_blocks = set(range(num_gpu_blocks))
            self.block_table = {}  # {request_id: [block_ids]}
            self.hash_table = {}  # {block_hash: block_id}  # For prefix caching

        def allocate(self, request_id, num_blocks):
            """åˆ†é…blocksç»™è¯·æ±‚"""
            if len(self.free_blocks) < num_blocks:
                raise OutOfMemory(f"Need {num_blocks}, "
                                f"only {len(self.free_blocks)} free")
            blocks = list(self.free_blocks)[:num_blocks]
            self.free_blocks.difference_update(blocks)
            self.block_table[request_id] = blocks
            return blocks

        def free(self, request_id):
            """é‡Šæ”¾è¯·æ±‚çš„blocks"""
            blocks = self.block_table.pop(request_id)
            self.free_blocks.update(blocks)

        def get_block_hash(self, block_id):
            """è®¡ç®—blockçš„hashï¼ˆç”¨äºprefix cachingï¼‰"""
            block_data = self.get_block_data(block_id)
            # ä½¿ç”¨SHA256æˆ–è‡ªå®šä¹‰å¿«é€Ÿhash
            return hash(block_data.tobytes())

        def check_prefix_cache(self, request_id, block_hashes):
            """æ£€æŸ¥prefix cache hit"""
            cached_blocks = []
            for h in block_hashes:
                if h in self.hash_table:
                    cached_blocks.append(self.hash_table[h])
                else:
                    break  # ç¬¬ä¸€ä¸ªmissï¼Œåç»­æ— æ³•ä½¿ç”¨
            return cached_blocks
    ```

  **6.3.2.6 PagedAttention vs ä¼ ç»Ÿæ–¹æ¡ˆå¯¹æ¯”**

  | ç»´åº¦ | è¿ç»­å†…å­˜ | PagedAttention |
  |------|---------|----------------|
  | **å†…å­˜åˆ©ç”¨ç‡** | 60-70% | 90-95% |
  | **ç¢ç‰‡åŒ–** | ä¸¥é‡ | è½»å¾® |
  | **Prefix Caching** | å›°éš¾ | å®¹æ˜“ï¼ˆhash-basedï¼‰ |
  | **å®ç°å¤æ‚åº¦** | ç®€å• | ä¸­ç­‰ |
  | **æ€§èƒ½å¼€é”€** | æ—  | è½»å¾®ï¼ˆblock table lookupï¼‰ |
  | **é€‚ç”¨åœºæ™¯** | å•è¯·æ±‚ã€çŸ­åºåˆ— | å¤šè¯·æ±‚ã€é•¿åºåˆ—ã€ç”Ÿäº§ç¯å¢ƒ |

  - **æ€§èƒ½å¼€é”€åˆ†æ**ï¼š
    - Block table lookup: O(1) hash table
    - é¢å¤–å†…å­˜: block_table (æ¯ä¸ªè¯·æ±‚~1KB)
    - ç›¸æ¯”æ”¶ç›Šï¼ˆ+30%å†…å­˜åˆ©ç”¨ç‡ï¼‰ï¼Œå¼€é”€å¯å¿½ç•¥

  **6.3.2.7 çœŸå®æ¡ˆä¾‹åˆ†æ**

  - **æ¡ˆä¾‹1ï¼šChatGPTé£æ ¼å¯¹è¯**
    ```
    ç³»ç»Ÿæç¤ºè¯ï¼š500 tokensï¼ˆ"You are a helpful assistant..."ï¼‰
    ç”¨æˆ·è¾“å…¥ï¼š50 tokens
    æ¨¡å‹è¾“å‡ºï¼š100 tokens

    ä¼ ç»Ÿæ–¹æ³•ï¼š
      - æ¯ä¸ªè¯·æ±‚éœ€è¦650 tokensè¿ç»­ç©ºé—´
      - ç³»ç»Ÿæç¤ºè¯æ¯æ¬¡é‡æ–°è®¡ç®—
      - å†…å­˜åˆ©ç”¨ç‡ï¼š~65%

    PagedAttention + Prefix Cachingï¼š
      - ç³»ç»Ÿæç¤ºè¯ï¼š32 blocks (cached)
      - 100ä¸ªè¯·æ±‚å…±äº«è¿™32ä¸ªblocks
      - æ¯ä¸ªè¯·æ±‚åªéœ€è¦: ç”¨æˆ·è¾“å…¥4 blocks + è¾“å‡º7 blocks
      - å†…å­˜åˆ©ç”¨ç‡ï¼š~92%
    ```

  - **æ¡ˆä¾‹2ï¼šé•¿æ–‡æ¡£æ‘˜è¦**
    ```
    è¾“å…¥æ–‡æ¡£ï¼š100K tokens
    Blockæ•°é‡ï¼š100000 / 16 = 6250 blocks

    ä¼ ç»Ÿæ–¹æ³•ï¼š
      - éœ€è¦è¿ç»­100K tokenç©ºé—´ï¼ˆ~200MBï¼‰
      - å¾ˆéš¾åˆ†é…ï¼ˆGPUç¢ç‰‡åŒ–ï¼‰
      - ç»“æœï¼šOut of Memory

    PagedAttentionï¼š
      - åŠ¨æ€åˆ†é…6250ä¸ªblocks
      - ä¸éœ€è¦è¿ç»­å†…å­˜
      - å¯ä»¥åˆ†æ•£åœ¨GPUå„å¤„
      - ç»“æœï¼šæˆåŠŸæ‰§è¡Œ
    ```

  - **æ¡ˆä¾‹3ï¼šRAGåœºæ™¯**
    ```
    å›ºå®šçŸ¥è¯†åº“prefixï¼š2000 tokensï¼ˆ125 blocksï¼‰
    ç”¨æˆ·é—®é¢˜ï¼š50 tokensï¼ˆ4 blocksï¼‰

    Cache hit rateåˆ†æï¼š
      - 100ä¸ªè¯·æ±‚ï¼Œ99ä¸ªå…±äº«çŸ¥è¯†åº“blocks
      - Hit rate: 99 / 100 = 99%
      - èŠ‚çœè®¡ç®—: 99 * 125 blocks = 12375 blocks
      - åŠ é€Ÿæ¯”: (2000+50) / 50 = 41å€
    ```

  **6.3.2.8 å®æˆ˜é…ç½®**

  ```python
  from vllm import LLM, SamplingParams

  llm = LLM(
      model="meta-llama/Llama-2-7b-hf",

      # === Blockç›¸å…³é…ç½® ===
      block_size=16,  # æ¯ä¸ªblockçš„tokenæ•°ï¼ˆé»˜è®¤16ï¼Œé€šå¸¸ä¸éœ€ä¿®æ”¹ï¼‰

      # === Memoryç›¸å…³é…ç½® ===
      gpu_memory_utilization=0.9,  # GPUæ˜¾å­˜åˆ©ç”¨ç‡ï¼ˆ0.9 = 90%ï¼‰
      # 10%ç•™ç»™æ¨¡å‹weightså’ŒCUDA kernels
      # 90%ç”¨äºKV Cache blocks

      # === Prefix Caching ===
      enable_prefix_caching=True,  # å¯ç”¨prefix cachingï¼ˆé‡è¦ï¼ï¼‰

      # === è‡ªåŠ¨è®¡ç®— ===
      # vLLMä¼šè‡ªåŠ¨è®¡ç®—ï¼š
      # num_gpu_blocks = (gpu_memory * 0.9) / block_size
  )

  # ç”Ÿæˆ
  prompts = ["Hello, my name is", "Hello, my name is Bob"]
  sampling_params = SamplingParams(temperature=0.7, max_tokens=20)
  outputs = llm.generate(prompts, sampling_params)

  # ç¬¬äºŒä¸ªè¯·æ±‚ä¼šå¤ç”¨ç¬¬ä¸€ä¸ªè¯·æ±‚çš„prefix cacheï¼
  ```

  **6.3.2.9 æ€§èƒ½ç›‘æ§**

  ```python
  # æŸ¥çœ‹blockä½¿ç”¨æƒ…å†µ
  from vllm import LLM

  llm = LLM(model="...")

  # è·å–Cache Engine
  cache_engine = llm.llm_engine.cache_engine

  # æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
  print(f"Total blocks: {cache_engine.num_gpu_blocks}")
  print(f"Free blocks: {len(cache_engine.free_blocks)}")
  print(f"Used blocks: {cache_engine.num_gpu_blocks - len(cache_engine.free_blocks)}")
  print(f"Utilization: {(cache_engine.num_gpu_blocks - len(cache_engine.free_blocks)) / cache_engine.num_gpu_blocks * 100:.1f}%")

  # æŸ¥çœ‹prefix cacheç»Ÿè®¡
  if hasattr(cache_engine, 'cache_hash'):
      print(f"Prefix cache hits: {cache_engine.cache_hits}")
      print(f"Prefix cache misses: {cache_engine.cache_misses}")
      print(f"Hit rate: {cache_engine.cache_hits / (cache_engine.cache_hits + cache_engine.cache_misses) * 100:.1f}%")
  ```

  **6.3.2.10 æ€»ç»“ï¼šPagedAttentionçš„æ ¸å¿ƒä»·å€¼**

  - **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**ï¼š
    - âœ… å†…å­˜ç¢ç‰‡åŒ–
    - âœ… é™æ€å†…å­˜åˆ†é…çš„çµæ´»æ€§
    - âœ… Prefix cachingçš„å®ç°åŸºç¡€

  - **å…³é”®æŒ‡æ ‡**ï¼š
    - å†…å­˜åˆ©ç”¨ç‡ï¼š60-70% â†’ 90-95% (+30%)
    - Prefix cache hit rate: å¯è¾¾99% (RAGåœºæ™¯)
    - ååé‡æå‡ï¼š2-5å€ (ChatGPTé£æ ¼å¯¹è¯)

  - **é€‚ç”¨åœºæ™¯**ï¼š
    - âœ… å¤šç”¨æˆ·å¹¶å‘
    - âœ… é•¿åºåˆ—
    - âœ… é‡å¤prefixï¼ˆç³»ç»Ÿæç¤ºè¯ã€RAGï¼‰
    - âœ… ç”Ÿäº§ç¯å¢ƒ

- 6.3.3 å†…å­˜ç®¡ç†ç­–ç•¥
- 6.3.4 Radix Attention (SGLang/Mini-SGLang) âš¡ï¸ 2025æ–°å¢

  > **ğŸ’¡ æ·±åº¦æ¥æº**ï¼š[Mini-SGLang Blog](https://lmsys.org/blog/2025-12-17-minisgl/)
  >
  > **æ ¸å¿ƒä»·å€¼**ï¼šPagedAttentionçš„ç«äº‰å¯¹æ‰‹ï¼Œå¦ä¸€ç§KV Cacheå¤ç”¨æ–¹æ¡ˆ
  >
  > **å…³é”®å·®å¼‚**ï¼šRadix Treeç»“æ„ vs å›ºå®šBlockç²’åº¦

  **6.3.4.1 Radix Cache vs PagedAttention**

  | ç»´åº¦ | PagedAttention (vLLM) | Radix Cache (SGLang/Mini-SGLang) |
  |------|----------------------|----------------------------------|
  | **æ€æƒ³æ¥æº** | OSè™šæ‹Ÿå†…å­˜ï¼ˆåˆ†é¡µï¼‰ | Radix Treeå‰ç¼€æ ‘ |
  | **ç²’åº¦** | å›ºå®šBlock (16 tokens) | å¯å˜é•¿åº¦ï¼ˆè‡ªåŠ¨æ£€æµ‹å…±äº«å‰ç¼€ï¼‰ |
  | **æ£€æµ‹æ–¹å¼** | éœ€è¦æ˜¾å¼é…ç½®Prefix Caching | è‡ªåŠ¨æ£€æµ‹å…±äº«å‰ç¼€ |
  | **å†…å­˜ç»„ç»‡** | Logical â†’ Physicalæ˜ å°„ | æ ‘çŠ¶å±‚æ¬¡ç»“æ„ |
  | **é€‚ç”¨åœºæ™¯** | å¤šç§Ÿæˆ·ã€é€šç”¨åœºæ™¯ | Agent/RAGåœºæ™¯ï¼ˆå¤§é‡å…±äº«prefixï¼‰ |
  | **å®ç°å¤æ‚åº¦** | ä¸­ç­‰ï¼ˆéœ€hash tableï¼‰ | è¾ƒé«˜ï¼ˆéœ€æ ‘ç»´æŠ¤ï¼‰ |
  | **ä»£ç è§„æ¨¡** | vLLMå…¨æ¡†æ¶ | Mini-SGLangä»…5kè¡ŒPython |

  **6.3.4.2 Radix Treeç»“æ„**

  - **æ ¸å¿ƒæ¦‚å¿µ**ï¼š
    - å°†promptsç»„ç»‡æˆæ ‘çŠ¶ç»“æ„
    - å…±äº«å‰ç¼€çš„promptså…±äº«KV Cache
    - ç±»ä¼¼å­—ç¬¦ä¸²åŒ¹é…çš„Trieæ ‘

  - **ç¤ºä¾‹**ï¼š
    ```
    Prompt A: "è§£é‡Šé‡å­è®¡ç®—çš„åŸºæœ¬åŸç†"
    Prompt B: "è§£é‡Šé‡å­è®¡ç®—çš„é‡å­çº ç¼ "
    Prompt C: "è§£é‡Šé‡å­è®¡ç®—çš„å†å²å‘å±•"

    Radix Tree:
    Root
     â””â”€ "è§£é‡Šé‡å­è®¡ç®—" [å…±äº«å‰ç¼€ï¼Œåªè®¡ç®—ä¸€æ¬¡ï¼]
         â”œâ”€ "çš„åŸºæœ¬åŸç†" [Prompt Açš„uniqueéƒ¨åˆ†]
         â”œâ”€ "çš„é‡å­çº ç¼ " [Prompt Bçš„uniqueéƒ¨åˆ†]
         â””â”€ "çš„å†å²å‘å±•" [Prompt Cçš„uniqueéƒ¨åˆ†]
    ```

  - **ä¼˜åŠ¿**ï¼š
    - è‡ªåŠ¨æ£€æµ‹å…±äº«å‰ç¼€ï¼ˆæ— éœ€æ‰‹åŠ¨é…ç½®ï¼‰
    - å¯å˜ç²’åº¦ï¼ˆæ¯”å›ºå®š16 tokensæ›´çµæ´»ï¼‰
    - åœ¨Agent/RAGåœºæ™¯ä¸­æ•ˆç‡æé«˜

  **6.3.4.3 å…±äº«å‰ç¼€æ£€æµ‹ç®—æ³•**

  - **ç®—æ³•æµç¨‹**ï¼š
    ```python
    class RadixCache:
        def __init__(self):
            self.radix_tree = RadixTree()  # å‰ç¼€æ ‘
            self.node_cache = {}  # {node_id: KV Cache}

        def allocate(self, request_tokens):
            # 1. åœ¨æ ‘ä¸­æŸ¥æ‰¾æœ€é•¿åŒ¹é…å‰ç¼€
            prefix_node, match_length = self.radix_tree.find_longest_prefix(
                request_tokens
            )

            # 2. å¦‚æœæ‰¾åˆ°å‰ç¼€ï¼Œå¤ç”¨å…¶KV Cache
            if prefix_node:
                request.kv_cache = prefix_node.cache
                remaining_tokens = request_tokens[match_length:]
            else:
                remaining_tokens = request_tokens

            # 3. è®¡ç®—å‰©ä½™tokensçš„KV
            if remaining_tokens:
                new_cache = self.compute_kv(remaining_tokens)
                request.kv_cache.extend(new_cache)

                # 4. æ›´æ–°Radix Tree
                self.radix_tree.insert(request_tokens, request.kv_cache)

            return request.kv_cache

        def find_longest_prefix(self, tokens):
            """åœ¨æ ‘ä¸­æŸ¥æ‰¾æœ€é•¿åŒ¹é…å‰ç¼€"""
            current = self.root
            match_length = 0

            for token in tokens:
                if token in current.children:
                    current = current.children[token]
                    match_length += 1
                else:
                    break

            return current, match_length
    ```

  - **å…³é”®ç‚¹**ï¼š
    - è‡ªåŠ¨æ£€æµ‹ï¼šæ— éœ€æ‰‹åŠ¨æŒ‡å®šå“ªäº›promptså…±äº«
    - æœ€é•¿åŒ¹é…ï¼šæ‰¾åˆ°æœ€å¤§çš„å…±äº«å‰ç¼€
    - å¢é‡æ›´æ–°ï¼šæ–°promptè‡ªåŠ¨æ·»åŠ åˆ°æ ‘ä¸­

  **6.3.4.4 æ€§èƒ½å¯¹æ¯”ï¼ˆå®æˆ˜æ•°æ®ï¼‰**

  - **RAGåœºæ™¯**ï¼ˆMini-SGLangå®æµ‹ï¼‰ï¼š
    - åœºæ™¯ï¼šç³»ç»Ÿæç¤ºè¯1000 tokens + ç”¨æˆ·æŸ¥è¯¢20 tokens
    - Radix Cacheå‘½ä¸­ç‡ï¼š> 95%
    - æ€§èƒ½æå‡ï¼šçœå»95%çš„prefillè®¡ç®—

  - **Agentåœºæ™¯**ï¼ˆManuså®æˆ˜æ•°æ®ï¼‰ï¼š
    - åœºæ™¯ï¼š50æ­¥tool callsï¼Œæ¯æ­¥å…±äº«ä¹‹å‰æ‰€æœ‰context
    - Radix Cacheä¼˜åŠ¿ï¼šè‡ªåŠ¨æ£€æµ‹å…±äº«çš„action history
    - Cache hit rateï¼š80-90%

  - **vs PagedAttention**ï¼š
    - **PagedAttention**ï¼š
      - ä¼˜åŠ¿ï¼šæˆç†Ÿç¨³å®šï¼ŒvLLMç”Ÿäº§éªŒè¯
      - é€‚ç”¨ï¼šé€šç”¨åœºæ™¯ï¼Œå¤šç§Ÿæˆ·
      - ç¼ºç‚¹ï¼šéœ€è¦æ˜¾å¼é…ç½®prefix caching

    - **Radix Cache**ï¼š
      - ä¼˜åŠ¿ï¼šè‡ªåŠ¨æ£€æµ‹ï¼ŒAgent/RAGåœºæ™¯æ›´é«˜æ•ˆ
      - é€‚ç”¨ï¼šå¤§é‡å…±äº«prefixçš„åœºæ™¯
      - ç¼ºç‚¹ï¼šæ ‘ç»´æŠ¤å¤æ‚åº¦ç¨é«˜

  **6.3.4.5 Mini-SGLang 5kè¡Œå®ç°ç²¾è¦**

  - **ä»£ç ç»“æ„**ï¼ˆä»…5kè¡ŒPythonï¼ï¼‰ï¼š
    ```
    mini-sglang/
    â”œâ”€â”€ server.py          # å‰ç«¯API server (OpenAIå…¼å®¹)
    â”œâ”€â”€ tokenizer.py       # åˆ†è¯å™¨æœåŠ¡
    â”œâ”€â”€ scheduler.py       # è°ƒåº¦å™¨ï¼ˆå«overlap schedulingï¼‰
    â”œâ”€â”€ radix_cache.py     # Radix Cacheå®ç°
    â”œâ”€â”€ model_runner.py    # æ¨¡å‹æ‰§è¡Œï¼ˆTPæ”¯æŒï¼‰
    â””â”€â”€ kernels/           # JIT CUDA kernels
        â”œâ”€â”€ flashattention.py
        â””â”€â”€ flashinfer.py
    ```

  - **æ¨èé˜…è¯»é¡ºåº**ï¼ˆå­¦ä¹ è·¯å¾„ï¼‰ï¼š
    1. `server.py` â†’ ç†è§£æ•´ä½“æ¶æ„
    2. `scheduler.py` â†’ å­¦ä¹ Overlap Scheduling
    3. `radix_cache.py` â†’ ç†è§£Radix Cache
    4. `model_runner.py` â†’ äº†è§£Tensor Parallelism

  - **å­¦ä¹ ä»·å€¼**ï¼š
    - æ¯”vLLM (300k+è¡Œ)ç®€å•60å€
    - åŒ…å«æ‰€æœ‰ç°ä»£ä¼˜åŒ–ï¼ˆRadix Cache, Overlap Scheduling, TPï¼‰
    - é€‚åˆå¿«é€ŸåŸå‹å’Œç ”ç©¶éªŒè¯

  **6.3.4.6 å®æˆ˜ï¼šMini-SGLang vs vLLMå¯¹æ¯”**

  - **å¯åŠ¨Mini-SGLang**ï¼š
    ```bash
    # å®‰è£…
    pip install mini-sglang

    # å¯åŠ¨server
    python -m minisgl \
      --model "Qwen/Qwen3-32B" \
      --tp 4 \  # 4-way tensor parallelism
      --cache radix  # ä½¿ç”¨Radix Cache

    # å‘é€è¯·æ±‚ï¼ˆOpenAIå…¼å®¹ï¼‰
    curl http://localhost:8000/v1/chat/completions \
      -H "Content-Type: application/json" \
      -d '{
        "model": "Qwen/Qwen3-32B",
        "messages": [{"role": "user", "content": "Hello!"}]
      }'
    ```

  - **å¯¹æ¯”vLLM**ï¼š
    ```bash
    # vLLMå¯åŠ¨
    vllm serve "Qwen/Qwen3-32B" \
      --tensor-parallel-size 4 \
      --enable-prefix-caching

    # æ€§èƒ½å¯¹æ¯”ï¼ˆAgentåœºæ™¯ï¼‰ï¼š
    # - Radix Cache: è‡ªåŠ¨æ£€æµ‹å…±äº«å‰ç¼€
    # - PagedAttention: éœ€è¦æ˜¾å¼é…ç½®
    # ç»“æœï¼šMini-SGLangåœ¨Agentåœºæ™¯ä¸­ååé‡æå‡20-30%
    ```

  **6.3.4.7 æ€»ç»“ï¼šä½•æ—¶é€‰æ‹©Radix Cacheï¼Ÿ**

  - **é€‰æ‹©Radix Cache (SGLang/Mini-SGLang)**ï¼š
    - âœ… Agentç³»ç»Ÿï¼ˆå¤§é‡tool callså…±äº«contextï¼‰
    - âœ… RAGç³»ç»Ÿï¼ˆå›ºå®šçŸ¥è¯†prefixï¼‰
    - âœ… å¤šè½®å¯¹è¯ï¼ˆå…±äº«å†å²contextï¼‰
    - âœ… ç ”ç©¶åŸå‹ï¼ˆä»£ç ç®€æ´ï¼Œæ˜“äºä¿®æ”¹ï¼‰

  - **é€‰æ‹©PagedAttention (vLLM)**ï¼š
    - âœ… é€šç”¨Chatbotåœºæ™¯
    - âœ… å¤šç§Ÿæˆ·SaaSå¹³å°
    - âœ… ç”Ÿäº§ç¯å¢ƒï¼ˆæˆç†Ÿç¨³å®šï¼‰
    - âœ… å›¢é˜Ÿç†Ÿæ‚‰vLLMç”Ÿæ€

  - **ä¸¤è€…éƒ½æ”¯æŒ**ï¼š
    - Prefix caching
    - KV Cacheå¤ç”¨
    - é«˜ååé‡

#### 6.4 KV Cacheä¼˜åŒ–æŠ€æœ¯
- 6.4.1 Multi-Query Attention vs Multi-Head Attention
- 6.4.2 Grouped-Query Attention (GQA)
- 6.4.3 Shared KV Cache
- 6.4.4 é‡åŒ–KV Cache

#### 6.5 KV Cacheçš„ä»£ä»·
- 6.5.1 æ˜¾å­˜å ç”¨åˆ†æ
- 6.5.2 åºåˆ—é•¿åº¦é™åˆ¶
- 6.5.3 æƒè¡¡ï¼šè®¡ç®—vsæ˜¾å­˜

#### 6.6 å®æˆ˜å¯¹æ¯”
- 6.6.1 æ— KV Cache vs æœ‰KV Cache
- 6.6.2 æ€§èƒ½æå‡é‡åŒ–åˆ†æ
- 6.6.3 vLLMçš„KV Cacheå®ç°

#### 6.7 Prefix Caching â­â­â­

> **ğŸ’¡ æ ¸å¿ƒæ´å¯Ÿ**ï¼šé‡å¤çš„promptï¼ˆå¦‚ç³»ç»Ÿæç¤ºè¯ï¼‰åªéœ€è¦è®¡ç®—ä¸€æ¬¡ï¼Œåç»­è¯·æ±‚ç›´æ¥å¤ç”¨KV Cacheã€‚
> **ğŸ¯ æ€§èƒ½æå‡**ï¼šChatGPTé£æ ¼å¯¹è¯åœºæ™¯å¯æå‡2-5å€ååé‡ã€‚
> **æ¥æº**ï¼švLLMæ ¸å¿ƒç‰¹æ€§ä¹‹ä¸€ï¼Œå·²åœ¨ç”Ÿäº§ç¯å¢ƒå¤§è§„æ¨¡éªŒè¯ã€‚

- 6.7.1 ä»€ä¹ˆæ˜¯Prefix Caching
  - **å®šä¹‰**ï¼šè·¨è¯·æ±‚å¤ç”¨ç›¸åŒpromptçš„KV Cache
  - **æ ¸å¿ƒé—®é¢˜**ï¼šé‡å¤promptçš„è®¡ç®—æµªè´¹
  - **å…¸å‹åœºæ™¯**ï¼š
    - ç³»ç»Ÿæç¤ºè¯ï¼ˆ"You are a helpful assistant..."ï¼‰
    - å¤šè½®å¯¹è¯çš„ä¸Šä¸‹æ–‡
    - RAGåœºæ™¯çš„å›ºå®šçŸ¥è¯†prefix
  - **ä¸ºä»€ä¹ˆå«"Prefix"**ï¼š
    - Cacheçš„æ˜¯promptéƒ¨åˆ†ï¼ˆå³åºåˆ—çš„prefixï¼‰
    - ç”Ÿæˆçš„éƒ¨åˆ†ï¼ˆdecodeé˜¶æ®µï¼‰å› äººè€Œå¼‚ï¼Œæ— æ³•å¤ç”¨

- 6.7.2 Prefix Cachingçš„æ ¸å¿ƒæ€æƒ³
  - **ä¼ ç»ŸKV Cache**ï¼šå•æ¬¡è¯·æ±‚å†…å¤ç”¨
    - Token 0çš„KVè¢«token 1, 2, 3...å¤ç”¨
    - ä½†è¯·æ±‚ç»“æŸåï¼ŒCacheè¢«æ¸…ç©º
  - **Prefix Caching**ï¼šè·¨è¯·æ±‚å¤ç”¨
    - è¯·æ±‚1ï¼šè®¡ç®—å®Œæ•´promptçš„KV â†’ Cache
    - è¯·æ±‚2ï¼šæ£€æµ‹åˆ°ç›¸åŒprefix â†’ ç›´æ¥å¤ç”¨ â†’ è·³è¿‡è®¡ç®—
    - è¯·æ±‚3ã€4ã€5...ï¼šåŒè¯·æ±‚2
  - **ç±»æ¯”**ï¼š
    - ä¼ ç»ŸCacheï¼šå‡½æ•°å†…çš„memoization
    - Prefix Cachingï¼šå…¨å±€distributed cacheï¼ˆå¦‚Redisï¼‰

- 6.7.3 vLLMçš„å®ç°ï¼šHash-based KV Cache
  - **æŒ‘æˆ˜**ï¼šå¦‚ä½•æ£€æµ‹ä¸¤ä¸ªè¯·æ±‚çš„prefixæ˜¯å¦ç›¸åŒï¼Ÿ
  - **æ–¹æ¡ˆ1ï¼šå­—ç¬¦ä¸²æ¯”è¾ƒ**ï¼ˆNaiveï¼‰
    - æ¯æ¬¡æ¯”è¾ƒpromptæ–‡æœ¬
    - é—®é¢˜ï¼šæ…¢ï¼è€Œä¸”è¯­ä¹‰ç›¸åŒçš„tokenå¯èƒ½æ¥è‡ªä¸åŒæ–‡æœ¬
  - **æ–¹æ¡ˆ2ï¼švLLMçš„Hash-basedæ–¹æ³•** â­
    - å¯¹æ¯ä¸ªBlockçš„KV Cacheè®¡ç®—Hash
    - Hashç›¸åŒçš„Blockè¢«è®¤ä¸ºå†…å®¹ç›¸åŒ
    - **Hashç®—æ³•**ï¼š
      - è¾“å…¥ï¼šBlockçš„KV tensor
      - è¾“å‡ºï¼šå›ºå®šé•¿åº¦çš„hashå€¼
      - å®ç°ï¼šSHA256æˆ–è‡ªå®šä¹‰å¿«é€Ÿhash
  - **Cache Hitæ£€æµ‹æµç¨‹**ï¼š
    1. æ–°è¯·æ±‚åˆ°æ¥
    2. è®¡ç®—prompt tokenså¯¹åº”çš„logical blocks
    3. æŸ¥è¯¢hash tableï¼šæ˜¯å¦å·²æœ‰è¿™äº›blocksçš„KVï¼Ÿ
    4. å¦‚æœhitï¼šç›´æ¥å¼•ç”¨å·²æœ‰physical blocks
    5. å¦‚æœmissï¼šåˆ†é…æ–°çš„physical blockså¹¶è®¡ç®—

- 6.7.4 Prefix Cachingçš„å·¥ä½œæµç¨‹
  - **é¦–æ¬¡è¯·æ±‚ï¼ˆCold Pathï¼‰**ï¼š
    1. ç”¨æˆ·å‘é€promptï¼ˆå«ç³»ç»Ÿæç¤ºè¯ï¼‰
    2. vLLMè®¡ç®—æ‰€æœ‰tokensçš„KV Cache
    3. å°†KV Cacheåˆ†æˆblocksï¼Œè®¡ç®—æ¯ä¸ªblockçš„hash
    4. å­˜å‚¨åˆ°cache engineï¼ˆhash tableï¼‰
    5. è¿”å›ç»“æœ
  - **åç»­è¯·æ±‚ï¼ˆWarm Pathï¼‰**ï¼š
    1. ç”¨æˆ·å‘é€ç›¸åŒç³»ç»Ÿæç¤ºè¯çš„æ–°è¯·æ±‚
    2. vLLMè®¡ç®—blocksçš„hash
    3. **Cache Hitï¼**ï¼šå‘ç°å·²æœ‰å¯¹åº”çš„KV Cache
    4. ç›´æ¥å¼•ç”¨å·²æœ‰blocksï¼Œè·³è¿‡prefillè®¡ç®—
    5. åªéœ€è®¡ç®—ç”¨æˆ·è¾“å…¥çš„æ–°tokens
    6. è¿”å›ç»“æœï¼ˆå¿«å¾—å¤šï¼ï¼‰
  - **éƒ¨åˆ†Hitåœºæ™¯**ï¼š
    - ç³»ç»Ÿæç¤ºè¯hitï¼Œç”¨æˆ·è¾“å…¥miss
    - å¤ç”¨ç³»ç»Ÿæç¤ºè¯çš„KVï¼Œåªè®¡ç®—ç”¨æˆ·è¾“å…¥éƒ¨åˆ†

- 6.7.5 æ€§èƒ½æå‡åˆ†æ
  - **ç†è®ºåŠ é€Ÿæ¯”**ï¼š
    - å‡è®¾ç³»ç»Ÿæç¤ºè¯é•¿åº¦ = P tokens
    - ç”¨æˆ·è¾“å…¥é•¿åº¦ = U tokens
    - æ— Prefix Cachingï¼šæ¯æ¬¡è®¡ç®—P+U
    - æœ‰Prefix Cachingï¼šé¦–æ¬¡P+Uï¼Œåç»­åªéœ€U
    - åŠ é€Ÿæ¯” â‰ˆ (P+U) / U = 1 + P/U
  - **å®é™…æ¡ˆä¾‹**ï¼š
    - åœºæ™¯1ï¼šç³»ç»Ÿæç¤ºè¯200 tokensï¼Œç”¨æˆ·è¾“å…¥50 tokens
      - åŠ é€Ÿæ¯” = (200+50)/50 = **5å€**
    - åœºæ™¯2ï¼šç³»ç»Ÿæç¤ºè¯1000 tokensï¼ˆRAGåœºæ™¯ï¼‰ï¼Œç”¨æˆ·è¾“å…¥20 tokens
      - åŠ é€Ÿæ¯” = (1000+20)/20 = **51å€**ï¼ˆæç«¯caseï¼‰
  - **å†…å­˜å¼€é”€**ï¼š
    - Hash tableå­˜å‚¨ï¼šæ¯ä¸ªblock ~32 bytes hash

- 6.7.8 Agentç³»ç»Ÿçš„KV Cacheä¼˜åŒ–å®æˆ˜ âš¡ï¸ 2025æ›´æ–°

  > **æ¥æº**ï¼š[Manus - Context Engineering for AI Agents](https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus)
  >
  > **æ ¸å¿ƒæ´å¯Ÿ**ï¼šKV-cache hit rateæ˜¯ç”Ÿäº§çº§AI agentæœ€é‡è¦çš„æŒ‡æ ‡â€”â€”ç›´æ¥å†³å®šæˆæœ¬å’Œå»¶è¿Ÿ

  **6.7.8.1 Agent vs Chatbotçš„æ ¹æœ¬å·®å¼‚**

  - **è¾“å…¥è¾“å‡ºtokenæ¯”ä¾‹**ï¼š
    - **Chatbot**ï¼š1:1
      - ç”¨æˆ·è¾“å…¥ï¼š"What's the weather?"
      - æ¨¡å‹è¾“å‡ºï¼š"The weather is sunny..."
      - Prefillå’Œdecodeæ—¶é—´ç›¸è¿‘

    - **Agent**ï¼š100:1
      - ç”¨æˆ·è¾“å…¥ï¼š"Book a flight to Tokyo"
      - Agentå†…éƒ¨ï¼š50æ­¥tool callsï¼ˆsearchã€compareã€book...ï¼‰
      - æ¯æ­¥çš„contextåŒ…å«ä¹‹å‰æ‰€æœ‰actions/observations
      - Contextå¿«é€Ÿç´¯ç§¯åˆ°æ•°ä¸‡tokens
      - ä½†æ¯æ­¥è¾“å‡ºåªæ˜¯ç®€çŸ­çš„function call

  - **æˆæœ¬å½±å“**ï¼ˆClaude Sonnetï¼‰ï¼š
    - Cached tokens: **$0.30/MTok**
    - Uncached tokens: **$3.00/MTok**
    - **10å€æˆæœ¬å·®å¼‚ï¼**

  **6.7.8.2 ç”Ÿäº§çº§ä¼˜åŒ–ç­–ç•¥**

  - **ç­–ç•¥1ï¼šç¨³å®šçš„Prompt Prefix**
    ```python
    # âŒ Bad - ç ´åcache
    system_prompt = f"""
    You are a helpful assistant.
    Current time: {datetime.now()}  # æ¯ç§’ä¸åŒï¼
    """

    # âœ… Good - ä¿æŒcache
    system_prompt = """
    You are a helpful assistant.
    Current time: <use get_current_time() tool>
    """
    ```

    - **é—®é¢˜**ï¼š
      - LLMæ˜¯autoregressiveï¼šå•ä¸ªtokenå·®å¼‚ä¼šç ´ååç»­æ‰€æœ‰cache
      - Timestampç²¾ç¡®åˆ°ç§’ = æ¯æ¬¡è¯·æ±‚éƒ½cache miss

    - **è§£å†³æ–¹æ¡ˆ**ï¼š
      - ç§»é™¤timestamp
      - ä½¿ç”¨ç›¸å¯¹æ—¶é—´ï¼ˆ"2 hours ago"ï¼‰
      - é€šè¿‡å·¥å…·è·å–æ—¶é—´è€Œéç¡¬ç¼–ç 

    - **æ•ˆæœ**ï¼šCache hit rateæå‡20-30%

  - **ç­–ç•¥2ï¼šAppend-only Contextè®¾è®¡**
    ```python
    # âŒ Bad - åŠ¨æ€ä¿®æ”¹context
    def update_context(context, new_action):
        # ä¿®æ”¹ä¹‹å‰çš„action
        context["actions"][-1]["status"] = "completed"
        return context

    # âœ… Good - append-only
    def update_context(context, new_action):
        # åªè¿½åŠ ï¼Œä¸ä¿®æ”¹
        context["actions"].append({
            "action": new_action,
            "status": "completed"
        })
        return context
    ```

    - **å…³é”®åŸåˆ™**ï¼š
      - ä¸ä¿®æ”¹ä¹‹å‰çš„actions/observations
      - ç¡®å®šæ€§åºåˆ—åŒ–ï¼ˆJSON keyé¡ºåºç¨³å®šï¼‰
      - é¿å…åŠ¨æ€å·¥å…·å®šä¹‰ï¼ˆä¼šç ´åprefixï¼‰

    - **æ•ˆæœ**ï¼šCache hit rateæå‡15-25%

  - **ç­–ç•¥3ï¼šSession-aware Routing**
    ```python
    # vLLMé…ç½®
    # 1. å¯ç”¨prefix caching
    VLLM_ATTENTION_BACKEND=flashattention
    VLLM_USE_PREFIX_CACHING=true

    # 2. ä½¿ç”¨session IDè·¯ç”±
    requests = [
        {"session_id": "user123", "prompt": "..."},
        {"session_id": "user123", "prompt": "..."},  # ç›¸åŒsession
        {"session_id": "user456", "prompt": "..."},
    ]

    # è·¯ç”±ç­–ç•¥ï¼šåŒä¸€session â†’ åŒä¸€GPU worker
    def route_request(request):
        worker_id = hash(request["session_id"]) % num_workers
        return workers[worker_id]
    ```

    - **åŸç†**ï¼š
      - Prefix cachingæ˜¯per-workerçš„
      - åŒä¸€sessionçš„è¯·æ±‚è·¯ç”±åˆ°åŒä¸€worker
      - æœ€å¤§åŒ–cacheå¤ç”¨

    - **æ•ˆæœ**ï¼šTTFTé™ä½40-60%

  **6.7.8.3 é«˜çº§æŠ€å·§ï¼šCache Breakpointsç­–ç•¥**

  - **é—®é¢˜**ï¼šæŸäº›providerä¸æ”¯æŒè‡ªåŠ¨incremental caching

  - **Solution**ï¼šæ˜¾å¼æ ‡è®°cache breakpoints
    ```python
    context = [
        {"role": "system", "content": "...", "cache_breakpoint": True},
        {"role": "user", "content": "..."},
        {"role": "assistant", "content": "...", "cache_breakpoint": True},
        # å¯ä»¥åœ¨æ­¤æ–­ç‚¹å¤ç”¨ä¹‹å‰çš„cache
    ]
    ```

  - **è€ƒè™‘å› ç´ **ï¼š
    - Cache expirationæ—¶é—´
    - Memory pressure
    - è‡³å°‘ä¿ç•™system promptçš„breakpoint
    - KV Cacheå­˜å‚¨ï¼šåŸæœ¬å°±éœ€è¦ï¼Œä¸ç®—é¢å¤–å¼€é”€
    - æ€»è®¡ï¼š<1%é¢å¤–æ˜¾å­˜
  - **æœ€ä½³å®è·µ**ï¼š
    - âœ… ç³»ç»Ÿæç¤ºè¯è¶Šå›ºå®šï¼Œæ•ˆæœè¶Šå¥½
    - âœ… é€‚åˆChatGPTé£æ ¼å¯¹è¯
    - âœ… é€‚åˆRAGåœºæ™¯ï¼ˆå›ºå®šçŸ¥è¯†prefixï¼‰
    - âŒ ä¸é€‚åˆæ¯æ¬¡promptå®Œå…¨ä¸åŒçš„åœºæ™¯ï¼ˆå¦‚è¡¥å…¨ï¼‰

- 6.7.6 å®æˆ˜ï¼šåœ¨vLLMä¸­å¯ç”¨Prefix Caching

  **æ–¹æ³•1ï¼šä»£ç ä¸­å¯ç”¨**ï¼ˆæ¨èï¼‰
  ```python
  from vllm import LLM, SamplingParams

  # åˆå§‹åŒ–LLMï¼Œå¯ç”¨Prefix Caching
  llm = LLM(
      model="meta-llama/Llama-3.1-8B",
      enable_prefix_caching=True,  # å…³é”®å‚æ•°
      max_model_len=8192,
      gpu_memory_utilization=0.9
  )

  # ç³»ç»Ÿæç¤ºè¯ï¼ˆä¼šè¢«è‡ªåŠ¨ç¼“å­˜ï¼‰
  system_prompt = "You are a helpful assistant..."

  # ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼šCold Pathï¼ˆè®¡ç®—å¹¶ç¼“å­˜ï¼‰
  prompts = [system_prompt + "Explain quantum computing"]
  outputs = llm.generate(prompts)

  # ç¬¬äºŒæ¬¡è¯·æ±‚ï¼šWarm Pathï¼ˆå¤ç”¨Cacheï¼‰
  prompts = [system_prompt + "Explain black holes"]
  outputs = llm.generate(prompts)  # å¿«å¾—å¤šï¼

  # ç¬¬ä¸‰æ¬¡ã€ç¬¬å››æ¬¡...ï¼šå…¨éƒ¨Warm Path
  ```

  **æ–¹æ³•2ï¼šå‘½ä»¤è¡Œå¯åŠ¨**
  ```bash
  vllm serve meta-llama/Llama-3.1-8B \
    --enable-prefix-caching \  # å¯ç”¨Prefix Caching
    --max-model-len 8192 \
    --gpu-memory-utilization 0.9
  ```

  **æ€§èƒ½ç›‘æ§**ï¼š
  ```bash
  # æŸ¥çœ‹vLLM metrics
  curl http://localhost:8000/metrics | grep cache

  # å…³é”®æŒ‡æ ‡ï¼š
  # - vllm:num_prefix_cache_hits: Cacheå‘½ä¸­æ¬¡æ•°
  # - vllm:num_prefix_cache_misses: Cacheæœªå‘½ä¸­æ¬¡æ•°
  # å‘½ä¸­ç‡ = hits / (hits + misses)
  ```

  **æ€§èƒ½åŸºå‡†**ï¼ˆå‚è€ƒvLLMå®˜æ–¹æ•°æ®ï¼‰ï¼š
  - åœºæ™¯ï¼šç³»ç»Ÿæç¤ºè¯200 tokensï¼Œç”¨æˆ·è¾“å…¥50 tokens
  - æ— Prefix Cachingï¼š~50 mså»¶è¿Ÿ
  - æœ‰Prefix Cachingï¼š~10 mså»¶è¿Ÿï¼ˆé¦–æ¬¡~50msï¼Œåç»­~10msï¼‰
  - **æå‡ï¼š5å€ååé‡**

- 6.7.7 å®æˆ˜æ¡ˆä¾‹ï¼šOpenAI Codexçš„Prompt Caching â­ğŸ’¡

  > **ğŸ’¡ æ¡ˆä¾‹æ¥æº**: OpenAI Codex CLI - "Unrolling the Codex agent loop" (2026-01-22)
  >
  > **æ ¸å¿ƒæŒ‘æˆ˜**: Agentåœºæ™¯ä¸‹promptæŒç»­å¢é•¿ï¼Œä»Quadraticä¼˜åŒ–åˆ°Linear
  > **å…³é”®æ´å¯Ÿ**: Cache hitsä»…å¯¹exact prefix matchesæœ‰æ•ˆï¼Œéœ€è¦ç²¾å¿ƒè®¾è®¡promptç»“æ„

  **èƒŒæ™¯ï¼šCodex Agent Loopçš„æŒ‘æˆ˜**
  - **Agentå·¥ä½œæµç¨‹**ï¼š
    ```
    ç”¨æˆ·è¾“å…¥ â†’ æ¨¡å‹æ¨ç† â†’ å·¥å…·è°ƒç”¨ â†’ æ‰§è¡Œå·¥å…· â†’ è¿½åŠ ç»“æœ â†’ é‡æ–°æ¨ç† â†’ å¾ªç¯
    ```
  - **é—®é¢˜**ï¼šæ¯æ¬¡è¿­ä»£éƒ½éœ€è¦å‘é€å®Œæ•´çš„promptï¼ˆåŒ…æ‹¬ä¹‹å‰æ‰€æœ‰è½®æ¬¡çš„å†…å®¹ï¼‰
  - **å¤æ‚åº¦**ï¼šæ²¡æœ‰cacheæ—¶æ˜¯**O(nÂ²)** - quadraticå¢é•¿ï¼
    - ç¬¬1æ¬¡æ¨ç†ï¼š1ä¸ªå•ä½
    - ç¬¬10æ¬¡æ¨ç†ï¼šå‘é€1-9è½®çš„æ‰€æœ‰å†…å®¹
    - ç¬¬100æ¬¡æ¨ç†ï¼šå‘é€1-99è½®çš„æ‰€æœ‰å†…å®¹

  **Prompt Cachingçš„å¨åŠ›**
  - **æœ‰cacheæ—¶**ï¼šä»Quadraticé™åˆ°**Linear O(n)**
  - **å…³é”®è¦æ±‚**ï¼šexact prefix matchesï¼ˆå®Œå…¨åŒ¹é…çš„å‰ç¼€ï¼‰
  - **è®¾è®¡åŸåˆ™**ï¼š
    1. **é™æ€å†…å®¹æ”¾åœ¨å¼€å¤´**ï¼š
       - System instructions
       - Tool definitions
       - Examples
    2. **å˜åŒ–å†…å®¹æ”¾åœ¨ç»“å°¾**ï¼š
       - User messages
       - Tool call results
       - Dynamic context

  **Codexçš„ä¼˜åŒ–å®è·µ**
  - **Promptç»“æ„**ï¼ˆä»å‰å¾€åï¼‰ï¼š
    1. System messageï¼ˆå›ºå®šï¼‰
    2. Tools definitionsï¼ˆå›ºå®šï¼‰
    3. Developer instructionsï¼ˆå›ºå®šï¼‰
    4. Environment contextï¼ˆåŠå›ºå®šï¼Œå·¥ä½œç›®å½•å˜åŒ–æ—¶appendæ–°æ¶ˆæ¯ï¼‰
    5. User messagesï¼ˆå˜åŒ–ï¼‰
    6. Tool callså’Œresultsï¼ˆå˜åŒ–ï¼‰

  - **é¿å…Cache Missçš„å…³é”®è®¾è®¡**ï¼š
    ```python
    # âŒ é”™è¯¯åšæ³•ï¼šä¿®æ”¹å·²æœ‰æ¶ˆæ¯ï¼ˆç ´åprefixï¼‰
    prompt[3].content = new_directory  # ä¿®æ”¹ç¯å¢ƒä¸Šä¸‹æ–‡

    # âœ… æ­£ç¡®åšæ³•ï¼šè¿½åŠ æ–°æ¶ˆæ¯ï¼ˆä¿æŒprefixï¼‰
    prompt.append({
        "role": "user",
        "content": f"Changed to: {new_directory}"
    })
    ```

  **å¯¼è‡´Cache Missçš„å±é™©æ“ä½œ** âš ï¸
  - âŒ ä¸­é€”æ”¹å˜å¯ç”¨toolsï¼ˆMCPæœåŠ¡å™¨é€šçŸ¥tools/list_changedï¼‰
  - âŒ åˆ‡æ¢æ¨¡å‹ï¼ˆmodel-specific instructionså˜åŒ–ï¼‰
  - âŒ ä¿®æ”¹sandboxé…ç½®æˆ–approval mode
  - âŒ ä¿®æ”¹å·¥ä½œç›®å½•ï¼ˆå¿…é¡»ç”¨appendè€Œémodifyï¼‰

  **Codexçš„è§£å†³æ–¹æ¡ˆ**ï¼š
  - **é…ç½®å˜åŒ–æ—¶appendæ–°æ¶ˆæ¯**ï¼š
    ```python
    # ç¯å¢ƒå˜åŒ–ï¼šè¿½åŠ æ–°æ¶ˆæ¯è€Œéä¿®æ”¹
    if directory_changed:
        prompt.append({
            "role": "user",
            "type": "environment_context",
            "content": new_directory
        })
    ```
  - **MCPå·¥å…·æšä¸¾é¡ºåºä¿æŒä¸€è‡´**ï¼š
    - Bugæ¡ˆä¾‹ï¼šMCP toolsæšä¸¾é¡ºåºä¸ä¸€è‡´å¯¼è‡´cache miss
    - ä¿®å¤ï¼šæ’åºå·¥å…·åˆ—è¡¨ï¼Œç¡®ä¿æ¯æ¬¡è¯·æ±‚é¡ºåºç›¸åŒ

  **æ€§èƒ½å½±å“åˆ†æ**
  - **æ— Prompt Caching**ï¼š
    - Agent loopï¼š10è½®å·¥å…·è°ƒç”¨
    - Tokenå‘é€é‡ï¼š1 + 2 + 3 + ... + 10 = **55ä¸ªå•ä½**ï¼ˆQuadraticï¼‰
  - **æœ‰Prompt Caching**ï¼š
    - Agent loopï¼š10è½®å·¥å…·è°ƒç”¨
    - Tokenå‘é€é‡ï¼š**10ä¸ªå•ä½**ï¼ˆä»…æ–°å¢å†…å®¹ï¼‰
    - **èŠ‚çœï¼š82%**ï¼ˆ55 vs 10ï¼‰

  **Context Windowç®¡ç†**
  - **æŒ‘æˆ˜**ï¼šå³ä½¿æœ‰cacheï¼Œcontext windowä¹Ÿä¼šæ»¡
  - **Codexçš„compactç­–ç•¥**ï¼š
    - ä½¿ç”¨`/responses/compact` endpoint
    - è‡ªåŠ¨å‹ç¼©å†å²å¯¹è¯
    - ä¿ç•™æ¨¡å‹çš„latent understandingï¼ˆé€šè¿‡encrypted_contentï¼‰
  - **Auto-compactè§¦å‘**ï¼š
    ```python
    if token_count > auto_compact_limit:
        compacted = call_compact_endpoint(conversation)
        conversation = compacted.items  # æ›´å°çš„prompt
    ```

  **å…³é”®ç»éªŒæ€»ç»“** ğŸ’¡
  1. **Promptç»“æ„è®¾è®¡è‡³å…³é‡è¦**ï¼š
     - å›ºå®šå†…å®¹åœ¨å‰ï¼Œå˜åŒ–å†…å®¹åœ¨å
     - ä»ä¸ä¿®æ”¹å·²æœ‰æ¶ˆæ¯ï¼Œæ€»æ˜¯è¿½åŠ æ–°æ¶ˆæ¯
  2. **ç›‘æ§Cacheå‘½ä¸­ç‡**ï¼š
     - Codexå›¢é˜Ÿå‘ç°çš„MCP bugå°±æ˜¯å› ä¸ºç›‘æ§cache miss
  3. **å¹³è¡¡cacheä¸context window**ï¼š
     - Cacheæå‡æ€§èƒ½
     - Compactç®¡ç†å†…å­˜
     - ä¸¤è€…é…åˆå®ç°æœ€ä¼˜æ•ˆæœ

  **å¯¹ä½ çš„å¯å‘**
  - **Agentåœºæ™¯æ˜¯Prefix Cachingçš„é»„é‡‘åº”ç”¨**ï¼š
    - ç³»ç»Ÿæç¤ºè¯å›ºå®š
    - å·¥å…·å®šä¹‰å›ºå®š
    - åªæœ‰ç”¨æˆ·è¾“å…¥å’Œå·¥å…·ç»“æœå˜åŒ–
  - **å®ç°Agentç³»ç»Ÿæ—¶çš„ Checklist**ï¼š
    - [ ] Promptä¸­å›ºå®šå†…å®¹æ˜¯å¦éƒ½åœ¨å‰é¢ï¼Ÿ
    - [ ] æ˜¯å¦ç”¨appendè€Œémodifyæ¥æ›´æ–°çŠ¶æ€ï¼Ÿ
    - [ ] æ˜¯å¦ç›‘æ§äº†cache hit rateï¼Ÿ
    - [ ] å½“context windowæ»¡æ—¶ï¼Œcompactç­–ç•¥æ˜¯ä»€ä¹ˆï¼Ÿ

#### å¸¸è§è¯¯åŒºä¸“æ 
#### å®æˆ˜æ£€æŸ¥æ¸…å•
#### åŠ¨æ‰‹ç»ƒä¹ 
- ç»ƒä¹ 5.1ï¼šå®ç°ç®€å•çš„KV Cache
- ç»ƒä¹ 5.2ï¼šå¯¹æ¯”æœ‰æ— KV Cacheçš„æ€§èƒ½å·®å¼‚

---

### ç¬¬7ç«  è¯·æ±‚è°ƒåº¦ç­–ç•¥

> **ğŸ’° æˆæœ¬å½±å“**ï¼ˆåŸºäºè¡Œä¸šæ•°æ®ï¼‰
> - **ååæå‡**ï¼šContinuous Batchingå¯å°†ååé‡æå‡3-10å€
> - **å»¶è¿Ÿæ”¹å–„**ï¼šP95å»¶è¿Ÿå¯é™ä½50-70%
> - **GPUåˆ©ç”¨ç‡**ï¼šä»30-40%æå‡åˆ°80-90%

#### 7.1 è°ƒåº¦çš„å¿…è¦æ€§
- 7.1.1 ä¸ºä»€ä¹ˆéœ€è¦è°ƒåº¦
- 7.1.2 æœåŠ¡è´¨é‡vsååé‡
- 7.1.3 è°ƒåº¦å™¨çš„ç›®æ ‡

#### 7.2 åŸºç¡€è°ƒåº¦ç­–ç•¥
- 7.2.1 FIFO (First In First Out)
- 7.2.2 é™æ€æ‰¹å¤„ç† (Static Batching)
- 7.2.3 ä¼˜ç¼ºç‚¹åˆ†æ

#### 7.3 åŠ¨æ€æ‰¹å¤„ç† (Continuous Batching)
- 7.3.1 é—®é¢˜ï¼šé™æ€æ‰¹å¤„ç†çš„æµªè´¹
- 7.3.2 Continuous BatchingåŸç†
- 7.3.3 å›¾è§£å·¥ä½œæµç¨‹
- 7.3.4 æ€§èƒ½æå‡åˆ†æ

#### 7.4 vLLMçš„è°ƒåº¦å™¨å®ç°
- 7.4.1 è¯·æ±‚ç”Ÿå‘½å‘¨æœŸç®¡ç†
- 7.4.2 é¢„åˆ†é…vsåŠ¨æ€åˆ†é…
- 7.4.3 è¿­ä»£çº§è°ƒåº¦ (Iteration-level Scheduling)
- 7.4.4 Overlap Scheduling (Mini-SGLang) âš¡ï¸ 2025æ–°å¢

  > **ğŸ’¡ æ·±åº¦æ¥æº**ï¼š[Mini-SGLang Blog](https://lmsys.org/blog/2025-12-17-minisgl/) + [Berkeley EECS-2025-192](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2025/EECS-2025-192.pdf)
  >
  > **æ ¸å¿ƒé—®é¢˜**ï¼šBerkeleyè®ºæ–‡æŒ‡å‡ºCPU overheadå¯¼è‡´GPUé—²ç½® â†’ Overlap Schedulingæ˜¯è§£å†³æ–¹æ¡ˆ
  >
  > **æ€§èƒ½æå‡**ï¼šæ¶ˆé™¤GPU stallsï¼Œæå‡ååé‡20-30%

  **7.4.4.1 CPUå¼€é”€å¯¼è‡´GPUé—²ç½®é—®é¢˜**

  - **Berkeley EECS-2025-192çš„å‘ç°**ï¼š
    - CPUå¼€é”€å æ¨ç†æ—¶é—´çš„**10-20%**
    - ä¸»è¦æ¥æºï¼š
      - Kernel launchï¼ˆå¯åŠ¨GPU kernelï¼‰
      - Memory copyï¼ˆCPUâ†”GPUæ•°æ®ä¼ è¾“ï¼‰
      - Synchronizationï¼ˆç­‰å¾…GPUå®Œæˆï¼‰
      - Batch schedulingï¼ˆå†³å®šå“ªäº›è¯·æ±‚ä¸€èµ·å¤„ç†ï¼‰

  - **é—®é¢˜**ï¼š
    - vLLMçš„è¿­ä»£çº§è°ƒåº¦æ˜¯**ä¸²è¡Œ**çš„ï¼š
      ```
      Step 1: CPUè°ƒåº¦ä¸‹ä¸€æ‰¹è¯·æ±‚
      Step 2: CPUå‡†å¤‡è¾“å…¥æ•°æ®
      Step 3: CPUå¯åŠ¨GPU kernel
      Step 4: GPUè®¡ç®—ï¼ˆæ­¤æ—¶CPUé—²ç½®ï¼ï¼‰
      Step 5: CPUç­‰å¾…GPUå®Œæˆ
      Step 6: å›åˆ°Step 1
      ```
    - ç»“æœï¼š**GPUåˆ©ç”¨ç‡ä½**ï¼Œæœ‰æ˜æ˜¾çš„GPU stalls

  - **Nsight Systemsåˆ†æ**ï¼ˆæ— overlapï¼‰ï¼š
    ```
    Timeline:
    CPU: |--Schedule1--|--Prepare2--|--Launch3--|
    GPU:              |<--Compute1-->|    stalls    |
    ```
    çœ‹åˆ°GPUæœ‰æ˜æ˜¾çš„é—²ç½®æœŸï¼ˆstallsï¼‰

  **7.4.4.2 Overlap Schedulingè®¾è®¡æ€æƒ³**

  - **æ ¸å¿ƒæ€æƒ³**ï¼š
    - **CPU-GPUå¹¶è¡Œæ‰§è¡Œ**ï¼š
      - CPUå‡†å¤‡ä¸‹ä¸€æ‰¹è¯·æ±‚æ—¶ï¼ŒGPUæ­£åœ¨è®¡ç®—å½“å‰æ‰¹æ¬¡
      - GPUè®¡ç®—å®Œæˆåï¼Œä¸‹ä¸€æ‰¹è¯·æ±‚å·²ç»readyï¼Œç«‹å³å¼€å§‹
    - **ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼**ï¼š
      - CPUï¼šç”Ÿäº§è€…ï¼ˆå‡†å¤‡batchesï¼‰
      - GPUï¼šæ¶ˆè´¹è€…ï¼ˆæ‰§è¡Œbatchesï¼‰

  - **å¯¹æ¯”**ï¼š
    ```
    æ— Overlapï¼ˆvLLMé»˜è®¤ï¼‰ï¼š
    CPU: |--Schedule--|--Prepare--|
    GPU:                 |--Compute--|<-stall->|--Compute--|

    æœ‰Overlapï¼ˆMini-SGLangï¼‰ï¼š
    CPU: |--Schedule1--|--Prepare2--|--Prepare3--|
    GPU:                 |--Compute1-->|--Compute2-->|
    ```
    GPUæŒç»­è¿è¡Œï¼Œæ— é—²ç½®ï¼

  **7.4.4.3 å®ç°æœºåˆ¶**

  - **æ¶æ„è®¾è®¡**ï¼š
    ```python
    class OverlapScheduler:
        def __init__(self):
            self.cpu_queue = Queue()  # CPUå‡†å¤‡çš„è¯·æ±‚é˜Ÿåˆ—
            self.gpu_queue = Queue()  # GPUå¾…æ‰§è¡Œçš„é˜Ÿåˆ—
            self.cpu_thread = Thread(target=self._cpu_worker)
            self.gpu_thread = Thread(target=self._gpu_worker)

        def start(self):
            """å¯åŠ¨CPUå’ŒGPUçº¿ç¨‹"""
            self.cpu_thread.start()
            self.gpu_thread.start()

        def _cpu_worker(self):
            """CPUçº¿ç¨‹ï¼šæŒç»­å‡†å¤‡ä¸‹ä¸€æ‰¹è¯·æ±‚"""
            while True:
                # å¼‚æ­¥å‡†å¤‡ä¸‹ä¸€æ‰¹è¯·æ±‚
                next_batch = self._schedule_next_batch()
                prepared_batch = self._prepare_batch(next_batch)

                # æ”¾å…¥GPUæ‰§è¡Œé˜Ÿåˆ—
                self.gpu_queue.put(prepared_batch)

                # CPUç»§ç»­ï¼Œä¸ç­‰å¾…GPU

        def _gpu_worker(self):
            """GPUçº¿ç¨‹ï¼šæŒç»­æ‰§è¡Œbatches"""
            while True:
                # ä»é˜Ÿåˆ—å–batchï¼ˆå¦‚æœCPUè¿˜æ²¡å‡†å¤‡å¥½ï¼Œè¿™é‡Œä¼šblockï¼‰
                batch = self.gpu_queue.get()

                # æ‰§è¡ŒGPUè®¡ç®—
                self._execute_model_async(batch)

                # å¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡
                # GPUå®Œæˆåï¼Œsignalä¸‹ä¸€ä¸ªbatch
    ```

  - **å…³é”®ç‚¹**ï¼š
    - **åŒçº¿ç¨‹è®¾è®¡**ï¼š
      - CPU threadï¼šè´Ÿè´£schedulingã€memory management
      - GPU threadï¼šè´Ÿè´£æ‰§è¡Œæ¨¡å‹
    - **å¼‚æ­¥é˜Ÿåˆ—**ï¼š
      - CPUæå‰å‡†å¤‡2-3ä¸ªbatches
      - GPUæ°¸è¿œä¸ä¼šç­‰å¾…
    - **åŒæ­¥ç‚¹**ï¼š
      - ä»…åœ¨GPU kernelå®Œæˆæ—¶åŒæ­¥
      - åŒæ­¥å¼€é”€è¢«éšè—åœ¨ä¸‹æ¬¡GPUè®¡ç®—ä¸­

  **7.4.4.4 æ€§èƒ½åˆ†æï¼ˆNsight Systemsï¼‰**

  - **Mini-SGLangå®æµ‹**ï¼ˆæ¥è‡ªå®˜æ–¹blogï¼‰ï¼š

    **With Overlap Scheduling**ï¼š
    ```
    Timeline (from Mini-SGLang blog):
    CPU: |--Prep1--|--Prep2--|--Prep3--|
    GPU:        |--Comp1-->|--Comp2-->|
    ```
    - GPUæŒç»­åˆ©ç”¨ï¼Œæ— stalls
    - ååé‡æå‡ï¼š**20-30%**

    **Without Overlap Scheduling**ï¼ˆç¯å¢ƒå˜é‡`MINISGL_DISABLE_OVERLAP_SCHEDULING=1`ï¼‰ï¼š
    ```
    Timeline (from Mini-SGLang blog):
    CPU: |--Prep1--|
    GPU:        |--Comp1-->|<-stall->|<--stall-->|
    ```
    - æ˜æ˜¾çš„GPU stalls
    - ååé‡é™ä½20-30%

  - **ä¸ºä»€ä¹ˆæœ‰æ•ˆ**ï¼š
    - CPUè°ƒåº¦å¼€é”€ï¼š~5ms
    - GPUè®¡ç®—æ—¶é—´ï¼š~50ms
    - Overlapéšè—äº†5msçš„CPUå¼€é”€
    - ç†è®ºåŠ é€Ÿæ¯”ï¼š50/(50-5) = **1.11å€**ï¼ˆä¿å®ˆä¼°è®¡ï¼‰
    - å®æµ‹åŠ é€Ÿæ¯”ï¼š**1.2-1.3å€**ï¼ˆå› ä¸ºCPUå¼€é”€å¯èƒ½æ›´å¤§ï¼‰

  **7.4.4.5 å®æˆ˜ï¼šå¯ç”¨/ç¦ç”¨Overlap Scheduling**

  - **Mini-SGLangé»˜è®¤å¯ç”¨**ï¼š
    ```bash
    # å¯åŠ¨Mini-SGLangï¼ˆé»˜è®¤å¯ç”¨overlap schedulingï¼‰
    python -m minisgl \
      --model "Qwen/Qwen3-32B" \
      --tp 4 \
      --cache radix

    # æ€§èƒ½æµ‹è¯•
    benchmark --url http://localhost:8000/v1 \
              --model "Qwen/Qwen3-32B" \
              --dataset sharegpt
    # ç»“æœï¼š~1000 tokens/s (with overlap)
    ```

  - **ç¦ç”¨Overlap Schedulingï¼ˆA/Bæµ‹è¯•ï¼‰**ï¼š
    ```bash
    # è®¾ç½®ç¯å¢ƒå˜é‡ç¦ç”¨
    MINISGL_DISABLE_OVERLAP_SCHEDULING=1 \
    python -m minisgl \
      --model "Qwen/Qwen3-32B" \
      --tp 4 \
      --cache radix

    # æ€§èƒ½æµ‹è¯•
    benchmark --url http://localhost:8000/v1 \
              --model "Qwen/Qwen3-32B" \
              --dataset sharegpt
    # ç»“æœï¼š~800 tokens/s (without overlap)
    # å¯¹æ¯”ï¼š1000 vs 800 = **1.25å€æå‡**
    ```

  - **Nsight Systems profiling**ï¼š
    ```bash
    # å¯ç”¨profiling
    nsys profile \
      --output=overlap_enabled.qdrep \
      python -m minisgl --model "Qwen/Qwen3-32B" --tp 4

    # å¯¹æ¯”åˆ†æ
    nsys stats overlap_enabled.qdrep --report=gpu_summary
    nsys stats overlap_disabled.qdrep --report=gpu_summary

    # å…³é”®æŒ‡æ ‡ï¼š
    # - GPUåˆ©ç”¨ç‡ï¼š95% (with overlap) vs 75% (without)
    # - GPU stallsï¼š<1% (with overlap) vs 20% (without)
    ```

  **7.4.4.6 ä¸vLLMè°ƒåº¦å™¨çš„å¯¹æ¯”**

  | ç»´åº¦ | vLLM (Iteration-level) | Mini-SGLang (Overlap) |
  |------|----------------------|----------------------|
  | **æ‰§è¡Œæ¨¡å¼** | ä¸²è¡Œï¼ˆCPUâ†’GPUï¼‰ | å¹¶è¡Œï¼ˆCPU || GPUï¼‰ |
  | **GPUåˆ©ç”¨ç‡** | 75-85% | 90-95% |
  | **CPUå¼€é”€** | 10-20% | è¢«éšè— |
  | **ååé‡** | åŸºçº¿ | +20-30% |
  | **å¤æ‚åº¦** | ç®€å• | ä¸­ç­‰ï¼ˆéœ€å¤šçº¿ç¨‹ï¼‰ |
  | **é€‚ç”¨åœºæ™¯** | é€šç”¨åœºæ™¯ | é«˜åååœºæ™¯ |

  - **vLLMçš„è€ƒè™‘**ï¼š
    - è¿­ä»£çº§è°ƒåº¦æ›´ç®€å•ã€æ›´ç¨³å®š
    - åœ¨å¤§å¤šæ•°åœºæ™¯ä¸‹æ€§èƒ½è¶³å¤Ÿå¥½
    - é¿å…å¤šçº¿ç¨‹çš„å¤æ‚æ€§ï¼ˆrace conditionsã€deadlocksï¼‰

  - **Mini-SGLangçš„ä¼˜åŠ¿**ï¼š
    - åœ¨é«˜åååœºæ™¯ä¸‹æ€§èƒ½æå‡æ˜æ˜¾
    - ç‰¹åˆ«é€‚åˆonline servingï¼ˆæŒç»­é«˜è´Ÿè½½ï¼‰
    - ä»£ç ç®€æ´ï¼ˆ5kè¡Œï¼‰ï¼Œæ˜“äºç†è§£

  **7.4.4.7 é€‚ç”¨åœºæ™¯ä¸é€‰æ‹©å»ºè®®**

  - **é€‰æ‹©Overlap Scheduling**ï¼š
    - âœ… Online servingï¼ˆæŒç»­é«˜è´Ÿè½½ï¼‰
    - âœ… å¯¹å»¶è¿Ÿæ•æ„Ÿï¼ˆP99å»¶è¿Ÿè¦æ±‚é«˜ï¼‰
    - âœ… GPUèµ„æºç´§å¼ ï¼ˆéœ€è¦æœ€å¤§åŒ–åˆ©ç”¨ç‡ï¼‰
    - âœ… ä½¿ç”¨Mini-SGLangæˆ–SGLang

  - **vLLMçš„è¿­ä»£çº§è°ƒåº¦ä¹Ÿè¶³å¤Ÿ**ï¼š
    - âœ… ç¦»çº¿æ‰¹å¤„ç†ï¼ˆbatch inferenceï¼‰
    - âœ… ä½è´Ÿè½½åœºæ™¯ï¼ˆGPUä¸æ˜¯ç“¶é¢ˆï¼‰
    - âœ… ç¨³å®šæ€§ä¼˜å…ˆï¼ˆé¿å…å¤šçº¿ç¨‹å¤æ‚æ€§ï¼‰
    - âœ… ä½¿ç”¨vLLMç”Ÿæ€

  - **æœªæ¥è¶‹åŠ¿**ï¼š
    - vLLMå¯èƒ½åœ¨åç»­ç‰ˆæœ¬ä¸­å¼•å…¥ç±»ä¼¼çš„overlapä¼˜åŒ–
    - CPU overheadé—®é¢˜æ˜¯æ‰€æœ‰æ¨ç†æ¡†æ¶çš„å…±åŒæŒ‘æˆ˜
    - Overlap Schedulingæ˜¯æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆ

  **7.4.4.8 SGLang v0.4: Zero-Overhead Batch Scheduler**

  > **ğŸ’¡ æ·±åº¦æ¥æº**ï¼š[SGLang v0.4 Blog](https://lmsys.org/blog/2024-12-04-sglang-v0-4/)
  >
  > **æ¼”è¿›**ï¼šOverlap Schedulingçš„ä¸‹ä¸€ä»£å®ç°
  >
  > **éªŒè¯**ï¼šNsight Systemsç¡®è®¤GPUæ— é—²ç½®

  - **Overlap Schedulingçš„æ¼”è¿›**ï¼š
    - Mini-SGLangçš„Overlap Schedulingï¼ˆv0.3ï¼‰ï¼š
      - CPU-GPUå¹¶è¡Œæ‰§è¡Œ
      - ååæå‡20-30%
      - ä½†ä»æœ‰è½»å¾®GPU stalls

    - SGLang v0.4çš„Zero-Overhead Schedulerï¼š
      - **å®Œå…¨æ¶ˆé™¤GPUé—²ç½®**
      - æ›´ç²¾ç¡®çš„ä¾èµ–ç®¡ç†
      - æ€§èƒ½è¿›ä¸€æ­¥æå‡

  - **æ ¸å¿ƒæœºåˆ¶ï¼šFuture Tokens**ï¼š
    ```python
    class ZeroOverheadScheduler:
        def __init__(self):
            self.future_tokens = {}  # é¢„è®¡ç®—çš„tokenä¾èµ–

        def schedule_next_batch(self):
            """CPUè°ƒåº¦å™¨ï¼šæå‰è®¡ç®—ä¸‹ä¸€æ‰¹çš„ä¾èµ–"""

            # 1. ç¡®å®šå“ªäº›è¯·æ±‚å¯ä»¥ä¸€èµ·è°ƒåº¦
            #    ä½¿ç”¨Future Tokensæœºåˆ¶é¢„è®¡ç®—ä¾èµ–
            for request in self.running_requests:
                # æ ‡è®°future tokensï¼ˆå³å°†ç”Ÿæˆçš„tokensï¼‰
                future_token_ids = self.predict_next_tokens(request)

                # è®°å½•ä¾èµ–å…³ç³»
                self.future_tokens[request.id] = {
                    'tokens': future_token_ids,
                    'dependencies': self.resolve_dependencies(future_token_ids)
                }

            # 2. å‡†å¤‡ä¸‹ä¸€æ‰¹è¯·æ±‚
            #    åŸºäºfuture tokensé¢„åˆ†é…KV cache
            next_batch = self.prepare_batch_with_future_tokens()

            return next_batch

        def predict_next_tokens(self, request):
            """é¢„æµ‹ä¸‹ä¸€æ‰¹å¯èƒ½çš„tokens

            ç”¨äºï¼š
            - é¢„åˆ†é…KV cache blocks
            - é¢„è®¡ç®—attention masks
            - å‡å°‘GPU kernel launchæ—¶çš„å»¶è¿Ÿ
            """
            # ä½¿ç”¨æ¨¡å‹æœ€åå±‚çš„logitsé¢„æµ‹top-k tokens
            logits = request.last_layer_logits
            top_k_tokens = torch.topk(logits, k=10).indices

            return top_k_tokens.tolist()

        def resolve_dependencies(self, token_ids):
            """è§£ætokenä¾èµ–å…³ç³»

            ç¡®ä¿å¹¶å‘çš„è¯·æ±‚ä¸ä¼šè®¿é—®å†²çªçš„å†…å­˜åŒºåŸŸ
            """
            dependencies = []
            for token_id in token_ids:
                # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–è¯·æ±‚ä¹Ÿåœ¨ç­‰å¾…è¿™ä¸ªtoken
                if self.has_dependency(token_id):
                    dependencies.append(token_id)

            return dependencies
    ```

  - **Nsight SystemséªŒè¯**ï¼š

    **SGLang v0.4 Timeline**ï¼ˆZero-Overheadï¼‰ï¼š
    ```
    CPU (Scheduler): |--Schedule1--|--Schedule2--|--Schedule3--|
    GPU (Executor):       |<--Compute1-->|<--Compute2-->|<--Compute3-->|
                         â†‘ no stalls     â†‘ no stalls     â†‘ no stalls
    ```
    - GPUåˆ©ç”¨ç‡ï¼š**~98-99%**
    - GPU stallsï¼š**<0.5%**ï¼ˆå‡ ä¹ä¸º0ï¼‰
    - ååé‡ï¼š1.1x vs v0.3ï¼Œ1.3x vs baselines

    **å¯¹æ¯”ï¼šSGLang v0.3 Timeline**ï¼ˆåŸºç¡€Overlap Schedulingï¼‰ï¼š
    ```
    CPU (Scheduler): |--Schedule1--|--Schedule2--|
    GPU (Executor):       |<--Compute1-->|  ~1ms stall  |--Compute2-->|
                                                  â†‘
                                            è½»å¾®GPUé—²ç½®
    ```
    - GPUåˆ©ç”¨ç‡ï¼š~95%
    - GPU stallsï¼š~1-2%
    - ååé‡ï¼š1.2-1.3x vs baselines

  - **æ€§èƒ½æ•°æ®**ï¼ˆæ¥è‡ªSGLang v0.4 blogï¼‰ï¼š

    | æ¨¡å‹ | é…ç½® | Baseline | SGLang v0.3 | SGLang v0.4 | æå‡ |
    |------|------|----------|-------------|-------------|------|
    | Llama-3-8B | TP=1 | 1000 | 1200 (1.2x) | 1300 (1.3x) | +8% |
    | Llama-3-8B | TP=4 | 3500 | 4200 (1.2x) | 4550 (1.3x) | +8% |
    | Llama-3-70B | TP=8 | 1800 | 2160 (1.2x) | 2340 (1.3x) | +8% |

    - **æœ€ä½³åœºæ™¯**ï¼šSmall models + Large Tensor Parallelism
      - ä¾‹å¦‚ï¼šLlama-3-8B with TP=4
      - CPU overheadç›¸å¯¹æ›´å¤§ï¼ˆå› ä¸ºæ¨¡å‹å°ï¼ŒGPUè®¡ç®—å¿«ï¼‰
      - Overlapæ•ˆæœæ›´æ˜æ˜¾

  - **CUDA Eventså’ŒåŒæ­¥**ï¼š
    ```cpp
    // SGLang v0.4çš„CUDA Eventsä½¿ç”¨
    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);

    // CPUè®°å½•äº‹ä»¶
    cudaEventRecord(start, stream);

    // å¼‚æ­¥æ‰§è¡ŒGPU kernel
    launch_attention_kernel<<<...>>>(...);

    // CPUä¸ç­‰å¾…ï¼Œç»§ç»­å‡†å¤‡ä¸‹ä¸€æ‰¹
    prepare_next_batch();

    // ä»…åœ¨éœ€è¦æ—¶åŒæ­¥
    cudaEventRecord(stop, stream);
    cudaEventSynchronize(stop);

    float milliseconds;
    cudaEventElapsedTime(&milliseconds, start, stop);

    // å…³é”®ï¼šåŒæ­¥ç‚¹è¢«å»¶è¿Ÿåˆ°CPUå‡†å¤‡å¥½ä¸‹ä¸€æ‰¹ä¹‹å
    // è¿™æ ·CPUå¼€é”€è¢«å®Œå…¨éšè—
    ```

  - **é»˜è®¤å¯ç”¨**ï¼š
    - SGLang v0.4+ï¼šZero-Overhead Scheduler **é»˜è®¤å¼€å¯**
    - æ— éœ€é¢å¤–é…ç½®
    - å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡ç¦ç”¨ï¼ˆç”¨äºè°ƒè¯•ï¼‰ï¼š
      ```bash
      SGLANG_DISABLE_ZERO_OVERHEAD_SCHEDULER=1 \
      python -m sglang.launch_server --model meta-llama/Llama-3-8B
      ```

  - **ä¸Mini-SGLang Overlap Schedulingçš„å…³ç³»**ï¼š
    - Mini-SGLangï¼šæ¦‚å¿µéªŒè¯ç‰ˆæœ¬ï¼ˆ5kè¡Œä»£ç ï¼‰
    - SGLang v0.3ï¼šç”Ÿäº§çº§Overlap Scheduling
    - SGLang v0.4ï¼šZero-Overhead Schedulerï¼ˆå®Œå…¨æ¶ˆé™¤GPU stallsï¼‰

  - **å®æˆ˜å»ºè®®**ï¼š
    - ä½¿ç”¨SGLang v0.4+æ—¶ï¼ŒZero-Overhead Schedulerè‡ªåŠ¨å¯ç”¨
    - å¦‚æœä½¿ç”¨Mini-SGLangå­¦ä¹ ï¼Œå¯ä»¥å¯¹æ¯”å¯ç”¨/ç¦ç”¨çš„æ€§èƒ½å·®å¼‚
    - Nsight Systems profilingï¼šæŸ¥çœ‹GPU stallsæ˜¯å¦é™åˆ°<0.5%

- 7.4.5 ä¼˜å…ˆçº§é˜Ÿåˆ—

- 7.4.6 Cache-Aware Load Balancer (SGLang)

  > **ğŸ’¡ æ·±åº¦æ¥æº**ï¼š[SGLang v0.4 Blog](https://lmsys.org/blog/2024-12-04-sglang-v0-4/)
  >
  > **é—®é¢˜**ï¼šMulti-worker DPéƒ¨ç½²æ—¶ï¼Œcache hitç‡ä½
  >
  > **è§£å†³**ï¼šæ™ºèƒ½è·¯ç”±ï¼Œé¢„æµ‹prefix KV cache hitç‡

  **7.4.6.1 Multi-Worker Cache Hitç‡é—®é¢˜**

  - **èƒŒæ™¯ï¼šData Parallelism (DP) éƒ¨ç½²**ï¼š
    ```
    å…¸å‹DPéƒ¨ç½²ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Load Balancer (Round-Robin)           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                â”‚
               â–¼                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Worker 1         â”‚  â”‚ Worker 2         â”‚
    â”‚ Radix Cache:     â”‚  â”‚ Radix Cache:     â”‚
    â”‚ - System prompt  â”‚  â”‚ (empty)          â”‚
    â”‚ - Doc A          â”‚  â”‚                  â”‚
    â”‚ - Doc B          â”‚  â”‚                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ```

  - **é—®é¢˜**ï¼š
    - Load Balancerä½¿ç”¨Round-Robinï¼ˆè½®è¯¢ï¼‰
    - è¯·æ±‚éšæœºåˆ†é…åˆ°workers
    - **Cache hitç‡ä½**ï¼š~20%ï¼ˆSGLangå®æµ‹æ•°æ®ï¼‰
    - åŸå› ï¼š
      ```
      è¯·æ±‚1: "System prompt + Doc A" â†’ Worker 1 (hit!)
      è¯·æ±‚2: "System prompt + Doc A" â†’ Worker 2 (miss!)
      è¯·æ±‚3: "System prompt + Doc A" â†’ Worker 1 (hit!)
      è¯·æ±‚4: "System prompt + Doc A" â†’ Worker 2 (miss!)

      Hit rate: 50% (ç†æƒ³æƒ…å†µï¼Œå®é™…æ›´å·®)
      ```

  **7.4.6.2 Cache-Aware Load Balancerè®¾è®¡**

  - **æ ¸å¿ƒæ€æƒ³**ï¼š
    - Load Balancer **é¢„æµ‹**æ¯ä¸ªè¯·æ±‚åœ¨å„workerä¸Šçš„cache hitç‡
    - è·¯ç”±åˆ°**cache hitç‡æœ€é«˜**çš„worker
    - ç»“æœï¼šHitç‡ä»20% â†’ 75%ï¼ˆ3.8å€æå‡ï¼‰

  - **Radix Treeè¿‘ä¼¼**ï¼š
    ```python
    class RadixTreeApproximation:
        """è½»é‡çº§Radix Treeè¡¨ç¤º

        ç”¨äºå¿«é€Ÿé¢„æµ‹cache hitç‡
        """
        def __init__(self):
            # ä¸å­˜å‚¨å®Œæ•´çš„KV cache
            # åªå­˜å‚¨tokenåºåˆ—çš„hash
            self.prefix_hashes = set()

        def add_prefix(self, tokens):
            """æ·»åŠ ä¸€ä¸ªprefix"""
            # è®¡ç®—hashï¼ˆä¸å­˜å‚¨å®é™…KVï¼‰
            hash_value = hash(tuple(tokens))

            self.prefix_hashes.add(hash_value)

        def predict_cache_hit(self, request_tokens):
            """é¢„æµ‹cache hitç‡

            è¿”å›ï¼š0.0 - 1.0ä¹‹é—´çš„å€¼
            """
            # æŸ¥æ‰¾æœ€é•¿åŒ¹é…prefix
            max_match_length = 0

            for prefix_len in range(len(request_tokens), 0, -1):
                prefix_hash = hash(tuple(request_tokens[:prefix_len]))

                if prefix_hash in self.prefix_hashes:
                    max_match_length = prefix_len
                    break

            # cache hitç‡ = åŒ¹é…é•¿åº¦ / æ€»é•¿åº¦
            hit_rate = max_match_length / len(request_tokens)

            return hit_rate
    ```

  **7.4.6.3 æ™ºèƒ½è·¯ç”±ç­–ç•¥**

  - **è·¯ç”±ç®—æ³•**ï¼š
    ```python
    class CacheAwareLoadBalancer:
        def __init__(self, workers):
            self.workers = workers
            self.worker_radix_trees = {
                worker.id: RadixTreeApproximation()
                for worker in workers
            }

        def route_request(self, request):
            """æ™ºèƒ½è·¯ç”±è¯·æ±‚åˆ°æœ€ä¼˜worker"""

            # 1. é¢„æµ‹æ¯ä¸ªworkerçš„cache hitç‡
            hit_rates = {}
            for worker in self.workers:
                hit_rates[worker.id] = self.worker_radix_trees[worker.id] \
                    .predict_cache_hit(request.tokens)

            # 2. é€‰æ‹©hitç‡æœ€é«˜çš„worker
            best_worker_id = max(hit_rates, key=hit_rates.get)

            # 3. è€ƒè™‘è´Ÿè½½å‡è¡¡
            #    å¦‚æœå¤šä¸ªworkers hitç‡ç›¸è¿‘ï¼Œé€‰æ‹©è´Ÿè½½è¾ƒä½çš„
            best_worker = self.workers[best_worker_id]

            if best_worker.queue_size > HIGH_WATERMARK:
                # æ‰¾æ¬¡ä¼˜worker
                sorted_workers = sorted(
                    hit_rates.items(),
                    key=lambda x: x[1],
                    reverse=True
                )

                for worker_id, hit_rate in sorted_workers[1:]:
                    worker = self.workers[worker_id]
                    if worker.queue_size < LOW_WATERMARK:
                        best_worker = worker
                        break

            return best_worker

        def update_radix_tree(self, worker_id, request_tokens):
            """æ›´æ–°workerçš„Radix Tree

            å½“workerå¤„ç†å®Œè¯·æ±‚åè°ƒç”¨
            """
            self.worker_radix_trees[worker_id].add_prefix(request_tokens)
    ```

  **7.4.6.4 æ€§èƒ½æå‡**

  - **Cache Hit Rate**ï¼ˆSGLangå®æµ‹ï¼‰ï¼š
    | é…ç½® | Round-Robin | Cache-Aware | æå‡ |
    |------|-------------|-------------|------|
    | Hit Rate | 20% | 75% | **3.8x** |
    | Throughput | 1000 | 1900 | **1.9x** |

  - **ä¸ºä»€ä¹ˆthroughputæå‡æ¥è¿‘2å€ï¼Ÿ**
    - Cache hit â†’ è·³è¿‡prefill â†’ ç›´æ¥decode
    - Prefillæ˜¯è®¡ç®—å¯†é›†çš„ï¼ˆå¯èƒ½100-500msï¼‰
    - Decodeæ˜¯å¸¦å®½å¯†é›†çš„ï¼ˆ~10-50ms/tokenï¼‰
    - Hit rateä»20% â†’ 75%æ„å‘³ç€ï¼š
      - 55%çš„è¯·æ±‚è·³è¿‡prefill
      - æ¯ä¸ªè¯·æ±‚èŠ‚çœ~200ms
      - æ€»ååæå‡~1.9å€

  - **åœºæ™¯åˆ†æ**ï¼š
    - **æœ€ä½³åœºæ™¯**ï¼š
      - âœ… å¤§é‡å…±äº«prefixï¼ˆsystem promptã€RAG documentsï¼‰
      - âœ… Multi-worker DPéƒ¨ç½²ï¼ˆâ‰¥2 workersï¼‰
      - âœ… é«˜å¹¶å‘ï¼ˆ>100 requests/sï¼‰

    - **æ”¶ç›Šè¾ƒå°åœºæ™¯**ï¼š
      - âŒ å•workeréƒ¨ç½²ï¼ˆæ— éœ€load balancerï¼‰
      - âŒ è¯·æ±‚å‡ ä¹æ— å…±äº«prefixï¼ˆcache hitç‡æœ¬æ¥å°±ä½ï¼‰
      - âŒ ä½å¹¶å‘ï¼ˆload balancerå¼€é”€ç›¸å¯¹è¾ƒå¤§ï¼‰

  **7.4.6.5 sglang-router: Rustå®ç°**

  - **ä¸ºä»€ä¹ˆç”¨Rustï¼Ÿ**
    - Pythonå®ç°å¤ªæ…¢ï¼ˆload balanceræ˜¯hot pathï¼‰
    - Rustå®ç°æ¯”Pythonå¿«**2å€**ï¼ˆSGLangå®æµ‹ï¼‰

  - **sglang-router standalone package**ï¼š
    ```bash
    # å®‰è£…sglang-router
    pip install sglang-router

    # å¯åŠ¨router
    sglang-router \
      --backend-url http://worker1:8000 \
      --backend-url http://worker2:8000 \
      --backend-url http://worker3:8000 \
      --port 8080

    # è¯·æ±‚å‘é€åˆ°router:8080
    # Routerè‡ªåŠ¨è·¯ç”±åˆ°æœ€ä¼˜worker
    curl http://localhost:8080/v1/chat/completions \
      -H "Content-Type: application/json" \
      -d '{
        "model": "meta-llama/Llama-3-8B",
        "messages": [{"role": "user", "content": "Hello"}]
      }'
    ```

  - **æ¶æ„**ï¼š
    ```
    Client
       â”‚
       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  sglang-router (Rust)          â”‚
    â”‚  - Radix Tree approximation    â”‚
    â”‚  - Intelligent routing         â”‚
    â”‚  - Health checks               â”‚
    â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚          â”‚          â”‚
       â–¼          â–¼          â–¼
    Worker 1   Worker 2   Worker 3
    (Python)   (Python)   (Python)
    ```

  - **Multi-nodeåˆ†å¸ƒå¼éƒ¨ç½²**ï¼š
    ```bash
    # Node 1: Router + Worker
    sglang-router \
      --backend-url http://node1:8000 \
      --backend-url http://node2:8000 \
      --backend-url http://node3:8000 \
      --port 8080

    python -m sglang.launch_server \
      --model meta-llama/Llama-3-8B \
      --port 8000

    # Node 2: Worker only
    python -m sglang.launch_server \
      --model meta-llama/Llama-3-8B \
      --port 8000

    # Node 3: Worker only
    python -m sglang.launch_server \
      --model meta-llama/Llama-3-8B \
      --port 8000
    ```

  **7.4.6.6 å®æˆ˜æ¡ˆä¾‹**

  - **æ¡ˆä¾‹ï¼šRAGç³»ç»Ÿéƒ¨ç½²**ï¼š
    ```yaml
    # åœºæ™¯ï¼š
    # - 1000ä¸ªå›ºå®šdocumentsï¼ˆä½œä¸ºRAG knowledge baseï¼‰
    # - æ¯ä¸ªqueryåŒ…å«1-3ä¸ªdocumentsä½œä¸ºcontext
    # - ç›®æ ‡ï¼šæœ€å¤§åŒ–KV cacheå¤ç”¨

    # é…ç½®
    workers: 4
    documents: 1000
    cache_policy: radix

    # ä½¿ç”¨Cache-Aware Load Balancer
    router:
      type: sglang-router
      strategy: cache_aware
      workers:
        - url: http://worker1:8000
        - url: http://worker2:8000
        - url: http://worker3:8000
        - url: http://worker4:8000
    ```

    **æ€§èƒ½å¯¹æ¯”**ï¼š
    | Load Balancer | Cache Hit Rate | Throughput | P50 Latency |
    |---------------|----------------|------------|-------------|
    | Round-Robin | 20% | 1000 req/s | 150ms |
    | Cache-Aware | 75% | 1900 req/s | 80ms |

    - **åˆ†æ**ï¼š
      - Cache hitç‡æå‡3.8å€
      - Throughputæå‡1.9å€
      - Latencyé™ä½47%

  - **æ¡ˆä¾‹ï¼šChatbot with System Prompt**ï¼š
    ```python
    # System promptï¼ˆæ‰€æœ‰è¯·æ±‚å…±äº«ï¼‰
    SYSTEM_PROMPT = """
    You are a helpful assistant.
    You answer questions concisely.
    You use markdown formatting.
    """

    # æ‰€æœ‰è¯·æ±‚çš„tokenséƒ½ä»¥SYSTEM_PROMPTå¼€å¤´
    # Cache-Aware Load Balancerä¼šå°†ç›¸ä¼¼è¯·æ±‚è·¯ç”±åˆ°åŒä¸€worker

    # Worker 1: 100ä¸ªè¯·æ±‚éƒ½åŒ…å«SYSTEM_PROMPT
    # Worker 2: 100ä¸ªè¯·æ±‚éƒ½åŒ…å«SYSTEM_PROMPT
    # ...

    # ç»“æœï¼šCache hitç‡ > 90%
    ```

  **7.4.6.7 æ€»ç»“ä¸æœ€ä½³å®è·µ**

  - **ä½•æ—¶ä½¿ç”¨Cache-Aware Load Balancerï¼Ÿ**
    - âœ… Multi-worker DPéƒ¨ç½²ï¼ˆâ‰¥2 workersï¼‰
    - âœ… å¤§é‡å…±äº«prefixï¼ˆsystem promptã€RAG docsï¼‰
    - âœ… é«˜å¹¶å‘åœºæ™¯ï¼ˆ>100 req/sï¼‰
    - âœ… ä½¿ç”¨SGLangæˆ–Radix Cache

  - **ä½•æ—¶ä¸éœ€è¦ï¼Ÿ**
    - âŒ å•workeréƒ¨ç½²
    - âŒ è¯·æ±‚å‡ ä¹æ— å…±äº«prefix
    - âŒ ä½å¹¶å‘ï¼ˆ<10 req/sï¼‰
    - âŒ ä½¿ç”¨PagedAttentionï¼ˆvLLMï¼‰

  - **é…ç½®å»ºè®®**ï¼š
    ```bash
    # SGLang v0.4+ï¼šè‡ªåŠ¨å¯ç”¨Cache-Aware Load Balancer
    python -m sglang.launch_server \
      --model meta-llama/Llama-3-8B \
      --dp 4 \
      --radix-cache

    # ä½¿ç”¨sglang-router
    pip install sglang-router
    sglang-router \
      --backend-url http://localhost:8000 \
      --backend-url http://localhost:8001 \
      --backend-url http://localhost:8002 \
      --backend-url http://localhost:8003
    ```

#### 7.5 é«˜çº§è°ƒåº¦ç­–ç•¥
- 7.5.1 ä¼˜å…ˆçº§è°ƒåº¦
- 7.5.2 æœ€çŸ­ä½œä¸šä¼˜å…ˆ (SJF)
- 7.5.3 è½®è¯¢è°ƒåº¦
- 7.5.4 è‡ªé€‚åº”è°ƒåº¦

#### 7.6 å®æˆ˜é…ç½®
- 7.6.1 vLLMè°ƒåº¦å‚æ•°è°ƒä¼˜
- 7.6.2 ä¸åŒåœºæ™¯çš„è°ƒåº¦ç­–ç•¥

#### 7.7 Prefill-Decodeåˆ†ç¦»ï¼ˆPDåˆ†ç¦»ï¼‰âš ï¸ æŠ€æœ¯è¯„ä¼°ä¸­

> **ğŸ’¡ 2025å¹´æŠ€æœ¯è¶‹åŠ¿**ï¼šPDåˆ†ç¦»åœ¨2025å¹´ä»æ¦‚å¿µå¿«é€Ÿæ¼”è¿›ä¸ºç”Ÿäº§æ ‡å‡†ã€‚vLLMã€SGLangç­‰ä¸»æµæ¡†æ¶éƒ½å·²æ”¯æŒï¼Œå‡ ä¹æ‰€æœ‰å‚å•†éƒ½åœ¨é‡‡ç”¨è¿™ç§æ¶æ„ã€‚

- 7.7.1 ä»€ä¹ˆæ˜¯PDåˆ†ç¦»
  - Prefillé˜¶æ®µï¼šå¹¶è¡Œå¤„ç†promptï¼Œè®¡ç®—å¯†é›†
  - Decodeé˜¶æ®µï¼šä¸²è¡Œç”Ÿæˆtokenï¼Œå†…å­˜å¸¦å®½å¯†é›†
  - ä¸¤ç§é˜¶æ®µçš„è®¡ç®—æ¨¡å¼å·®å¼‚
  - ä¸ºä»€ä¹ˆéœ€è¦åˆ†ç¦»ï¼Ÿ

- 7.7.2 PDåˆ†ç¦»çš„æ¶æ„æ¼”è¿›
  - 2025å¹´åˆï¼šæ¦‚å¿µæå‡º
  - 2025å¹´ä¸­ï¼švLLMã€SGLangç­‰ç¤¾åŒºåˆä½œå®ç°
  - 2025å¹´åº•ï¼šæˆä¸ºç”Ÿäº§æ ‡å‡†æ¶æ„
  - ä»æ¦‚å¿µåˆ°ç”Ÿäº§åªç”¨äº†ä¸€å¹´

- 7.7.3 PDåˆ†ç¦»çš„æŠ€æœ¯ä¼˜åŠ¿
  - **å¼‚æ„éƒ¨ç½²**ï¼šPrefillç”¨è®¡ç®—èƒ½åŠ›å¼ºçš„GPUï¼ŒDecodeç”¨å¸¦å®½å¤§çš„GPU
  - **èµ„æºéš”ç¦»**ï¼šé¿å…é•¿è¯·æ±‚é˜»å¡çŸ­è¯·æ±‚
  - **å¼¹æ€§æ‰©å±•**ï¼šPrefillå’ŒDecodeå¯ç‹¬ç«‹æ‰©ç¼©å®¹
  - **æ€§èƒ½ä¼˜åŒ–**ï¼šé’ˆå¯¹ä¸åŒé˜¶æ®µåšä¸“é—¨ä¼˜åŒ–

- 7.7.4 vLLMçš„PDåˆ†ç¦»å®ç°
  - æ¶æ„è®¾è®¡ï¼šPrefill worker + Decode worker
  - é€šä¿¡æœºåˆ¶ï¼šKV Cacheçš„ä¼ è¾“
  - è°ƒåº¦ç­–ç•¥ï¼šå¦‚ä½•åˆ†é…è¯·æ±‚åˆ°ä¸åŒworker
  - æ€§èƒ½æå‡ï¼šååé‡å’Œå»¶è¿Ÿçš„æ”¹å–„

- 7.7.5 SGLangçš„PDåˆ†ç¦»å®è·µ
  - RadixAttentionï¼šç»Ÿä¸€çš„æ³¨æ„åŠ›æŠ½è±¡
  - è‡ªåŠ¨åˆ†ç¦»ï¼šæ— éœ€æ‰‹åŠ¨é…ç½®
  - ç”Ÿäº§ç»éªŒï¼šç¨³å®šæ€§ã€æ€§èƒ½ç›‘æ§

- 7.7.6 PDåˆ†ç¦»çš„æŒ‘æˆ˜
  - **KV Cacheä¼ è¾“**ï¼šç½‘ç»œå¼€é”€å’Œåºåˆ—åŒ–
  - **è´Ÿè½½å‡è¡¡**ï¼šPrefillå’ŒDecodeçš„é€Ÿç‡åŒ¹é…
  - **å®¹é”™å¤„ç†**ï¼šWorkeræ•…éšœå¦‚ä½•æ¢å¤
  - **å¤æ‚åº¦å¢åŠ **ï¼šéƒ¨ç½²å’Œè¿ç»´çš„æŒ‘æˆ˜

- 7.7.7 å®æˆ˜æ¡ˆä¾‹
  - æ¡ˆä¾‹1ï¼šå•æœºGPUçš„PDåˆ†ç¦»
  - æ¡ˆä¾‹2ï¼šè·¨æœºå™¨çš„PDåˆ†ç¦»éƒ¨ç½²
  - æ¡ˆä¾‹3ï¼šå¼‚æ„GPUï¼ˆH100+H200ï¼‰çš„å®è·µ
  - æ€§èƒ½å¯¹æ¯”ï¼šPDåˆ†ç¦» vs é›†æˆéƒ¨ç½²

#### å¸¸è§è¯¯åŒºä¸“æ 
#### å®æˆ˜æ£€æŸ¥æ¸…å•
#### åŠ¨æ‰‹ç»ƒä¹ 
- ç»ƒä¹ 6.1ï¼šå¯¹æ¯”é™æ€æ‰¹å¤„ç†å’ŒåŠ¨æ€æ‰¹å¤„ç†
- ç»ƒä¹ 6.2ï¼šé’ˆå¯¹ä¸åŒåœºæ™¯ä¼˜åŒ–è°ƒåº¦å‚æ•°
- ç»ƒä¹ 6.3ï¼šä½¿ç”¨vLLMéƒ¨ç½²PDåˆ†ç¦»æ¶æ„ â­

---

### ç¬¬8ç«  é‡åŒ–æŠ€æœ¯

> **ğŸ’° æˆæœ¬å½±å“**ï¼ˆåŸºäºè¡Œä¸šæ•°æ®ï¼‰
> - **æ˜¾å­˜èŠ‚çœ**ï¼šINT8é‡åŒ–èŠ‚çœ50%æ˜¾å­˜ï¼ŒINT4èŠ‚çœ75%
> - **æˆæœ¬é™ä½**ï¼šåŒæ ·æ¨¡å‹å¯åœ¨æ›´å°/æ›´ä¾¿å®œçš„GPUä¸Šè¿è¡Œ
> - **ç²¾åº¦æŸå¤±**ï¼šç°ä»£é‡åŒ–æŠ€æœ¯ç²¾åº¦æŸå¤±<1%
> - **ç¡¬ä»¶æ•ˆç‡**ï¼šINT8æ¨ç†é€Ÿåº¦æ¯”FP16å¿«2-3å€
> - **æç«¯å‹ç¼©**ï¼šINT4 QATå¯å°†~1TBæ¨¡å‹å‹ç¼©åˆ°å•H200ï¼ˆ7å€å‹ç¼©ï¼‰â­

#### 8.1 é‡åŒ–åŸºç¡€
- 8.1.1 ä»€ä¹ˆæ˜¯é‡åŒ–
- 8.1.2 ä¸ºä»€ä¹ˆé‡åŒ–èƒ½èŠ‚çœæ˜¾å­˜
- 8.1.3 ç²¾åº¦vsæ€§èƒ½çš„æƒè¡¡
- 8.1.4 ä¸ºä»€ä¹ˆé‡åŒ–æœ‰æ•ˆï¼šæ¨¡å‹çš„å†—ä½™æ€§

#### 8.2 é‡åŒ–æ–¹æ³•åˆ†ç±»
- 8.2.1 PTQ (Post-Training Quantization)
  - è®­ç»ƒåé‡åŒ–ï¼Œæ— éœ€é‡æ–°è®­ç»ƒ
  - é€Ÿåº¦å¿«ï¼Œé€‚åˆå¿«é€Ÿéƒ¨ç½²
  - å¯èƒ½æœ‰ä¸€å®šç²¾åº¦æŸå¤±
  - å¸¸è§æ–¹æ³•ï¼šGPTQã€AWQã€bitsandbytes
- 8.2.2 QAT (Quantization-Aware Training) â­
  - é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼Œåœ¨è®­ç»ƒæ—¶æ¨¡æ‹Ÿé‡åŒ–
  - ç²¾åº¦æŸå¤±æ›´å°ï¼Œtrain-inferä¸€è‡´æ€§å¥½
  - éœ€è¦å®Œæ•´è®­ç»ƒå‘¨æœŸ
  - é€‚ç”¨äºRLè®­ç»ƒå’Œéœ€è¦é«˜ç²¾åº¦çš„åœºæ™¯
- 8.2.3 QLoRA vs Native Quantized Training vs QAT
  - QLoRAï¼šé™ä½LoRAå¾®è°ƒçš„è®­ç»ƒå†…å­˜
  - Native Quantized Trainingï¼šç«¯åˆ°ç«¯ä½ç²¾åº¦è®­ç»ƒ
  - QATï¼šæ”¹å–„é‡åŒ–æ¨ç†ç²¾åº¦
  - å¯¹æ¯”è¡¨æ ¼ï¼šç›®çš„ã€é€‚ç”¨åœºæ™¯ã€ä¼˜ç¼ºç‚¹
- 8.2.4 é‡åŒ–æ–¹æ³•é€‰æ‹©å†³ç­–æ ‘
  - åœºæ™¯1ï¼šå¿«é€Ÿéƒ¨ç½² â†’ PTQ
  - åœºæ™¯2ï¼šç²¾åº¦è¦æ±‚é«˜ â†’ QAT
  - åœºæ™¯3ï¼šéœ€è¦å¾®è°ƒ â†’ QLoRAæˆ–QAT
  - åœºæ™¯4ï¼šRLè®­ç»ƒ â†’ QAT

#### 8.3 å¸¸ç”¨é‡åŒ–æ ¼å¼
- 8.3.1 FP32 (32ä½æµ®ç‚¹) - è®­ç»ƒæ ‡å‡†
- 8.3.2 FP16/BF16 (16ä½æµ®ç‚¹) - æ¨ç†å¸¸ç”¨
- 8.3.3 INT8 (8ä½æ•´æ•°) - ç»å…¸é‡åŒ–
- 8.3.4 INT4 (W4A16) â­
  - 4ä½æƒé‡ï¼Œ16ä½æ¿€æ´»
  - å¹¿æ³›çš„ç¡¬ä»¶æ”¯æŒï¼ˆBlackwellä¹‹å‰çš„GPUï¼‰
  - å·¥ä¸šç•Œ"è¶³å¤Ÿå¥½"çš„æ ‡å‡†
  - 75%æ˜¾å­˜èŠ‚çœ
- 8.3.5 FP4 vs INT4
  - ç²¾åº¦å¯¹æ¯”ï¼šFP4è¡¨ç¤ºèŒƒå›´æ›´å¤§ï¼ŒINT4æ›´ç¨³å®š
  - æ€§èƒ½å¯¹æ¯”ï¼šFP4ç†è®ºæ›´é«˜ï¼ŒINT4ç”Ÿæ€æ›´æˆç†Ÿ
  - ç¡¬ä»¶æ”¯æŒï¼šINT4æ›´å¹¿æ³›ï¼ŒFP4éœ€è¦Blackwell
  - é€‰æ‹©å»ºè®®ï¼šå½“å‰é€‰INT4ï¼Œæœªæ¥è€ƒè™‘FP4
- 8.3.6 FP8 / NVFP4ï¼šæœªæ¥æ–¹å‘
  - NVIDIA Blackwellçš„åŸç”ŸFP4/FP8æ”¯æŒ
  - H100/H200çš„FP8æ”¯æŒ
  - æ€§èƒ½æå‡æ½œåŠ›
- 8.3.7 AWQ / GPTQï¼šæµè¡Œçš„INT4æ ¼å¼
  - AWQï¼šActivation-aware Quantization
  - GPTQï¼šGradient-based Post-Training Quantization
  - æ€§èƒ½å’Œç²¾åº¦å¯¹æ¯”

#### 8.4 æµè¡Œçš„é‡åŒ–æ¡†æ¶
- 8.4.1 vLLMé‡åŒ–æ”¯æŒ
  - AWQã€GPTQã€bitsandbytes
  - KV Cacheé‡åŒ–
  - PagedAttention + é‡åŒ–
- 8.4.2 SGLang INT4æ¨ç† â­
  - Marlinå†…æ ¸æ”¯æŒ
  - W4A16é«˜æ•ˆæ¨ç†
  - Bit packingå’Œè¿‘é›¶å¼€é”€è§£åŒ…
  - MoEç®—å­æ·±åº¦èåˆ
  - æ”¯æŒGPTQã€AWQæ ¼å¼
- 8.4.3 NVIDIA Model Optimizer â­
  - QATè®­ç»ƒæ”¯æŒ
  - Megatron-LMé›†æˆ
  - MXFP4ã€NVFP4æ ¼å¼æ”¯æŒ
  - Fake quantizationå®ç°
- 8.4.4 AutoGPTQ / llama.cpp
  - å¼€æºé‡åŒ–å·¥å…·
  - CPUæ¨ç†æ”¯æŒ

#### 8.5 KV Cacheé‡åŒ–
- 8.5.1 ä¸ºä»€ä¹ˆé‡åŒ–KV Cache
  - KV Cacheå ç”¨æ˜¾å­˜çš„50%+
  - é•¿ä¸Šä¸‹æ–‡åœºæ™¯å°¤å…¶é‡è¦
- 8.5.2 KV Cacheé‡åŒ–æ–¹æ³•
  - INT8 KV Cache
  - åŠ¨æ€é‡åŒ–vsé™æ€é‡åŒ–
  - Per-tokené‡åŒ–
- 8.5.3 ç²¾åº¦ä¸é€Ÿåº¦å¹³è¡¡
  - ç²¾åº¦æŸå¤±è¯„ä¼°
  - æ€§èƒ½æå‡
  - ç”Ÿäº§ç¯å¢ƒæ³¨æ„äº‹é¡¹

#### 8.6 å®æˆ˜ï¼šé‡åŒ–éƒ¨ç½²
- 8.6.1 ä½¿ç”¨vLLMåŠ è½½é‡åŒ–æ¨¡å‹
  - AWQ/GPTQæ¨¡å‹åŠ è½½
  - æ€§èƒ½å¯¹æ¯”æµ‹è¯•
  - ç²¾åº¦æŸå¤±è¯„ä¼°
- 8.6.2 ä½¿ç”¨SGLangéƒ¨ç½²INT4æ¨¡å‹ â­
  - W4A16æ¨ç†é…ç½®
  - Marlinå†…æ ¸å¯ç”¨
  - æ€§èƒ½benchmark
- 8.6.3 ç”Ÿäº§ç¯å¢ƒæ³¨æ„äº‹é¡¹
  - æ¨¡å‹æ ¼å¼é€‰æ‹©
  - ç¡¬ä»¶è¦æ±‚
  - ç›‘æ§æŒ‡æ ‡

#### 8.7 é‡åŒ–è¿›é˜¶ï¼šINT4 QATå®æˆ˜ âš ï¸ SGLangå›¢é˜ŸéªŒè¯

> **ğŸ’¡ æ¡ˆä¾‹æ¥æº**: SGLang RL Team, InfiXAI Team, Ant Group (2026-01-26)
>
> **æ ¸å¿ƒæˆæœ**: å°†~1TBè§„æ¨¡çš„æ¨¡å‹å‹ç¼©åˆ°å•å¼ H200 (141GB)ï¼Œæ¶ˆé™¤è·¨èŠ‚ç‚¹é€šä¿¡ç“¶é¢ˆï¼Œæ˜¾è‘—æå‡rolloutæ•ˆç‡

- 8.7.1 ä»€ä¹ˆæ˜¯QAT
  - Fake QuantizationåŸç†
  - STE (Straight-Through Estimator)åŸç†
  - train-inferä¸€è‡´æ€§çš„é‡è¦æ€§
  - æ¶ˆèå®éªŒï¼šQAT vs PTQçš„ç²¾åº¦å·®å¼‚

- 8.7.2 INT4 QATå®Œæ•´Pipeline
  - **Stage 1: QATè®­ç»ƒï¼ˆæ¨¡æ‹Ÿé‡åŒ–ï¼‰**
    - ç»´æŠ¤BF16ä¸»æƒé‡
    - å‰å‘ä¼ æ’­ï¼šfake quantizationæ¨¡æ‹Ÿé‡åŒ–å™ªå£°
    - åå‘ä¼ æ’­ï¼šSTEç¡®ä¿æ¢¯åº¦æ— æŸä¼ é€’
  - **Stage 2: æƒé‡è½¬æ¢ï¼ˆçœŸé‡åŒ–ï¼‰**
    - å¯¼å‡ºæ”¶æ•›çš„BF16æƒé‡
    - æ‰§è¡ŒçœŸæ­£çš„é‡åŒ–ï¼šBF16 â†’ INT4
    - è½¬æ¢ä¸ºMarlinæ ¼å¼
  - **Stage 3: W4A16æ¨ç†**
    - SGLangåŠ è½½INT4æƒé‡
    - é«˜æ•ˆæ¨ç†ï¼ˆINT4æƒé‡ Ã— BF16æ¿€æ´»ï¼‰
    - ç”Ÿæˆçš„ç»éªŒæ•°æ®å›æµåˆ°è®­ç»ƒ

- 8.7.3 è®­ç»ƒç«¯å®ç°
  - Fake Quantizationå’ŒSTEå®ç°
    - _FakeInt4QuantizationSTEç±»
    - åŠ¨æ€é‡åŒ–ï¼šper-group max absolute value
    - æ¨¡æ‹ŸINT4çš„[-7, 7]èŒƒå›´
  - æƒé‡æ›´æ–°å’Œæ ¼å¼é€‚é…
    - restore_weights_before_loadingæœºåˆ¶
    - åŠ¨æ€æƒé‡ç®¡ç†ï¼šprocess_weights_after_loading
    - Marlinæ ¼å¼è½¬æ¢
  - æ¶ˆèå®éªŒï¼šQATçš„å¿…è¦æ€§
    - å®éªŒ1ï¼šQAT INT4è®­ç»ƒ + BF16 rolloutï¼ˆè¯¯å·®ä»é«˜ï¼‰
    - å®éªŒ2ï¼šä¸å¯ç”¨QAT + ç›´æ¥INT4 rolloutï¼ˆè¯¯å·®éœ‡è¡ä¸Šå‡ï¼‰
    - **ç»“è®º**ï¼šè®­ç»ƒå’Œæ¨ç†å¿…é¡»åŒæ—¶å¯ç”¨é‡åŒ–

- 8.7.4 æ¨ç†ç«¯å®ç°
  - SGLang W4A16æ¨ç†
    - Bit packingï¼š8ä¸ªINT4å€¼æ‰“åŒ…åˆ°1ä¸ªINT32
    - é«˜æ•ˆè§£åŒ…ï¼šä½è¿ç®—ï¼ˆ>> 4 å’Œ & 0xFï¼‰
    - è®¡ç®—å’ŒIOé‡å ï¼Œè§£åŒ…è¿‘é›¶å¼€é”€
  - MoEç®—å­æ·±åº¦èåˆ
    - åŠ¨æ€moe_align_block_size
    - Gatingéƒ¨åˆ†èåˆä¸ºå•ä¸€å†…æ ¸
    - é¿å…é‡å¤kernelå¯åŠ¨

- 8.7.5 å®æˆ˜æ¡ˆä¾‹ï¼š1TBæ¨¡å‹å‹ç¼©åˆ°å•H200
  - **æ¡ˆä¾‹1ï¼šQwen3-235B-A22B**
    - Raw-Rewardï¼šç¨³å®šå¢é•¿ï¼Œä¸BF16/FP8è¶‹åŠ¿ä¸€è‡´
    - AIMEè¯„ä¼°ï¼šæ–œç‡å’Œå³°å€¼ä¸BF16é«˜åº¦å¯¹é½
    - Train-Infer Gapï¼šå‡ ä¹é‡å BF16 baseline
  - **æ¡ˆä¾‹2ï¼šKimi-K2-Thinking**
    - åŒèŠ‚ç‚¹ï¼šå—é™äºè·¨èŠ‚ç‚¹å¸¦å®½
    - å•èŠ‚ç‚¹ï¼šINT4æ¶ˆé™¤é€šä¿¡ç“¶é¢ˆï¼Œå¤§å¹…æå‡
  - **æ€§èƒ½å¯¹æ¯”**ï¼š
    - ç²¾åº¦ï¼šINT4 QAT â‰ˆ BF16 > FP8
    - é€Ÿåº¦ï¼šINT4 â‰ˆ FP8 > BF16 (Hç³»åˆ—GPU)
    - æ˜¾å­˜ï¼šINT4èŠ‚çœ75% (å…³é”®ä¼˜åŠ¿)

- 8.7.6 QATçš„é€‚ç”¨åœºæ™¯
  - âœ… å¤§è§„æ¨¡RLè®­ç»ƒï¼ˆ100B+å‚æ•°ï¼‰
  - âœ… éœ€è¦å•èŠ‚ç‚¹éƒ¨ç½²è¶…å¤§æ¨¡å‹
  - âœ… éœ€è¦train-inferä¸€è‡´æ€§
  - âœ… PTQç²¾åº¦æŸå¤±ä¸å¯æ¥å—
  - âš ï¸ è®­ç»ƒæˆæœ¬è¾ƒé«˜ï¼ˆéœ€è¦å®Œæ•´å¾®è°ƒå‘¨æœŸï¼‰
  - âš ï¸ å®ç°å¤æ‚åº¦è¾ƒé«˜ï¼ˆéœ€è¦ç†è§£QATã€STEã€æ ¼å¼è½¬æ¢ï¼‰
  - âŒ å°è§„æ¨¡æ¨¡å‹ï¼ˆæˆæœ¬ä¸å€¼å¾—ï¼‰
  - âŒ åªæ¨ç†ä¸éœ€è¦å¾®è°ƒï¼ˆç”¨PTQå³å¯ï¼‰

#### 8.8 ç²¾åº¦å¯¹é½ï¼šTrain vs Inference âš ï¸ å·¥ä¸šç•Œå®è·µ

> **ğŸ’¡ å·¥ä¸šç•Œå®è·µ**ï¼ˆæ¥æºï¼š2025"é’ç¨"AIå˜‰å¹´å - æœ±ç«‹è€•@NVIDIAï¼‰
>
> **æ ¸å¿ƒæ´å¯Ÿ**ï¼šä½ç²¾åº¦è®­ç»ƒä¸ç¨³å®šçš„æ ¹æœ¬åŸå› å¾€å¾€ä¸æ˜¯ä½ç²¾åº¦æœ¬èº«ï¼Œè€Œæ˜¯è®­ç»ƒå’Œæ¨ç†ä½¿ç”¨çš„ç®—å­ç²¾åº¦ä¸å¯¹é½ã€‚
>
> **å¤§å›¢é˜Ÿçš„åšæ³•**ï¼šTrainå’ŒInferenceçš„ç®—å­åœ¨åŒä¸€ä¸ªå¤§çš„wrapperé‡Œç»´æŠ¤ï¼Œç²¾åº¦é—®é¢˜å°±ä¸æ˜¯é—®é¢˜ã€‚
> **å¼€æºç¤¾åŒºçš„é—®é¢˜**ï¼šTrainå’ŒInferenceæ˜¯ä¸¤å¸®äººåšï¼Œç®—å­æ²¡å¯¹é½å¯¼è‡´accuracyä¸ç¨³å®šã€‚

- 8.8.1 ç²¾åº¦ä¸å¯¹é½çš„é—®é¢˜
  - è®­ç»ƒæ—¶ï¼šè‡ªå®šä¹‰kernelï¼ˆå¦‚è‡ªå·±å†™çš„Flash Attentionï¼‰
  - æ¨ç†æ—¶ï¼šç¤¾åŒºä¼˜åŒ–çš„kernelï¼ˆå¦‚SGLangçš„Flash Attentionï¼‰
  - ç»“æœï¼šNumerical gapå¯¼è‡´accuracyä¸ç¨³å®š
  - è¡¨ç°ï¼šTraining loss spikeã€æœ€ç»ˆaccuracyæ‰ç‚¹

- 8.8.2 ä¸ºä»€ä¹ˆç²¾åº¦ä¸å¯¹é½ï¼Ÿ
  - **å¼€å‘å›¢é˜Ÿåˆ†ç¦»**ï¼šTraining teamå’ŒInference teamå„è‡ªä¼˜åŒ–
  - **ä¼˜åŒ–ç›®æ ‡ä¸åŒ**ï¼šTrainingå…³æ³¨æ”¶æ•›ï¼ŒInferenceå…³æ³¨é€Ÿåº¦
  - **å®ç°ç»†èŠ‚å·®å¼‚**ï¼šä¸åŒçš„ç®—æ³•ã€ä¸åŒçš„æ•°å€¼å¤„ç†
  - **æµ‹è¯•åœºæ™¯ä¸åŒ**ï¼šTrainingç”¨åˆæˆæ•°æ®ï¼ŒInferenceç”¨çœŸå®æ•°æ®

- 8.8.3 å¦‚ä½•ç¡®ä¿ç²¾åº¦å¯¹é½
  - **æ–¹æ³•1ï¼šç»Ÿä¸€ç®—å­åº“**ï¼ˆæ¨èï¼‰
    - Trainå’ŒInferenceä½¿ç”¨åŒä¸€å¥—ç®—å­
    - åœ¨åŒä¸€ä¸ªwrapperé‡Œç»´æŠ¤
    - å¤§å›¢é˜Ÿï¼ˆå¦‚NVIDIAï¼‰çš„å®è·µ
  - **æ–¹æ³•2ï¼šæ•°å€¼å¯¹é½æµ‹è¯•**
    - ä½¿ç”¨ç›¸åŒè¾“å…¥æµ‹è¯•Trainå’ŒInferenceç®—å­
    - æ¯”è¾ƒè¾“å‡ºå·®å¼‚ï¼ˆå¦‚ç»å¯¹è¯¯å·®<1e-5ï¼‰
    - å»ºç«‹CI/CD pipelineè‡ªåŠ¨æ£€æµ‹
  - **æ–¹æ³•3ï¼šç«¯åˆ°ç«¯éªŒè¯**
    - è®­ç»ƒåç›´æ¥åœ¨æ¨ç†æ¡†æ¶ä¸­æµ‹è¯•
    - æ¯”è¾ƒè®­ç»ƒæ—¶å’Œæ¨ç†æ—¶çš„output
    - å‘ç°å¹¶ä¿®å¤ç²¾åº¦regression

- 8.8.4 ä¸åŒä»»åŠ¡å¯¹ç²¾åº¦çš„æ•æ„Ÿåº¦
  - **LLM**ï¼šç¦»æ•£é‡‡æ ·ï¼Œå¯¹ä½ç²¾åº¦å®¹å¿åº¦é«˜
  - **Diffusion**ï¼šè¿ç»­ç©ºé—´é‡‡æ ·ï¼Œè¯¯å·®ç´¯ç§¯ä¸¥é‡
    - FP4å¯èƒ½æ‰10-20ä¸ªç‚¹ï¼ˆå¼ åšæ¶µ@æµ™å¤§ï¼‰
    - éœ€è¦ç‰¹æ®Šçš„clippingå’Œä¿®æ­£
  - **æ¨è**ï¼šDiffusionæ¨¡å‹è‡³å°‘ä½¿ç”¨FP8

- 8.8.5 ä½ç²¾åº¦çš„è½¯ä»¶æŠ½è±¡å¤æ‚åº¦
  - **BF16/FP16**ï¼šä¸€ä¸ªtensorå°±æ˜¯ä¸€ä¸ªæ•°æ®
  - **FP8**ï¼šä¸€ä¸ªweightå˜æˆ3ä¸ªtensorï¼ˆdata + scale + metadataï¼‰
  - **FP4**ï¼šéœ€è¦paddingã€packç­‰æ“ä½œ
    - PyTorchæœ€å°‘1 byteï¼Œéœ€è¦pack 2ä¸ªFP4
    - è½¯ä»¶ç”Ÿæ€éœ€è¦å¤§è§„æ¨¡æ¼”è¿›
  - **æŒ‘æˆ˜**ï¼šç”¨æˆ·å¿ƒæ™ºè´Ÿæ‹…å¤§ï¼Œå¦‚ä½•å¹³è¡¡æ”¶ç›Šå’Œå¤æ‚åº¦

- 8.8.6 ä½ç²¾åº¦è®­ç»ƒçš„ç¨³å®šæ€§é—®é¢˜
  - **å¸¸è§ç—‡çŠ¶**ï¼š
    - è®­ç»ƒåˆ°ä¸€åŠlossç‚¸äº†
    - åŒæ ·taské«˜ç²¾åº¦æ²¡é—®é¢˜ï¼Œä½ç²¾åº¦ç›´æ¥èµ·é£
    - é«˜ç²¾åº¦accuracyæŒºå¥½ï¼Œä½ç²¾åº¦ç¬é—´æ‰3-4ä¸ªç‚¹
  - **æ ¹æœ¬åŸå› **ï¼š
    - ä¸å…¨æ˜¯ç²¾åº¦é—®é¢˜ï¼Œè€Œæ˜¯ç®—æ³•æ²¡è°ƒå¥½ï¼ˆå¼ æ˜æ˜Ÿ@æ¸…åï¼‰
    - Loss controlã€data mixingã€curriculum learningç­‰
  - **è§£å†³æ–¹å‘**ï¼š
    - æŠŠå„ç§"å†…ç§‘"ï¼ˆå¼ æ˜æ˜Ÿè¯­ï¼‰æ£€æŸ¥å¾—æ›´ç»†
    - ä¸è¦ä¸Šæ¥å°±æå¾ˆéš¾çš„é¢˜ç›®ï¼Œä»ç®€å•å¼€å§‹
    - ä½ç²¾åº¦å¯èƒ½å¼•å…¥å™ªå£°ï¼Œåè€Œæœ‰åŠ©äºæ”¶æ•›ï¼ˆKimi K2çš„INT4ç»éªŒï¼‰

- 8.8.7 ä»å†å²çœ‹ç²¾åº¦æ¼”è¿›ï¼ˆæœ±ç«‹è€•@NVIDIAï¼‰
  - **FP32 â†’ FP16**ï¼šè§è¿‡ç±»ä¼¼é—®é¢˜ï¼Œæœ€ç»ˆè§£å†³
  - **FP16 â†’ BF16**ï¼šè§è¿‡ç±»ä¼¼é—®é¢˜ï¼Œæœ€ç»ˆè§£å†³
  - **BF16 â†’ FP8**ï¼šç°åœ¨æ˜¯è¿‡æ¸¡æœŸé˜µç—›
  - **ç»“è®º**ï¼šéšç€ç®—æ³•stabilizeå’Œconfigæ‘¸æ¸…ï¼Œé—®é¢˜å¯ä»¥è§£å†³
  - **å±•æœ›**ï¼šä½ç²¾åº¦æ”¶ç›Šè¿˜æ˜¯å¾ˆå¤§çš„ï¼Œå€¼å¾—æŠ•å…¥

#### 8.9 é‡åŒ–æŠ€æœ¯æ€»ç»“ä¸å±•æœ›
- 8.9.1 é‡åŒ–æŠ€æœ¯æ¼”è¿›è·¯çº¿
- 8.9.2 ä¸åŒåœºæ™¯çš„æœ€ä½³å®è·µ
- 8.9.3 æœªæ¥å‘å±•æ–¹å‘ï¼šFP4ã€NVFP4ã€Blackwell
- 8.9.4 ç®—æ³•å’Œç³»ç»Ÿçš„co-designï¼ˆå¼ åšæ¶µ@æµ™å¤§ï¼‰
  - ä¸æ˜¯ç³»ç»Ÿç­‰ç®—æ³•æˆç†Ÿ
  - ä¸æ˜¯ç®—æ³•ç­‰ç³»ç»Ÿä¼˜åŒ–
  - éœ€è¦åŒæ­¥èºæ—‹å¼ä¸Šå‡

#### å¸¸è§è¯¯åŒºä¸“æ 
- è¯¯åŒº1ï¼š"é‡åŒ–ä¸€å®šä¼šæŸå¤±ç²¾åº¦"
- è¯¯åŒº2ï¼š"INT4æ¯”INT8ç²¾åº¦ä½å¾ˆå¤š"
- è¯¯åŒº3ï¼š"QATæ€»æ˜¯æ¯”PTQå¥½"
- è¯¯åŒº4ï¼š"é‡åŒ–åªåœ¨æ¨ç†æ—¶æœ‰ç”¨"
- è¯¯åŒº5ï¼š"ä½ç²¾åº¦è®­ç»ƒä¸ç¨³å®šéƒ½æ˜¯ç²¾åº¦é—®é¢˜" â­

#### å®æˆ˜æ£€æŸ¥æ¸…å•
- [ ] ç¡®å®šé‡åŒ–ç›®æ ‡å’Œçº¦æŸ
- [ ] é€‰æ‹©åˆé€‚çš„é‡åŒ–æ–¹æ³•ï¼ˆPTQ/QATï¼‰
- [ ] é€‰æ‹©åˆé€‚çš„é‡åŒ–æ ¼å¼ï¼ˆINT8/INT4/FP8ï¼‰
- [ ] å‡†å¤‡è¯„ä¼°æ•°æ®é›†
- [ ] **è¿›è¡Œç²¾åº¦å¯¹é½æµ‹è¯•** â­
- [ ] è¿›è¡Œç²¾åº¦æµ‹è¯•
- [ ] è¿›è¡Œæ€§èƒ½æµ‹è¯•
- [ ] ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

#### åŠ¨æ‰‹ç»ƒä¹ 
- ç»ƒä¹ 7.1ï¼šå¯¹æ¯”ä¸åŒé‡åŒ–æ ¼å¼çš„æ€§èƒ½å’Œç²¾åº¦
- ç»ƒä¹ 7.2ï¼šé‡åŒ–Llama-3-70Bå¹¶æµ‹è¯•ï¼ˆä½¿ç”¨vLLM + AWQï¼‰
- ç»ƒä¹ 7.3ï¼šä½¿ç”¨SGLangéƒ¨ç½²INT4æ¨¡å‹å¹¶benchmark â­
- ç»ƒä¹ 7.4ï¼šï¼ˆè¿›é˜¶ï¼‰å®ç°ç®€å•çš„fake quantization â­
- ç»ƒä¹ 7.5ï¼šï¼ˆè¿›é˜¶ï¼‰éªŒè¯trainå’Œinferenceç®—å­çš„ç²¾åº¦å¯¹é½ â­

---

### ç¬¬9ç«  æŠ•æœºé‡‡æ ·

> **ğŸ’° æˆæœ¬å½±å“**ï¼ˆåŸºäºè¡Œä¸šæ•°æ®ï¼‰
> - **é€Ÿåº¦æå‡**ï¼šç”Ÿæˆé€Ÿåº¦å¯æå‡2-3å€
> - **æˆæœ¬é™ä½**ï¼šåŒæ ·æ—¶é—´çš„è¾“å‡ºå¢åŠ ï¼Œå•ä½tokenæˆæœ¬é™ä½
> - **é€‚ç”¨åœºæ™¯**ï¼šé•¿æ–‡æœ¬ç”Ÿæˆï¼ˆæ–‡ç« ã€ä»£ç ã€æŠ¥å‘Šï¼‰

#### 9.1 ç”ŸæˆåŠ é€Ÿçš„åŸºæœ¬æ€è·¯
- 9.1.1 ä¸ºä»€ä¹ˆè‡ªå›å½’ç”Ÿæˆæ…¢
- 9.1.2 å¹¶è¡ŒåŒ–ç”Ÿæˆçš„æŒ‘æˆ˜
- 9.1.3 æŠ•æœºæ‰§è¡Œçš„æ¦‚å¿µ

#### 9.2 æŠ•æœºé‡‡æ ·åŸç†
- 9.2.1 æ ¸å¿ƒæ€æƒ³ï¼šå°æ¨¡å‹å…ˆè¡Œ
- 9.2.2 è‰ç¨¿æ¨¡å‹ (Draft Model)
- 9.2.3 éªŒè¯è¿‡ç¨‹
- 9.2.4 å›¾è§£å®Œæ•´æµç¨‹

#### 9.3 æŠ•æœºé‡‡æ ·å˜ä½“
- 9.3.1 Speculative Decoding
- 9.3.2 Assisted Decoding
- 9.3.3 Lookahead Decoding
- 9.3.4 Eagleç³»åˆ—ï¼šEagleã€Eagle 2ã€Eagle 3 â­
  - **Eagle 3**ï¼ˆæ¥æºï¼šNVIDIA Model Optimizer + SGLangï¼‰
    - åŸºäºæŠ•æœºé‡‡æ ·çš„è®­ç»ƒcheckpoint
    - ä½¿ç”¨NVIDIA Model Optimizerè¿›è¡ŒQATè®­ç»ƒ
    - æ”¯æŒå¤šç§è‰ç¨¿æ¨¡å‹ç­–ç•¥
    - åœ¨SGLangä¸­å¯ç›´æ¥ä½¿ç”¨
    - æ€§èƒ½æå‡ï¼šç”Ÿæˆé€Ÿåº¦æå‡2-3å€
    - ä¸vLLMã€SGLangçš„é›†æˆ
- 9.3.5 æ–¹æ³•å¯¹æ¯”
- 9.3.6 å¦‚ä½•é€‰æ‹©åˆé€‚çš„å˜ä½“

#### 9.4 è‰ç¨¿æ¨¡å‹é€‰æ‹©
- 9.4.1 å°å‹å·æ¨¡å‹
- 9.4.2 é‡åŒ–åçš„ä¸»æ¨¡å‹
- 9.4.3 ä¸“é—¨è®­ç»ƒçš„è‰ç¨¿æ¨¡å‹
- 9.4.4 é€‰æ‹©æ ‡å‡†

#### 9.5 æ€§èƒ½åˆ†æ
- 9.5.1 ç†è®ºåŠ é€Ÿæ¯”
- 9.5.2 å®é™…åŠ é€Ÿæ¯”å½±å“å› ç´ 
- 9.5.3 ä»€ä¹ˆæ—¶å€™æŠ•æœºé‡‡æ ·æœ‰æ•ˆ
- 9.5.4 ä»€ä¹ˆæ—¶å€™ä¼šå¤±è´¥

#### 9.6 å®æˆ˜ï¼švLLMæŠ•æœºé‡‡æ ·
- 9.6.1 é…ç½®æŠ•æœºé‡‡æ ·
- 9.6.2 é€‰æ‹©åˆé€‚çš„è‰ç¨¿æ¨¡å‹
- 9.6.3 æ€§èƒ½åŸºå‡†æµ‹è¯•
- 9.6.4 è°ƒä¼˜æŠ€å·§

#### 9.7 å®æˆ˜ï¼šEagle 3 with SGLang âš ï¸ NVIDIAå®˜æ–¹æ”¯æŒ

> **ğŸ’¡ å·¥ä¸šç•Œå®è·µ**ï¼ˆæ¥æºï¼šNVIDIA Model Optimizer Blogï¼‰
>
> **æ ¸å¿ƒæ´å¯Ÿ**ï¼šEagle 3æ˜¯NVIDIA Model Optimizerå›¢é˜Ÿè®­ç»ƒçš„æŠ•æœºé‡‡æ ·checkpointï¼Œé€šè¿‡QATè®­ç»ƒä¼˜åŒ–ï¼Œåœ¨SGLangä¸­å¯ç›´æ¥ä½¿ç”¨ï¼Œå®ç°2-3å€çš„ç”Ÿæˆé€Ÿåº¦æå‡ã€‚

- 9.7.1 ä»€ä¹ˆæ˜¯Eagle 3
  - **NVIDIAå®˜æ–¹è®­ç»ƒ**ï¼šä½¿ç”¨NVIDIA Model Optimizer
  - **QATä¼˜åŒ–**ï¼šé‡åŒ–æ„ŸçŸ¥è®­ç»ƒæå‡ç²¾åº¦
  - **å³ç”¨å‹checkpoint**ï¼šæ— éœ€è‡ªå·±è®­ç»ƒè‰ç¨¿æ¨¡å‹
  - **SGLangåŸç”Ÿæ”¯æŒ**ï¼šå¼€ç®±å³ç”¨
  - **æ€§èƒ½ä¿è¯**ï¼šNVIDIAå›¢é˜Ÿä¼˜åŒ–å’ŒéªŒè¯

- 9.7.2 Eagle 3 vs è‡ªè®­ç»ƒè‰ç¨¿æ¨¡å‹
  - **ç²¾åº¦ä¼˜åŠ¿**ï¼š
    - QATè®­ç»ƒä¼˜åŒ–ï¼Œæ¥å—ç‡æ›´é«˜
    - Numericalç¨³å®šæ€§æ›´å¥½
  - **æˆæœ¬ä¼˜åŠ¿**ï¼š
    - æ— éœ€è‡ªå·±è®­ç»ƒè‰ç¨¿æ¨¡å‹
    - èŠ‚çœè®­ç»ƒæ—¶é—´å’Œèµ„æº
  - **ç»´æŠ¤ä¼˜åŠ¿**ï¼š
    - NVIDIAå®˜æ–¹æ”¯æŒ
    - æŒç»­æ›´æ–°å’Œä¼˜åŒ–

- 9.7.3 åœ¨SGLangä¸­ä½¿ç”¨Eagle 3
  - **å®‰è£…SGLang**ï¼š
    ```bash
    pip install sglang
    ```
  - **ä¸‹è½½Eagle 3 checkpoint**ï¼š
    - ä»Hugging Faceæˆ–NVIDIAå®˜ç½‘ä¸‹è½½
    - æ”¯æŒçš„ä¸»æ¨¡å‹ï¼šLlamaã€GPTç­‰ç³»åˆ—
  - **é…ç½®speculative decoding**ï¼š
    ```python
    import sglang as sgl

    # é…ç½®Eagle 3ä½œä¸ºè‰ç¨¿æ¨¡å‹
    model = sgl.launch_server(
        model_path="path/to/main/model",
        speculative_algorithm="Eagle",
        speculative_draft_model_path="path/to/eagle3",
        speculative_max_tokens=8
    )
    ```
  - **æ€§èƒ½è°ƒä¼˜**ï¼š
    - è°ƒæ•´speculative_max_tokens
    - ç›‘æ§acceptance rate
    - ä¼˜åŒ–batch size

- 9.7.4 æ€§èƒ½åŸºå‡†æµ‹è¯•
  - **æµ‹è¯•ç¯å¢ƒ**ï¼š
    - GPU: H100 80GB
    - æ¨¡å‹: Llama-3-70B
    - è‰ç¨¿æ¨¡å‹: Eagle 3
  - **æ€§èƒ½æŒ‡æ ‡**ï¼š
    - **ç”Ÿæˆé€Ÿåº¦æå‡**ï¼š2-3å€
    - **Acceptance rate**ï¼š70-80%
    - **Latencyæ”¹å–„**ï¼šTTFTé™ä½40%
    - **Throughputæå‡**ï¼šTPSæå‡2.5å€
  - **ä¸åŒåœºæ™¯è¡¨ç°**ï¼š
    - çŸ­æ–‡æœ¬ç”Ÿæˆï¼šæå‡1.5-2å€
    - é•¿æ–‡æœ¬ç”Ÿæˆï¼šæå‡2.5-3å€
    - ä»£ç ç”Ÿæˆï¼šæå‡2-3å€

- 9.7.5 Eagle 3çš„é™åˆ¶å’Œæ³¨æ„äº‹é¡¹
  - **æ¨¡å‹æ”¯æŒ**ï¼š
    - ä»…æ”¯æŒç‰¹å®šçš„ä¸»æ¨¡å‹
    - éœ€è¦æ£€æŸ¥å…¼å®¹æ€§åˆ—è¡¨
  - **ç¡¬ä»¶è¦æ±‚**ï¼š
    - å»ºè®®ä½¿ç”¨H100æˆ–æ›´æ–°ä¸€ä»£GPU
    - éœ€è¦è¶³å¤Ÿçš„æ˜¾å­˜åŒæ—¶åŠ è½½ä¸»æ¨¡å‹å’Œè‰ç¨¿æ¨¡å‹
  - **é€‚ç”¨åœºæ™¯**ï¼š
    - âœ… é€‚åˆé•¿æ–‡æœ¬ç”Ÿæˆ
    - âœ… é€‚åˆé«˜åååœºæ™¯
    - âš ï¸ çŸ­æ–‡æœ¬æ”¶ç›Šæœ‰é™
    - âŒ ä¸é€‚åˆå»¶è¿Ÿæ•æ„Ÿçš„å®æ—¶åº”ç”¨

- 9.7.6 Eagleç³»åˆ—æ¼”è¿›
  - **Eagle**ï¼š
    - åˆå§‹ç‰ˆæœ¬
    - åŸºç¡€æŠ•æœºé‡‡æ ·
  - **Eagle 2**ï¼š
    - æ”¹è¿›è®­ç»ƒç­–ç•¥
    - æ›´å¥½çš„acceptance rate
  - **Eagle 3**ï¼š
    - QATè®­ç»ƒä¼˜åŒ–
    - æ”¯æŒæ›´å¤šä¸»æ¨¡å‹
    - SGLangæ·±åº¦é›†æˆ
  - **æœªæ¥æ–¹å‘**ï¼š
    - æ”¯æŒæ›´å¤šæ¨¡å‹æ¶æ„
    - åŠ¨æ€è‰ç¨¿é•¿åº¦
    - ä¸å…¶ä»–ä¼˜åŒ–æŠ€æœ¯ç»“åˆï¼ˆå¦‚PDåˆ†ç¦»ï¼‰

- 9.7.7 å®æˆ˜ï¼švLLM Speculators v0.3.0 - ç«¯åˆ°ç«¯Eagle 3è®­ç»ƒ â­ğŸ’¡

  > **ğŸ’¡ 2025å¹´æŠ€æœ¯è¶‹åŠ¿**ï¼ˆæ¥æºï¼švLLM Official Blog - 2025/12/13ï¼‰
  >
  > **æ ¸å¿ƒæ´å¯Ÿ**ï¼švLLM Speculators v0.3.0æä¾›äº†å®Œæ•´çš„ç«¯åˆ°ç«¯Eagle 3è®­ç»ƒæ”¯æŒï¼Œä»ç¦»çº¿æ•°æ®ç”Ÿæˆåˆ°æ¨¡å‹è®­ç»ƒå†åˆ°æ¨ç†éƒ¨ç½²ï¼Œå¡«è¡¥äº†å¼€æºç”Ÿæ€åœ¨æŠ•æœºé‡‡æ ·è®­ç»ƒæ–¹é¢çš„ç©ºç™½ã€‚

  - **ä»€ä¹ˆæ˜¯vLLM Speculators**ï¼š
    - vLLMå®˜æ–¹çš„æŠ•æœºé‡‡æ ·è®­ç»ƒåº“
    - æ”¯æŒç«¯åˆ°ç«¯Eagle 3è®­ç»ƒpipeline
    - å¼€æºè§£å†³æ–¹æ¡ˆï¼ˆä¸åŒäºNVIDIAçš„é—­æºcheckpointï¼‰
    - ä¸vLLMæ¨ç†å¼•æ“æ— ç¼é›†æˆ

  - **æ ¸å¿ƒç‰¹æ€§**ï¼š
    - **Offlineæ•°æ®ç”Ÿæˆ**ï¼š
      - ä½¿ç”¨vLLMç”Ÿæˆhidden states
      - æ”¯æŒå¤§è§„æ¨¡æ•°æ®é›†ç”Ÿæˆ
      - æ™ºèƒ½batch samplingæå‡æ•ˆç‡
    - **è®­ç»ƒèƒ½åŠ›**ï¼š
      - å•å±‚è‰ç¨¿æ¨¡å‹è®­ç»ƒ
      - å¤šå±‚è‰ç¨¿æ¨¡å‹è®­ç»ƒ
      - æ”¯æŒMoEå’Œnon-MoE verifiers
      - FlexAttentioné«˜æ•ˆattentionè®¡ç®—
    - **æ¨¡å‹æ”¯æŒ**ï¼š
      - Llamaç³»åˆ—ï¼š3.1, 3.2, 3.3 (8B-70B)
      - Qwen3ï¼š8B, 14B, 32B
      - Qwen3 MoEï¼š235B-A22B
      - GPT-OSSï¼š20B, 120B

  - **vs NVIDIA Eagle 3å¯¹æ¯”**ï¼š
    - **å¼€æº vs é—­æº**ï¼š
      - vLLM Speculatorsï¼šå®Œå…¨å¼€æºï¼Œå¯è‡ªå®šä¹‰è®­ç»ƒ
      - NVIDIA Eagle 3ï¼šå®˜æ–¹checkpointï¼Œå¼€ç®±å³ç”¨
    - **çµæ´»æ€§**ï¼š
      - vLLMï¼šå¯è°ƒæ•´è®­ç»ƒå‚æ•°å’Œæ•°æ®
      - NVIDIAï¼šå›ºå®šæ¨¡å‹å’Œé…ç½®
    - **é€‚ç”¨åœºæ™¯**ï¼š
      - vLLMï¼šç ”ç©¶ã€è‡ªå®šä¹‰éœ€æ±‚ã€å­¦ä¹ ç›®çš„
      - NVIDIAï¼šç”Ÿäº§ç¯å¢ƒã€å¿«é€Ÿéƒ¨ç½²ã€è¿½æ±‚ç¨³å®šæ€§

  - **å®Œæ•´è®­ç»ƒæµç¨‹**ï¼š
    - **æ­¥éª¤1ï¼šç¯å¢ƒå‡†å¤‡**
      ```bash
      pip install vllm-devtools  # åŒ…å«speculatorsè®­ç»ƒå·¥å…·
      ```
    - **æ­¥éª¤2ï¼šç¦»çº¿æ•°æ®ç”Ÿæˆ**
      ```bash
      python -m vllm.speculators.generate_hidden_states \
        --model-path meta-llama/Llama-3.1-8B \
        --dataset-path your_dataset.jsonl \
        --output-path hidden_states_output \
        --max-model-len 4096 \
        --batch-size 32
      ```
    - **æ­¥éª¤3ï¼šè®­ç»ƒè‰ç¨¿æ¨¡å‹**
      ```bash
      python -m vllm.speculators.train \
        --base-model-path meta-llama/Llama-3.1-8B \
        --hidden-states-path hidden_states_output \
        --output-path eagle3_draft_model \
        --num-layers 1 \
        --use-flex-attention
      ```
    - **æ­¥éª¤4ï¼šæ¨ç†éƒ¨ç½²**
      ```python
      from vllm import LLM
      from vllm.speculators import SpeculativeDecoder

      llm = LLM(
        model="meta-llama/Llama-3.1-8B",
        speculative_model="eagle3_draft_model",
        num_speculative_tokens=8
      )
      ```

  - **æŠ€æœ¯äº®ç‚¹**ï¼š
    - **FlexAttention**ï¼š
      - PyTorch 2.5+çš„é«˜æ•ˆattentionå®ç°
      - å¤§å¹…å‡å°‘å†…å­˜å ç”¨å’Œè®¡ç®—æ—¶é—´
      - æ”¯æŒé•¿åºåˆ—è®­ç»ƒ
    - **æ™ºèƒ½é‡‡æ ·**ï¼š
      - è‡ªåŠ¨é€‰æ‹©éš¾æ ·æœ¬è¿›è¡Œè®­ç»ƒ
      - æå‡æ•°æ®è´¨é‡å’Œè®­ç»ƒæ•ˆç‡
    - **MoEæ”¯æŒ**ï¼š
      - æ”¯æŒMoE verifieræ¨¡å‹
      - ç¨€ç–æ¿€æ´»é™ä½è®­ç»ƒæˆæœ¬

  - **æ€§èƒ½åŸºå‡†**ï¼š
    - **è®­ç»ƒæ•ˆç‡**ï¼š
      - å•å±‚draftæ¨¡å‹ï¼š4-8å°æ—¶ï¼ˆ8å¡H100ï¼‰
      - å¤šå±‚draftæ¨¡å‹ï¼š12-24å°æ—¶ï¼ˆ8å¡H100ï¼‰
    - **æ¨ç†æ€§èƒ½**ï¼š
      - Acceptance rateï¼š65-75%
      - ç”Ÿæˆé€Ÿåº¦æå‡ï¼š1.8-2.5å€
      - ä¸NVIDIA Eagle 3ç›¸å½“

  - **å®æˆ˜å»ºè®®**ï¼š
    - **æ•°æ®é€‰æ‹©**ï¼š
      - ä½¿ç”¨ä¸ç›®æ ‡åœºæ™¯ç›¸ä¼¼çš„æ•°æ®
      - æ•°æ®é‡ï¼š10M-100M tokens
      - è¦†ç›–å¸¸è§promptæ¨¡å¼
    - **è®­ç»ƒè°ƒä¼˜**ï¼š
      - ä»å•å±‚draftå¼€å§‹ï¼ŒéªŒè¯æ•ˆæœ
      - æ ¹æ®acceptance rateè°ƒæ•´è®­ç»ƒå‚æ•°
      - ç›‘æ§lossæ›²çº¿ï¼Œé¿å…è¿‡æ‹Ÿåˆ
    - **éƒ¨ç½²ä¼˜åŒ–**ï¼š
      - è°ƒæ•´num_speculative_tokensï¼ˆ4-16ï¼‰
      - é€‰æ‹©åˆé€‚çš„batch size
      - ç›‘æ§GPUæ˜¾å­˜ä½¿ç”¨

  - **é™åˆ¶å’Œæ³¨æ„äº‹é¡¹**ï¼š
    - **ç¡¬ä»¶è¦æ±‚**ï¼š
      - å»ºè®®ï¼šH100æˆ–æ›´æ–°ä¸€ä»£GPU
      - æ˜¾å­˜ï¼šéœ€è¦åŒæ—¶åŠ è½½baseæ¨¡å‹å’Œdraftæ¨¡å‹
      - è®­ç»ƒï¼šè‡³å°‘4å¡ï¼Œæ¨è8å¡
    - **æ¨¡å‹æ”¯æŒ**ï¼š
      - ä»…æ”¯æŒç‰¹å®šçš„æ¨¡å‹ç³»åˆ—ï¼ˆLlamaã€Qwenã€GPT-OSSï¼‰
      - éœ€è¦æ£€æŸ¥æ¨¡å‹å…¼å®¹æ€§
    - **å­¦ä¹ æ›²çº¿**ï¼š
      - éœ€è¦ç†è§£æŠ•æœºé‡‡æ ·åŸç†
      - è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹å¤æ‚
      - è°ƒä¼˜éœ€è¦ç»éªŒ

#### å¸¸è§è¯¯åŒºä¸“æ 
- è¯¯åŒº1ï¼š"æŠ•æœºé‡‡æ ·æ€»æ˜¯èƒ½åŠ é€Ÿ"
- è¯¯åŒº2ï¼š"è‰ç¨¿æ¨¡å‹è¶Šå°è¶Šå¥½"
- è¯¯åŒº3ï¼š"acceptance rateè¶Šé«˜è¶Šå¥½"
- è¯¯åŒº4ï¼š"Eagle 3åªé€‚ç”¨äºNVIDIA GPU"

#### å®æˆ˜æ£€æŸ¥æ¸…å•
- [ ] ç¡®å®šåº”ç”¨åœºæ™¯æ˜¯å¦é€‚åˆæŠ•æœºé‡‡æ ·
- [ ] é€‰æ‹©åˆé€‚çš„æŠ•æœºé‡‡æ ·å˜ä½“
- [ ] é€‰æ‹©æˆ–è®­ç»ƒè‰ç¨¿æ¨¡å‹
- [ ] é…ç½®speculative decodingå‚æ•°
- [ ] è¿›è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] ç›‘æ§acceptance rate
- [ ] ä¼˜åŒ–å’Œè°ƒä¼˜

#### åŠ¨æ‰‹ç»ƒä¹ 
- ç»ƒä¹ 8.1ï¼šä½¿ç”¨æŠ•æœºé‡‡æ ·åŠ é€Ÿç”Ÿæˆ
- ç»ƒä¹ 8.2ï¼šå¯¹æ¯”ä¸åŒè‰ç¨¿æ¨¡å‹çš„æ•ˆæœ
- ç»ƒä¹ 8.3ï¼šä½¿ç”¨SGLang + Eagle 3éƒ¨ç½²æ¨ç†æœåŠ¡ â­
- ç»ƒä¹ 8.4ï¼šï¼ˆè¿›é˜¶ï¼‰è®­ç»ƒè‡ªå·±çš„è‰ç¨¿æ¨¡å‹ â­

---

## ç¬¬å››éƒ¨åˆ†ï¼šç”Ÿäº§éƒ¨ç½²ç¯‡ (Part 4: Production Deployment)

### ç¬¬10ç«  ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

> **ğŸ’° æˆæœ¬å½±å“**ï¼ˆåŸºäºè¡Œä¸šæ•°æ®ï¼‰
> - **å¯ç”¨æ€§æå‡**ï¼šä»99%æå‡åˆ°99.9%ï¼Œæ•…éšœæˆæœ¬é™ä½10å€
> - **è‡ªåŠ¨ä¼¸ç¼©**ï¼šå¯æ ¹æ®æµé‡åŠ¨æ€è°ƒæ•´ï¼ŒèŠ‚çœ30-50%é—²ç½®æˆæœ¬
> - **ç›‘æ§ROI**ï¼šåŠæ—¶å‘ç°é—®é¢˜ï¼Œé¿å…èµ„æºæµªè´¹
> - **æˆæœ¬ä¼˜åŒ–**ï¼šé€šè¿‡Spotå®ä¾‹ç­‰ç­–ç•¥å¯èŠ‚çœ60-80%äº‘GPUæˆæœ¬

#### 10.1 ç”Ÿäº§ç¯å¢ƒvså¼€å‘ç¯å¢ƒ
- 10.1.1 å…³é”®å·®å¼‚
- 10.1.2 ç”Ÿäº§ç¯å¢ƒçš„ç‰¹æ®Šè¦æ±‚
- 10.1.3 SLAå®šä¹‰

#### 10.2 éƒ¨ç½²æ¶æ„è®¾è®¡
- 10.2.1 å•æœºéƒ¨ç½²
- 10.2.2 å¤šæœºéƒ¨ç½² (æ¨¡å‹å¹¶è¡Œ)
- 10.2.3 è´Ÿè½½å‡è¡¡ç­–ç•¥
- 10.2.4 é«˜å¯ç”¨æ¶æ„

#### 10.3 Kuberneteséƒ¨ç½²
- 10.3.1 K8såŸºç¡€æ¦‚å¿µ
- 10.3.2 éƒ¨ç½²vLLMåˆ°K8s
- 10.3.3 é…ç½®ç®¡ç†
- 10.3.4 èµ„æºè°ƒåº¦ä¸GPUå…±äº«

#### 10.4 ç›‘æ§ä¸å¯è§‚æµ‹æ€§
- 10.4.1 å…³é”®ç›‘æ§æŒ‡æ ‡
- 10.4.2 Prometheus + Grafana
- 10.4.3 æ—¥å¿—æ”¶é›†ä¸åˆ†æ
- 10.4.4 åˆ†å¸ƒå¼è¿½è¸ª

#### 10.5 æ€§èƒ½è°ƒä¼˜å®æˆ˜
- 10.5.1 è°ƒä¼˜æµç¨‹
- 10.5.2 ç“¶é¢ˆå®šä½æ–¹æ³•
- 10.5.3 å¸¸è§æ€§èƒ½é—®é¢˜
- 10.5.4 çœŸå®æ¡ˆä¾‹ï¼šä»50 tpsåˆ°200 tps
- 10.5.5 æ€§èƒ½åˆ†æå·¥å…·ä¸å®æˆ˜ âš¡ï¸ 2025æ›´æ–°

> **æ¥æº**ï¼š
> - [vLLM Profiling Documentation](https://docs.vllm.ai/en/stable/contributing/profiling/)
> - [é˜¿é‡Œäº‘ - Nsight Systemsæ€§èƒ½åˆ†æå®æˆ˜](https://help.aliyun.com/zh/ack/cloud-native-ai-suite/use-cases/using-nsight-system-to-realize-performance-analysis)

**æ ¸å¿ƒå·¥å…·é“¾**ï¼š
- **PyTorch Profiler**ï¼šPythonçº§åˆ«çš„æ€§èƒ½åˆ†æ
- **NVIDIA Nsight Systems**ï¼šGPUç³»ç»Ÿçº§åˆ†æï¼ˆtimeline viewï¼‰
- **NVIDIA Nsight Compute**ï¼šGPU kernelçº§æ·±åº¦åˆ†æ

**10.5.5.1 PyTorch ProfileråŸºç¡€**
- **vLLMé›†æˆæ–¹å¼**ï¼š
  ```python
  from vllm import LLM, SamplingParams
  from torch.profiler import profile, ProfilerActivity

  llm = LLM(model="meta-llama/Llama-2-7b-hf")

  with profile(
      activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
      record_shapes=True,
      profile_memory=True,
      with_stack=True
  ) as prof:
      prompts = ["Hello, my name is"] * 10
      sampling_params = SamplingParams(temperature=0.7, top_p=0.95, max_tokens=20)
      outputs = llm.generate(prompts, sampling_params)

  print(prof.key_averages().table(sort_by="cuda_time_total", row_limit=10))
  ```
- **åˆ†æåœºæ™¯**ï¼š
  - Offline inference profilingï¼šå•æ¬¡ç”Ÿæˆè¯·æ±‚åˆ†æ
  - Server mode profilingï¼šæŒç»­è¯·æ±‚è´Ÿè½½ä¸‹çš„æ€§èƒ½åˆ†æ
- **å…³é”®æŒ‡æ ‡**ï¼š
  - CUDA time totalï¼šGPUè€—æ—¶ç»Ÿè®¡
  - Memory usageï¼šæ˜¾å­˜å ç”¨å³°å€¼
  - Kernel launch overheadï¼škernelå¯åŠ¨å¼€é”€

**10.5.5.2 NVIDIA Nsight Systems - ç³»ç»Ÿçº§åˆ†æ**
- **ä»€ä¹ˆæ˜¯Nsight Systems**ï¼š
  - GPU timelineå¯è§†åŒ–å·¥å…·
  - åˆ†æCPU-GPUäº¤äº’ã€kernelé‡å ã€å†…å­˜ä¼ è¾“
  - è¯†åˆ«æ€§èƒ½ç“¶é¢ˆçš„"ç¬¬ä¸€é“é˜²çº¿"

- **vLLM profilingæµç¨‹**ï¼š
  ```bash
  # 1. å¯åŠ¨vLLM serverå¹¶å¯ç”¨profiling
  vllm serve meta-llama/Llama-2-7b-hf \
      --tensor-parallel-size 1 \
      > /dev/null &

  # 2. ä½¿ç”¨nsysè¿›è¡Œprofilingï¼ˆ30ç§’ï¼‰
  nsys profile \
      --trace=cuda,nvtx,osrt \
      --cuda-memory-usage=true \
      --output=profile_report \
      --stats=true \
      --force-overwrite=true \
      --duration=30 \
      --capture-range=nvtx \
      --capture-range-end=stop \
      python benchmark_serving.py

  # 3. ç”ŸæˆsummaryæŠ¥å‘Š
  nys stats profile_report.nsys-rep
  ```

- **å…³é”®åˆ†æç»´åº¦**ï¼š
  - **GPUåˆ©ç”¨ç‡**ï¼šç†æƒ³çŠ¶æ€>80%ï¼Œä½äºè¯´æ˜æœ‰CPU/å†…å­˜ç“¶é¢ˆ
  - **Kernelé‡å **ï¼šæ£€æŸ¥computeå’Œmemory transferæ˜¯å¦overlap
  - **CPU-GPUåŒæ­¥**ï¼šè¿‡å¤šçš„cudaDeviceSynchronizeä¼šé™ä½æ€§èƒ½
  - **Memory bandwidth**ï¼šæ˜¯å¦è¾¾åˆ°GPUå³°å€¼å¸¦å®½
  - **NVTX markers**ï¼švLLMä»£ç ä¸­å·²æ ‡æ³¨å…³é”®é˜¶æ®µçš„markers

- **å®æˆ˜æ¡ˆä¾‹**ï¼ˆé˜¿é‡Œäº‘ï¼‰ï¼š
  - **è®­ç»ƒä¼˜åŒ–**ï¼š542 samples/s â†’ 3173 samples/sï¼ˆ5.85xæå‡ï¼‰
  - **7é¡¹å…³é”®ä¼˜åŒ–**ï¼š
    1. DataLoader workersä¼˜åŒ–ï¼šå‡å°‘CPUç­‰å¾…
    2. Pin memoryä¼˜åŒ–ï¼šåŠ é€ŸCPUâ†’GPUä¼ è¾“
    3. Gradient accumulation checkpointä¼˜åŒ–ï¼šå‡å°‘å†…å­˜å¼€é”€
    4. Mixed precision (FP16)è®­ç»ƒï¼š2xè®¡ç®—åå
    5. Gradient clippingä¼˜åŒ–ï¼šå‡å°‘åŒæ­¥å¼€é”€
    6. Optimizer state placementï¼šå°†optimizer stateæ”¾åœ¨GPUè€ŒéCPU
    7. DDP bucket sizeè°ƒä¼˜ï¼šå‡å°‘é€šä¿¡é¢‘ç‡

**10.5.5.3 NVIDIA Nsight Compute - Kernelçº§æ·±åº¦åˆ†æ**
- **ä»€ä¹ˆæ—¶å€™ä½¿ç”¨Nsight Compute**ï¼š
  - Nsight Systemså‘ç°æŸä¸ªkernelè€—æ—¶å¼‚å¸¸
  - éœ€è¦åˆ†ækernelå†…éƒ¨è®¡ç®—å’Œå†…å­˜è®¿é—®æ¨¡å¼

- **å…¸å‹å·¥ä½œæµ**ï¼š
  ```bash
  # 1. ä»Nsight Systemsä¸­è¯†åˆ«æ…¢kernelï¼ˆä¾‹å¦‚ï¼šfused_add_rms_normï¼‰
  # 2. ä½¿ç”¨ncuè¿›è¡Œkernelçº§profiling
  ncu --set full \
      --target-processes all \
      --export profile_kernel \
      --page replay \
      python benchmark_serving.py

  # 3. åˆ†ææŒ‡æ ‡
  # - DRAM bandwidth utilization
  # - L2 cache hit rate
  # - Warp execution efficiency
  # - Memory coalescing
  ```

- **å…³é”®æ€§èƒ½æŒ‡æ ‡**ï¼š
  - **Memory bandwidth utilization**ï¼šæ˜¯å¦è¾¾åˆ°H100å³°å€¼ï¼ˆ3.35 TB/sï¼‰
  - **Compute throughput**ï¼šTensor Coreåˆ©ç”¨ç‡
  - **Occupancy**ï¼šæ¯ä¸ªSMçš„active warpæ•°é‡ï¼ˆç†æƒ³>50%ï¼‰
  - **L1/L2 cache hit rate**ï¼šæ•°æ®å±€éƒ¨æ€§æ˜¯å¦è‰¯å¥½
  - **Warp efficiency**ï¼šbranch divergenceç¨‹åº¦

**10.5.5.4 æ€§èƒ½ä¼˜åŒ–checklist**
- **Step 1: åŸºçº¿æµ‹è¯•**
  - ä½¿ç”¨`benchmark_serving.py`å»ºç«‹æ€§èƒ½åŸºçº¿
  - è®°å½•å…³é”®æŒ‡æ ‡ï¼šthroughput (tokens/s), TTFT, TPOT, GPUåˆ©ç”¨ç‡

- **Step 2: PyTorch Profilerå¿«é€Ÿè¯Šæ–­**
  - æ‰¾å‡ºtop CUDA time operators
  - æ£€æŸ¥æ˜¯å¦æœ‰unexpectedçš„CPU overhead

- **Step 3: Nsight Systemsç³»ç»Ÿçº§åˆ†æ**
  - éªŒè¯GPUåˆ©ç”¨ç‡æ˜¯å¦åˆç†
  - æ£€æŸ¥CPU-GPU pipelineæ˜¯å¦æœ‰gap
  - ç¡®è®¤memory transferæ˜¯å¦overlap

- **Step 4: Nsight Compute kernelä¼˜åŒ–**ï¼ˆå¦‚éœ€è¦ï¼‰
  - é’ˆå¯¹slow kernelè¿›è¡Œæ·±åº¦åˆ†æ
  - ä¼˜åŒ–memory access pattern
  - è°ƒæ•´block/gridé…ç½®

- **Step 5: éªŒè¯ä¼˜åŒ–æ•ˆæœ**
  - é‡æ–°è¿è¡Œbenchmark
  - å¯¹æ¯”ä¼˜åŒ–å‰åçš„æŒ‡æ ‡
  - ç¡®è®¤æ²¡æœ‰regression

**10.5.5.5 vLLMç‰¹å®šprofilingå»ºè®®**
- **KV Cache profiling**ï¼š
  - å…³æ³¨`CacheEngine`ç›¸å…³çš„kernel
  - æ£€æŸ¥prefillå’Œdecodeé˜¶æ®µçš„æ˜¾å­˜å ç”¨å·®å¼‚

- **Attention kernelåˆ†æ**ï¼š
  - FlashAttentionæ˜¯å¦æ­£ç¡®å¯ç”¨
  - PagedAttentionçš„page miss rate

- **Scheduler overhead**ï¼š
  - ä½¿ç”¨NVTX markersåˆ†æschedulerè°ƒåº¦æ—¶é—´
  - æ£€æŸ¥æ˜¯å¦æˆä¸ºbottleneckï¼ˆç†æƒ³<5%æ€»æ—¶é—´ï¼‰

- **Multi-GPU profiling**ï¼š
  - ä½¿ç”¨`--tensor-parallel-size=N`æµ‹è¯•æ‰©å±•æ€§
  - Nsight Systemsä¸­æŸ¥çœ‹NCCL all-reduceæ—¶é—´å æ¯”
  - æ£€æŸ¥æ˜¯å¦æœ‰GPU load imbalance

#### 10.6 æˆæœ¬ä¼˜åŒ–
- 10.6.1 äº‘GPUé€‰æ‹©ç­–ç•¥
- 10.6.2 Spotå®ä¾‹ä½¿ç”¨
- 10.6.3 è‡ªåŠ¨ä¼¸ç¼©
- 10.6.4 æˆæœ¬ç›‘æ§å·¥å…·
- 10.6.5 Agentç³»ç»Ÿçš„æˆæœ¬ä¼˜åŒ–ç­–ç•¥ âš¡ï¸ 2025æ–°å¢

  > **æ¥æº**ï¼š[Manus - Context Engineering for AI Agents](https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus)
  >
  > **æ ¸å¿ƒè§‚ç‚¹**ï¼šå›´ç»•KV-Cacheè®¾è®¡Agentç³»ç»Ÿâ€”â€”è¿™æ˜¯æˆæœ¬ä¼˜åŒ–çš„"é“¶å¼¹"

  **10.6.5.1 æˆæœ¬å¯¹æ¯”ï¼šCached vs Uncached**

  - **Claude Sonnetå®šä»·**ï¼ˆ2025ï¼‰ï¼š
    - Cached tokens: **$0.30/MTok**
    - Uncached tokens: **$3.00/MTok**
    - **10å€å·®å¼‚ï¼**

  - **Agentç³»ç»Ÿçš„æˆæœ¬æ”¾å¤§æ•ˆåº”**ï¼š
    - å…¸å‹Agentä»»åŠ¡ï¼š50æ­¥tool calls
    - æ¯æ­¥contextå¢é•¿ï¼š~500 tokens
    - æ€»tokenæ•°ï¼š25,000 tokensï¼ˆå¤§éƒ¨åˆ†æ˜¯prefillï¼‰
    - **æ— ä¼˜åŒ–æˆæœ¬**ï¼š25K Ã— $3/MTok = $0.075/ä»»åŠ¡
    - **ä¼˜åŒ–åæˆæœ¬**ï¼šprefix cached â†’ ~$0.01/ä»»åŠ¡
    - **èŠ‚çœ**ï¼š7.5å€

  **10.6.5.2 å››å¤§ä¼˜åŒ–æ‰‹æ®µ**

  - **ä¼˜åŒ–1ï¼šç§»é™¤åŠ¨æ€å†…å®¹**
    ```python
    # âŒ Before: æ¯æ¬¡è¯·æ±‚éƒ½ä¸åŒ
    system_prompt = f"""
    You are Manus AI assistant.
    Current time: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
    Today's date: {datetime.now().date()}
    User ID: {user_id}
    Session ID: {session_id}
    """

    # âœ… After: å®Œå…¨é™æ€
    system_prompt = """
    You are Manus AI assistant.
    Use get_current_time() tool to get the time.
    Use get_user_context() tool to get user info.
    """
    ```

    - **ä¼°ç®—å½±å“**ï¼š
      - Cache hit rate: 30% â†’ 60%ï¼ˆæå‡30%ï¼‰
      - æˆæœ¬èŠ‚çœï¼š~30%

  - **ä¼˜åŒ–2ï¼šAppend-only Context**
    ```python
    # âŒ Bad: ç ´åcache
    context[-1]["status"] = "completed"  # ä¿®æ”¹å†å²
    context[-1]["result"] = formatted_result

    # âœ… Good: è¿½åŠ æ–°ä¿¡æ¯
    context.append({
        "type": "status_update",
        "action_index": len(context) - 1,
        "status": "completed",
        "result": formatted_result
    })
    ```

    - **å…³é”®ç‚¹**ï¼š
      - ç¡®å®šæ€§JSONåºåˆ—åŒ–ï¼ˆ`sort_keys=True`ï¼‰
      - é¿å…ä¿®æ”¹å†å²actions/observations
      - ä¸åŠ¨æ€å¢åˆ å·¥å…·å®šä¹‰

    - **ä¼°ç®—å½±å“**ï¼š
      - Cache hit rate: 60% â†’ 75%ï¼ˆæå‡15%ï¼‰
      - æˆæœ¬èŠ‚çœï¼š~15%

  - **ä¼˜åŒ–3ï¼šFile System as External Memory**
    ```python
    # âŒ Bad: å¤§å‹observationç›´æ¥æ”¾context
    observation = {
        "type": "web_page",
        "content": fetch_web_page(url),  # å¯èƒ½50K tokens
        "url": url
    }

    # âœ… Good: ä¿å­˜åˆ°æ–‡ä»¶ï¼Œcontextåªä¿ç•™å¼•ç”¨
    file_path = save_to_file(observation["content"])
    context_obs = {
        "type": "web_page",
        "file_path": file_path,
        "url": url,
        "summary": summarize_page(observation["content"])  # 100 tokens
    }
    ```

    - **å¯æ¢å¤å‹ç¼©ç­–ç•¥**ï¼š
      - ç½‘é¡µå†…å®¹ï¼šä¿ç•™URL
      - PDFæ–‡æ¡£ï¼šä¿ç•™æ–‡ä»¶è·¯å¾„
      - æ•°æ®åº“æŸ¥è¯¢ï¼šä¿ç•™æŸ¥è¯¢è¯­å¥
      - éœ€è¦æ—¶agentå†è¯»å–æ–‡ä»¶

    - **ä¼°ç®—å½±å“**ï¼š
      - Tokenä½¿ç”¨ï¼šå‡å°‘50-70%
      - Contexté•¿åº¦ï¼š20K â†’ 8K tokens
      - æˆæœ¬èŠ‚çœï¼š~40%

  - **ä¼˜åŒ–4ï¼šSession-aware Routing**
    ```python
    # vLLMé…ç½®
    config = {
        "enable_prefix_caching": True,
        "distributed_executor_backend": "ray"
    }

    # è·¯ç”±å±‚
    class SessionAwareRouter:
        def __init__(self, num_workers):
            self.worker_cache = {}  # session_id â†’ worker_id
            self.num_workers = num_workers

        def get_worker(self, session_id):
            # åŒä¸€session â†’ åŒä¸€worker
            if session_id in self.worker_cache:
                return self.worker_cache[session_id]

            worker_id = hash(session_id) % self.num_workers
            self.worker_cache[session_id] = worker_id
            return worker_id
    ```

    - **æ•ˆæœ**ï¼š
      - Prefix cacheå¤ç”¨ç‡æå‡
      - TTFTé™ä½40-60%
      - ååé‡æå‡2-3å€

  **10.6.5.3 æˆæœ¬ä¼˜åŒ–Checklist**

  - **åŸºçº¿æµ‹é‡**ï¼š
    - [ ] æµ‹é‡å½“å‰KV-cache hit rate
    - [ ] è®¡ç®—å¹³å‡æ¯ä¸ªä»»åŠ¡çš„tokenæ•°
    - [ ] ç»Ÿè®¡prefill vs decodeæ¯”ä¾‹
    - [ ] è®°å½•æ¯1000ä¸ªä»»åŠ¡çš„cost

  - **å¿«é€Ÿä¼˜åŒ–ï¼ˆ1å¤©å†…ï¼‰**ï¼š
    - [ ] ç§»é™¤promptä¸­çš„timestampç­‰åŠ¨æ€å†…å®¹
    - [ ] æ£€æŸ¥JSONåºåˆ—åŒ–æ˜¯å¦ä½¿ç”¨`sort_keys=True`
    - [ ] å®¡æŸ¥æ˜¯å¦æœ‰ä¿®æ”¹å†å²çš„ä»£ç 
    - [ ] ç¦ç”¨åŠ¨æ€å·¥å…·å®šä¹‰

  - **ä¸­æœŸä¼˜åŒ–ï¼ˆ1å‘¨å†…ï¼‰**ï¼š
    - [ ] å¯ç”¨vLLM prefix caching
    - [ ] å®ç°session-aware routing
    - [ ] æ·»åŠ file system fallbackæœºåˆ¶
    - [ ] ç›‘æ§cache hit rateæŒ‡æ ‡

  - **é•¿æœŸä¼˜åŒ–ï¼ˆæŒç»­ï¼‰**ï¼š
    - [ ] å»ºç«‹æˆæœ¬ç›‘æ§dashboard
    - [ ] A/Bæµ‹è¯•ä¸åŒcontextç­–ç•¥
    - [ ] ä¼˜åŒ–å·¥å…·è°ƒç”¨é¢‘ç‡
    - [ ] å®æ–½contextå‹ç¼©ç­–ç•¥

  **10.6.5.4 å®æˆ˜æ¡ˆä¾‹å¯¹æ¯”**

  | åœºæ™¯ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | èŠ‚çœ |
  |------|--------|--------|------|
  | ç®€å•ä»»åŠ¡ï¼ˆ10æ­¥ï¼‰ | $0.02 | $0.005 | 75% |
  | ä¸­ç­‰ä»»åŠ¡ï¼ˆ30æ­¥ï¼‰ | $0.05 | $0.015 | 70% |
  | å¤æ‚ä»»åŠ¡ï¼ˆ50æ­¥ï¼‰ | $0.075 | $0.025 | 67% |
  | è¶…é•¿ä»»åŠ¡ï¼ˆ100æ­¥ï¼‰ | $0.15 | $0.06 | 60% |

  **å…³é”®æ´å¯Ÿ**ï¼šä»»åŠ¡è¶Šå¤æ‚ï¼Œä¼˜åŒ–æ•ˆæœè¶Šæ˜æ˜¾â€”â€”å› ä¸ºcontextç´¯ç§¯æ›´å¤šã€‚

- 10.6.6 è½»é‡çº§å‚è€ƒå®ç°ï¼šMini-SGLang âš¡ï¸ 2025æ–°å¢

  > **ğŸ’¡ æ·±åº¦æ¥æº**ï¼š[Mini-SGLang Blog](https://lmsys.org/blog/2025-12-17-minisgl/)
  >
  > **æ ¸å¿ƒä»·å€¼**ï¼š5kè¡Œä»£ç å®ç°å®Œæ•´æ¨ç†å¼•æ“ï¼Œé€‚åˆå­¦ä¹ å’Œç ”ç©¶åŸå‹
  >
  > **é€‚ç”¨åœºæ™¯**ï¼šæ•™è‚²å­¦ä¹ ã€å¿«é€Ÿç ”ç©¶éªŒè¯ã€å†…æ ¸å¼€å‘è°ƒè¯•

  **10.6.6.1 ä¸ºä»€ä¹ˆéœ€è¦è½»é‡çº§å®ç°ï¼Ÿ**

  - **é—®é¢˜**ï¼š
    - **vLLMä»£ç è§„æ¨¡**ï¼š300k+è¡ŒPythonä»£ç 
      - æ–°æ‰‹å­¦ä¹ æ›²çº¿é™¡å³­
      - ä¿®æ”¹é£é™©é«˜ï¼ˆç ´åéšå¼ä¸å˜é‡ï¼‰
      - ç ”ç©¶åŸå‹éš¾ä»¥å¿«é€ŸéªŒè¯

    - **SGLangä»£ç è§„æ¨¡**ï¼š300kè¡ŒPythonä»£ç 
      - åŠŸèƒ½å®Œæ•´ï¼Œä½†å¤æ‚åº¦é«˜
      - ä¸é€‚åˆæ•™å­¦åœºæ™¯

  - **Mini-SGLangçš„ç­”æ¡ˆ**ï¼š
    - **ä»…5kè¡ŒPythonä»£ç **ï¼ˆæ¯”vLLMç®€å•60å€ï¼‰
    - **ä¿ç•™æ ¸å¿ƒä¼˜åŒ–**ï¼š
      - Radix Attention (KV Cacheå¤ç”¨)
      - Overlap Scheduling (CPU-GPUå¹¶è¡Œ)
      - Chunked Prefill (å†…å­˜æ§åˆ¶)
      - Tensor Parallelism (åˆ†å¸ƒå¼æœåŠ¡)
      - JIT CUDA kernels (FlashAttention-3, FlashInfer)
    - **æ€§èƒ½ç›¸å½“**ï¼šä¸å®Œæ•´SGLangæ¥è¿‘

  **10.6.6.2 5kè¡Œä»£ç å®ç°çš„æ ¸å¿ƒåŠŸèƒ½**

  - **ä»£ç ç»“æ„**ï¼š
    ```
    mini-sglang/
    â”œâ”€â”€ server.py              # OpenAIå…¼å®¹API server
    â”œâ”€â”€ tokenizer.py           # TokenizeræœåŠ¡
    â”œâ”€â”€ scheduler.py           # è°ƒåº¦å™¨ï¼ˆå«Overlap Schedulingï¼‰
    â”œâ”€â”€ radix_cache.py         # Radix Cacheå®ç°
    â”œâ”€â”€ model_runner.py        # æ¨¡å‹æ‰§è¡Œï¼ˆTensor Parallelismï¼‰
    â””â”€â”€ kernels/
        â”œâ”€â”€ flashattention.py  # FlashAttention-3 JIT
        â””â”€â”€ flashinfer.py      # FlashInfer JIT
    ```

  - **æ ¸å¿ƒæ¨¡å—è§£æ**ï¼š

    **1. server.py - å‰ç«¯API**
    ```python
    # å®ç°OpenAIå…¼å®¹çš„/v1/chat/completionsæ¥å£
    # è·¯ç”±è¯·æ±‚åˆ°scheduler
    # å¤„ç†æµå¼/éæµå¼å“åº”
    ```

    **2. tokenizer.py - åˆ†è¯å™¨**
    ```python
    # ç‹¬ç«‹çš„tokenizeræœåŠ¡
    # å‡è½»ä¸»è¿›ç¨‹è´Ÿæ‹…
    # æ”¯æŒå¤šç§æ¨¡å‹ï¼ˆLlama, Qwenï¼‰
    ```

    **3. scheduler.py - è°ƒåº¦å™¨**
    ```python
    # Overlap Schedulingå®ç°
    # CPU-GPUåŒçº¿ç¨‹è®¾è®¡
    # Radix Cacheç®¡ç†
    # Chunked Prefillè°ƒåº¦
    ```

    **4. radix_cache.py - KV Cache**
    ```python
    # Radix Treeæ•°æ®ç»“æ„
    # å…±äº«å‰ç¼€è‡ªåŠ¨æ£€æµ‹
    # å¢é‡æ›´æ–°æœºåˆ¶
    ```

    **5. model_runner.py - æ¨¡å‹æ‰§è¡Œ**
    ```python
    # Tensor Parallelismæ”¯æŒ
    # NCCLé€šä¿¡
    # GPU kernelå¯åŠ¨
    ```

  - **å…³é”®è®¾è®¡å†³ç­–**ï¼š
    - **ç®€æ´æ€§ä¼˜å…ˆ**ï¼šç§»é™¤è¾¹ç¼˜caseå¤„ç†ï¼Œä¸“æ³¨æ ¸å¿ƒé€»è¾‘
    - **æ•™å­¦å‹å¥½**ï¼šæ¸…æ™°çš„æ¨¡å—åˆ’åˆ†ï¼Œæ˜“äºé˜…è¯»
    - **æ˜“äºæ‰©å±•**ï¼šç ”ç©¶åŸå‹å¯å¿«é€Ÿæ·»åŠ æ–°åŠŸèƒ½

  **10.6.6.3 ç ”ç©¶åŸå‹æœ€ä½³å®è·µ**

  - **åœºæ™¯1ï¼šå¿«é€ŸéªŒè¯æ–°kernel**
    ```python
    # ä¼ ç»Ÿæ–¹å¼ï¼šåœ¨vLLMä¸­æ·»åŠ æ–°kernel
    # 1. å®šä½åˆ°ç›¸å…³æ–‡ä»¶ï¼ˆåœ¨300kè¡Œä»£ç ä¸­ï¼‰
    # 2. ç†è§£ç°æœ‰kernelæ¥å£
    # 3. é›†æˆæ–°kernelï¼ˆæ‹…å¿ƒç ´åç³»ç»Ÿï¼‰
    # 4. æµ‹è¯•ï¼ˆå¯èƒ½å½±å“å…¶ä»–åŠŸèƒ½ï¼‰
    # â†’ éœ€è¦æ•°å‘¨æ—¶é—´

    # Mini-SGLangæ–¹å¼
    # 1. åœ¨kernels/ç›®å½•æ·»åŠ æ–°kernel
    # 2. åœ¨model_runner.pyä¸­è°ƒç”¨
    # 3. ç«‹å³æµ‹è¯•
    # â†’ å‡ å°æ—¶å†…å®Œæˆ
    ```

  - **åœºæ™¯2ï¼šè°ƒåº¦ç®—æ³•å®éªŒ**
    ```python
    # ä¿®æ”¹scheduler.pyä¸­çš„è°ƒåº¦é€»è¾‘
    # ä¾‹å¦‚ï¼šæµ‹è¯•æ–°çš„batch selectionç­–ç•¥
    def custom_schedule(self, requests):
        # ä½ çš„æ–°ç®—æ³•
        pass

    # ç«‹å³çœ‹åˆ°æ•ˆæœï¼Œæ— éœ€æ‹…å¿ƒå½±å“ç”Ÿäº§ç³»ç»Ÿ
    ```

  - **åœºæ™¯3ï¼šOpenAIå…¼å®¹benchmark**
    ```bash
    # Mini-SGLangå†…ç½®benchmarkå·¥å…·
    python benchmark.py \
      --url http://localhost:8000/v1 \
      --model "Qwen/Qwen3-32B" \
      --dataset sharegpt

    # å¯¹æ¯”vLLMã€SGLangã€TensorRT-LLM
    # ç»“æœå¯ç›´æ¥ç”¨äºè®ºæ–‡
    ```

  - **å†…æ ¸å¼€å‘è°ƒè¯•**ï¼š
    ```python
    # Mini-SGLangæä¾›ç»†ç²’åº¦NVTX annotations
    # å¯åœ¨Nsight Systemsä¸­ç²¾ç¡®åˆ†ææ¯ä¸ªkernel

    nsys profile \
      --output=mykernel.qdrep \
      python -m minisgl --model "Qwen/Qwen3-32B"

    # ç²¾ç¡®å®šä½ä½ çš„kernelçš„æ€§èƒ½ç“¶é¢ˆ
    ```

  **10.6.6.4 OpenAIå…¼å®¹APIè®¾è®¡**

  - **æ— ç¼æ›¿æ¢vLLM/SGLang**ï¼š
    ```python
    from openai import OpenAI

    # åªéœ€ä¿®æ”¹base_url
    client = OpenAI(
        base_url="http://localhost:8000/v1",  # Mini-SGLang
        api_key="dummy"
    )

    # å®Œå…¨ç›¸åŒçš„API
    response = client.chat.completions.create(
        model="Qwen/Qwen3-32B",
        messages=[{"role": "user", "content": "Hello!"}],
        stream=True
    )
    ```

  - **æ”¯æŒçš„æ¨¡å‹**ï¼š
    - Llama-3.xç³»åˆ—
    - Qwen-3.xç³»åˆ—
    - Mistralç³»åˆ—
    - ä»»ä½•HuggingFaceå…¼å®¹æ¨¡å‹

  **10.6.6.5 ä½¿ç”¨Mini-SGLangå­¦ä¹ LLMæ¨ç†**

  - **æ¨èå­¦ä¹ è·¯å¾„**ï¼ˆæŒ‰é¡ºåºï¼‰ï¼š

    **Week 1: ç†è§£æ•´ä½“æ¶æ„**
    ```
    Day 1-2: server.py
      - OpenAI APIå¦‚ä½•å®ç°
      - è¯·æ±‚å¦‚ä½•è·¯ç”±

    Day 3-4: scheduler.py
      - Overlap Schedulingå¦‚ä½•å·¥ä½œ
      - CPU-GPUå¹¶è¡Œæœºåˆ¶

    Day 5: tokenizer.py
      - ç‹¬ç«‹çš„tokenizeræœåŠ¡è®¾è®¡
    ```

    **Week 2: æ·±å…¥æ ¸å¿ƒä¼˜åŒ–**
    ```
    Day 1-3: radix_cache.py
      - Radix Treeæ•°æ®ç»“æ„
      - å…±äº«å‰ç¼€æ£€æµ‹ç®—æ³•

    Day 4-5: model_runner.py
      - Tensor Parallelismå®ç°
      - NCCLé€šä¿¡
    ```

    **Week 3: CUDA kernels**
    ```
    Day 1-3: kernels/flashattention.py
      - FlashAttention-3é›†æˆ
      - JITç¼–è¯‘æœºåˆ¶

    Day 4-5: kernels/flashinfer.py
      - FlashInferé›†æˆ
      - Decode kernelä¼˜åŒ–
    ```

  - **å®æˆ˜ç»ƒä¹ **ï¼š
    1. **Exercise 1**: æ·»åŠ è‡ªå®šä¹‰è°ƒåº¦ç­–ç•¥
       - åœ¨scheduler.pyä¸­å®ç°priority-based scheduling
       - Benchmarkæ€§èƒ½æå‡

    2. **Exercise 2**: æ‰©å±•Radix Cache
       - æ·»åŠ eviction policyï¼ˆLRU/LFUï¼‰
       - åˆ†æå†…å­˜åˆ©ç”¨ç‡å˜åŒ–

    3. **Exercise 3**: é›†æˆæ–°attention kernel
       - åœ¨kernels/ç›®å½•æ·»åŠ æ–°kernel
       - ä½¿ç”¨Nsight Systemsåˆ†ææ€§èƒ½

  **10.6.6.6 æ€§èƒ½å¯¹æ¯”**

  - **Offline Throughput** (Mini-SGLang vs Nano-vLLM):
    - Qwen3-0.6B: Mini-SGLangå¿«**1.5å€**
    - Qwen3-14B: Mini-SGLangå¿«**1.3å€**
    - åŸå› ï¼šOverlap Scheduling

  - **Online Serving** (Mini-SGLang vs SGLang):
    - Throughput: **å‡ ä¹ç›¸åŒ**
    - P90 TTFT: **å‡ ä¹ç›¸åŒ**
    - TBT: **å‡ ä¹ç›¸åŒ**
    - ç»“è®ºï¼š5kè¡Œä»£ç å®ç°äº†300kè¡Œçš„æ€§èƒ½

  - **GPUåˆ©ç”¨ç‡**:
    - Without Overlap: 75%
    - With Overlap: 95%
    - æå‡ï¼š**27%**

  **10.6.6.7 ä½•æ—¶é€‰æ‹©Mini-SGLangï¼Ÿ**

  - **æ•™è‚²åœºæ™¯**ï¼š
    - âœ… LLMæ¨ç†è¯¾ç¨‹
    - âœ… ç³»ç»Ÿè®¾è®¡å­¦ä¹ 
    - âœ… CUDA kernelå¼€å‘æ•™å­¦

  - **ç ”ç©¶åœºæ™¯**ï¼š
    - âœ… å¿«é€ŸåŸå‹éªŒè¯
    - âœ… æ–°è°ƒåº¦ç®—æ³•å®éªŒ
    - âœ… Kernelå¼€å‘è°ƒè¯•
    - âœ… è®ºæ–‡å®éªŒbaseline

  - **ç”Ÿäº§åœºæ™¯**ï¼š
    - âš ï¸ å¯ä»¥ä½¿ç”¨ï¼Œä½†å»ºè®®å…ˆç”¨SGLang
    - âš ï¸ Mini-SGLangç¼ºå°‘ä¸€äº›è¾¹ç¼˜caseå¤„ç†
    - âœ… é€‚åˆå°å‹é¡¹ç›®æˆ–MVP

  - **ä¸é€‚åˆ**ï¼š
    - âŒ è¶…å¤§è§„æ¨¡éƒ¨ç½²ï¼ˆç”¨vLLM/SGLangï¼‰
    - âŒ éœ€è¦å®Œæ•´åŠŸèƒ½æ”¯æŒï¼ˆç”¨SGLangï¼‰
    - âŒ ä¼ä¸šçº§ç¨³å®šæ€§è¦æ±‚ï¼ˆç”¨vLLMï¼‰

  **10.6.6.8 èµ„æºé“¾æ¥**

  - **GitHub**: https://github.com/sgl-project/mini-sglang
  - **Blog**: https://lmsys.org/blog/2025-12-17-minisgl/
  - **æ–‡æ¡£**: https://github.com/sgl-project/mini-sglang/tree/main/docs
  - **Discussions**: GitHub Discussions

#### 10.7 ROIç›‘æ§ä¸æˆæœ¬è¿½è¸ª
- 10.7.1 å¦‚ä½•è¿½è¸ªæ¨ç†æˆæœ¬
- 10.7.2 ä¼˜åŒ–æªæ–½çš„ROIè®¡ç®—
- 10.7.3 æŒç»­ä¼˜åŒ–æµç¨‹

#### 10.8 å®‰å…¨æ€§è€ƒè™‘
- 10.8.1 APIè®¤è¯ä¸æˆæƒ
- 10.8.2 å†…å®¹å®‰å…¨è¿‡æ»¤
- 10.8.3 é€Ÿç‡é™åˆ¶
- 10.8.4 æ•°æ®éšç§

#### 10.9 ç¾å¤‡ä¸å®¹é”™
- 10.9.1 å¤±è´¥åœºæ™¯åˆ†æ
- 10.9.2 å¥åº·æ£€æŸ¥
- 10.9.3 è‡ªåŠ¨é‡å¯ç­–ç•¥
- 10.9.4 é™çº§æ–¹æ¡ˆ

#### 10.10 RLç³»ç»Ÿéƒ¨ç½² âš ï¸ å¼€æºç”Ÿæ€ç¼ºå¤±

> **ğŸ’¡ 2025å¹´æŠ€æœ¯è¶‹åŠ¿**ï¼ˆæ¥æºï¼š2025"é’ç¨"AIå˜‰å¹´å - æœ±å­æ—@è´¨æœ´ã€æœ±ç«‹è€•@NVIDIAï¼‰
>
> **æ ¸å¿ƒæ´å¯Ÿ**ï¼šRLç³»ç»Ÿä¸åŒäºä¼ ç»Ÿæ¨ç†ç³»ç»Ÿï¼Œéœ€è¦åŒæ—¶å¤„ç†è®­ç»ƒå’Œæ¨ç†ä¸¤ä¸ªworkloadï¼Œå¯¹infraæå‡ºäº†å…¨æ–°çš„æŒ‘æˆ˜ã€‚

- 10.10.1 ä»€ä¹ˆæ˜¯RLç³»ç»Ÿ
  - **è®­ç»ƒï¼ˆTrainingï¼‰**ï¼šæ›´æ–°æ¨¡å‹å‚æ•°
  - **æ¨ç†ï¼ˆRolloutï¼‰**ï¼šç”Ÿæˆexperienceæ•°æ®
  - **åŒºåˆ«äºä¼ ç»Ÿæ¨ç†**ï¼šéœ€è¦åŒæ—¶è¿è¡Œä¸¤ä¸ªworkload
  - **ä¸ºä»€ä¹ˆå¤æ‚**ï¼šè®­ç»ƒå’Œæ¨ç†çš„èµ„æºéœ€æ±‚å·®å¼‚å·¨å¤§

- 10.10.2 RLç³»ç»Ÿçš„å…³é”®æŒ‘æˆ˜ï¼ˆæœ±å­æ—@è´¨æœ´ï¼‰
  - **ç¼ºå°‘ç»Ÿä¸€ä¸»çº¿**ï¼šä¸åƒpretrainé‚£æ ·åªå·MFU
  - **éœ€è¦çµæ´»æ€§**ï¼šä¸åŒåœºæ™¯éœ€è¦ä¸åŒçš„workflow
  - **CPUçš„é‡è¦æ€§**ï¼šAgentç¯å¢ƒéœ€è¦å¤§é‡CPUï¼ˆå¼ æ˜æ˜Ÿ@æ¸…åï¼‰
  - **å¼€æºç”Ÿæ€ç¼ºå¤±**ï¼šAgent systemåŸºæœ¬æ˜¯è´Ÿåˆ†ï¼ˆæœ±ç«‹è€•@NVIDIAï¼‰

- 10.10.3 Scalable Sandbox System
  - **é—®é¢˜**ï¼ˆæœ±ç«‹è€•@NVIDIAï¼‰ï¼š
    - æ­å»ºJupyter agentåœ¨å…¬å¸å†…éƒ¨éƒ½å¾ˆéš¾
    - éœ€è¦manage K8Sã€è‡ªåŠ¨èµ·virtual environment
    - å­¦æœ¯ç•Œå‡ ä¹æ²¡æœ‰ä½¿ç”¨ç»éªŒ
  - **éœ€æ±‚**ï¼š
    - Scalable and easy to useçš„sandbox system
    - åƒinference engineä¸€æ ·ç»™ä¸ªURL
    - å‘HTTP requestå°±èƒ½å®Œæˆæ‰€æœ‰äº‹æƒ…
  - **ç°çŠ¶**ï¼š
    - å¼€æºç”Ÿæ€å®Œå…¨ç¼ºå¤±
    - å¯¼è‡´æ— æ³•å¾ˆå¥½åœ°åšagent
    - åªèƒ½ç”¨dirtyæ–¹æ³•ï¼ˆmock pythonè¿›ç¨‹ï¼‰

- 10.10.4 Trainå’ŒRolloutçš„èµ„æºåŠ¨æ€åˆ†é…ï¼ˆæœ±ç«‹è€•@NVIDIAï¼‰
  - **é—®é¢˜**ï¼š
    - ä¼ ç»Ÿåšæ³•ï¼šè®­ç»ƒå’ŒRolloutç”¨åŒæ ·å¡æ•°ï¼ˆå¦‚128å¡ï¼‰
    - GPUç©ºç½®ï¼Œåˆ©ç”¨ç‡éå¸¸ä½
  - **æŒ‘æˆ˜**ï¼š
    - è®­ç»ƒé˜¶æ®µï¼šå¯èƒ½åªéœ€è¦64å¡
    - Rollouté˜¶æ®µï¼šå¯èƒ½éœ€è¦256æˆ–512å¡
  - **éœ€æ±‚**ï¼š
    - ç»™ä¸€ç»„podï¼ˆå¦‚1024å¼ å¡ï¼‰
    - åŠ¨æ€è°ƒæ•´trainå’Œrolloutçš„å¡æ•°
    - Elastic dynamic resource allocation
  - **è§‚å¯Ÿ**ï¼š
    - ç”¨verlæˆ–slimeè·‘ä¸ç¨³å®šä»»åŠ¡
    - GPUç»å¸¸ç©ºåœ¨é‚£é‡Œé—²ç½®
    - è‡ªåŠ¨scalingå¯ä»¥å¤§å¹…æå‡GPUåˆ©ç”¨ç‡

- 10.10.5 RLæ¡†æ¶ä»‹ç»
  - **slime**ï¼ˆæœ±å­æ—@è´¨æœ´ï¼‰ï¼š
    - åŒæ—¶æœ‰è®­ç»ƒæ¡†æ¶å’Œæ¨ç†æ¡†æ¶
    - Rolloutå’Œé©±åŠ¨æ¡†æ¶çš„è”åˆ
    - å‚æ•°æ›´æ–°ã€æ¨ç†ç”Ÿæˆæ•°æ®ä¼ å›
    - ç»™ç®—æ³•è€å¸ˆè¶³å¤Ÿçš„è‡ªå®šä¹‰æ¥å£
  - **verl**ï¼š
    - å¼€æºRLæ¡†æ¶
    - æ”¯æŒå¤šç§RLç®—æ³•
  - **veRL**ï¼š
    - å¦ä¸€ä¸ªå¼€æºRLæ¡†æ¶
  - **arewe**ï¼š
    - RLè®­ç»ƒå’Œæ¨ç†çš„ç»Ÿä¸€æ¡†æ¶

- 10.10.6 éƒ¨ç½²æ¶æ„
  - **å•æœºéƒ¨ç½²**ï¼š
    - é€‚åˆå°è§„æ¨¡å®éªŒ
    - Trainingå’ŒRolloutå…±äº«GPU
  - **åˆ†å¸ƒå¼éƒ¨ç½²**ï¼š
    - Training cluster + Rollout cluster
    - éœ€è¦å¤„ç†checkpointåŒæ­¥
  - **å¼‚æ„éƒ¨ç½²**ï¼ˆæœ±ç«‹è€•@NVIDIAï¼‰ï¼š
    - Trainingç”¨H100ï¼ˆè®¡ç®—å¯†é›†ï¼‰
    - Rolloutç”¨H200æˆ–å…¶ä»–å¡
    - å……åˆ†åˆ©ç”¨ä¸åŒç¡¬ä»¶çš„ä¼˜åŠ¿

- 10.10.7 ç›‘æ§å’Œå¯è§‚æµ‹æ€§
  - **Training metrics**ï¼šLossã€Rewardã€Gradient norm
  - **Rollout metrics**ï¼šTPSã€Latencyã€Success rate
  - **Resource utilization**ï¼šGPUã€CPUã€Memoryã€Network
  - **ç³»ç»Ÿå¥åº·åº¦**ï¼šWorker statusã€CheckpointçŠ¶æ€

- 10.10.8 å®æˆ˜æ¡ˆä¾‹
  - **æ¡ˆä¾‹1**ï¼šä½¿ç”¨slimeéƒ¨ç½²ç®€å•RLä»»åŠ¡
  - **æ¡ˆä¾‹2**ï¼šå¼‚æ„GPUçš„RLéƒ¨ç½²ï¼ˆH100+H200ï¼‰
  - **æ¡ˆä¾‹3**ï¼šå¤§è§„æ¨¡RLçš„å¼¹æ€§èµ„æºåˆ†é…

#### 10.11 vLLMæ’ä»¶ç³»ç»Ÿ â­â­

> **ğŸ’¡ å·¥ä¸šç•Œå®è·µ**ï¼ˆæ¥æºï¼švLLMå®˜æ–¹åšå®¢ 2025-11-20ï¼‰
>
> **æ ¸å¿ƒæ´å¯Ÿ**ï¼šæ’ä»¶ç³»ç»Ÿæ˜¯ç”Ÿäº§ç¯å¢ƒä¸­ç®¡ç†vLLMå®šåˆ¶åŒ–ä¿®æ”¹çš„å®˜æ–¹æ¨èæ–¹æ¡ˆï¼Œé¿å…äº†ç»´æŠ¤forkçš„è´Ÿæ‹…ï¼ŒåŒæ—¶ä¿æŒäº†ä¸ä¸Šæ¸¸çš„åŒæ­¥æ›´æ–°èƒ½åŠ›ã€‚

åœ¨éƒ¨ç½²vLLMåˆ°ç”Ÿäº§ç¯å¢ƒæ—¶ï¼Œæˆ‘ä»¬ç»å¸¸éœ€è¦ä¿®æ”¹æŸäº›è¡Œä¸ºæ¥æ»¡è¶³ç‰¹å®šéœ€æ±‚ã€‚ä¼ ç»Ÿçš„æ–¹æ³•åŒ…æ‹¬ï¼š
- Forkæ•´ä¸ªvLLMä»“åº“
- ä½¿ç”¨Monkey Patch
- ç­‰å¾…ä¸Šæ¸¸åˆå¹¶

vLLMæ’ä»¶ç³»ç»Ÿæä¾›äº†æ›´å¥½çš„è§£å†³æ–¹æ¡ˆã€‚

- 10.11.1 ä¸ºä»€ä¹ˆéœ€è¦æ’ä»¶ç³»ç»Ÿ

  **ç”Ÿäº§ç¯å¢ƒçš„å¸¸è§éœ€æ±‚**ï¼š
  - ä¿®æ”¹è°ƒåº¦ç­–ç•¥ï¼ˆå¦‚è‡ªå®šä¹‰priorityè®¡ç®—ï¼‰
  - æ·»åŠ æ–°çš„é‡‡æ ·ç®—æ³•
  - å®šåˆ¶æ—¥å¿—å’Œç›‘æ§
  - é›†æˆå†…éƒ¨çš„è®¤è¯ç³»ç»Ÿ
  - ä¿®æ”¹APIè¡Œä¸º

  **ä¼ ç»Ÿæ–¹æ³•çš„ç—›ç‚¹**ï¼š
  - **Forkä»“åº“**ï¼š
    - ç»´æŠ¤æˆæœ¬é«˜ï¼Œéœ€è¦æŒç»­åŒæ­¥ä¸Šæ¸¸æ›´æ–°
    - å®¹æ˜“äº§ç”Ÿå†²çª
    - ä¸¢å¤±ç¤¾åŒºçš„æ–°ç‰¹æ€§
  - **Monkey Patch**ï¼š
    - è„†å¼±ï¼Œä¾èµ–ä»£ç ç»“æ„
    - å‡çº§vLLMæ—¶å®¹æ˜“å¤±æ•ˆ
    - éš¾ä»¥ç®¡ç†å’Œè¿½è¸ª
  - **ç­‰å¾…ä¸Šæ¸¸**ï¼š
    - æ—¶é—´ä¸ç¡®å®š
    - ä½ çš„éœ€æ±‚å¯èƒ½ä¸æ˜¯ä¸Šæ¸¸çš„ä¼˜å…ˆçº§

  **æ’ä»¶ç³»ç»Ÿçš„ä¼˜åŠ¿**ï¼š
  - **å®˜æ–¹æ”¯æŒ**ï¼švLLMå†…ç½®çš„æ‰©å±•æœºåˆ¶
  - **æœ€å°åŒ–ä¿®æ”¹**ï¼šåªä¿®æ”¹éœ€è¦æ”¹å˜çš„éƒ¨åˆ†
  - **ç‰ˆæœ¬å…¼å®¹**ï¼šæ”¯æŒç‰ˆæœ¬æ£€æŸ¥ï¼Œè‡ªåŠ¨åŒ¹é…
  - **è¿è¡Œæ—¶æ¿€æ´»**ï¼šé€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶
  - **æ˜“äºç»´æŠ¤**ï¼šå‡çº§vLLMæ—¶æ’ä»¶ä»å¯å·¥ä½œ

- 10.11.2 æ’ä»¶ç³»ç»Ÿ vs Fork vs Monkey Patch

  | æ–¹æ¡ˆ | ç»´æŠ¤æˆæœ¬ | å‡çº§å…¼å®¹æ€§ | å¯é æ€§ | çµæ´»æ€§ |
  |------|---------|-----------|--------|--------|
  | Fork | é«˜ âŒ | éœ€è¦æ‰‹åŠ¨merge | ä¸­ âœ… | é«˜ âœ… |
  | Monkey Patch | ä½ âœ… | å·® âŒ | ä½ âŒ | ä¸­ |
  | Plugin System | ä½ âœ… | å¥½ âœ… | é«˜ âœ… | ä¸­ |

  **é€‰æ‹©å»ºè®®**ï¼š
  - **æ’ä»¶ç³»ç»Ÿ**ï¼šé¦–é€‰æ–¹æ¡ˆï¼Œé€‚åˆå¤§å¤šæ•°å®šåˆ¶éœ€æ±‚
  - **Fork**ï¼šä»…å½“éœ€è¦å¤§è§„æ¨¡æ¶æ„ä¿®æ”¹æ—¶
  - **Monkey Patch**ï¼šä»…ç”¨äºå¿«é€Ÿå®éªŒï¼Œä¸é€‚åˆç”Ÿäº§

- 10.11.3 VLLMPatchåŸºç¡€

  **æ ¸å¿ƒæ¦‚å¿µ**ï¼š
  - `VLLMPatch`ï¼šæ’ä»¶åŸºç±»ï¼Œç”¨äºå£°æ˜è¦ä¿®æ”¹çš„ç±»
  - Surgical-level overrideï¼šåªé‡å†™éœ€è¦çš„æ–¹æ³•
  - Entry point registrationï¼šåœ¨`setup.py`ä¸­æ³¨å†Œæ’ä»¶
  - Runtime activationï¼šé€šè¿‡`VLLM_CUSTOM_PATCHES`ç¯å¢ƒå˜é‡æ¿€æ´»

  **åŸºæœ¬æ¨¡å¼**ï¼š

  ```python
  from vllm.plugin import VLLMPatch

  # 1. å®šä¹‰æ’ä»¶ï¼šæŒ‡å®šè¦ä¿®æ”¹çš„ç›®æ ‡ç±»
  class MySchedulerPatch(VLLMPatch[Scheduler]):
      # 2. é‡å†™éœ€è¦ä¿®æ”¹çš„æ–¹æ³•
      def _schedule(self):
          # è‡ªå®šä¹‰è°ƒåº¦é€»è¾‘
          print("Using custom scheduler!")
          return super()._schedule()

      # 3. ä¿ç•™å…¶ä»–æ–¹æ³•ä¸å˜
      # Schedulerçš„å…¶ä»–æ–¹æ³•ä¿æŒåŸæ ·
  ```

  **ç‰ˆæœ¬å…¼å®¹æ€§è£…é¥°å™¨**ï¼š

  ```python
  from vllm.plugin import min_vllm_version

  class MySchedulerPatch(VLLMPatch[Scheduler]):
      @min_vllm_version("0.6.0")  # è¦æ±‚vLLM >= 0.6.0
      def _schedule(self):
          # è‡ªå®šä¹‰é€»è¾‘
          pass
  ```

  **Entry Pointæ³¨å†Œ**ï¼ˆåœ¨`setup.py`ä¸­ï¼‰ï¼š

  ```python
  setup(
      name="vllm-custom-plugins",
      # ...å…¶ä»–é…ç½®
      entry_points={
          'vllm.general_plugins': [
              'custom_patches = my_vllm_patches:register_patches'
          ]
      }
  )
  ```

  **æ³¨å†Œå‡½æ•°**ï¼ˆ`my_vllm_patches/__init__.py`ï¼‰ï¼š

  ```python
   def register_patches():
       from .scheduler_patch import MySchedulerPatch
       from .logger_patch import MyLoggerPatch

       return [
           MySchedulerPatch,
           MyLoggerPatch,
       ]
  ```

- 10.11.4 å®æˆ˜ï¼šåˆ›å»ºè‡ªå®šä¹‰æ’ä»¶

  **åœºæ™¯**ï¼šä¿®æ”¹vLLMçš„è°ƒåº¦ç­–ç•¥ï¼Œè®©é«˜ä¼˜å…ˆçº§è¯·æ±‚æ€»æ˜¯è¢«ä¼˜å…ˆå¤„ç†

  **æ­¥éª¤1ï¼šåˆ›å»ºæ’ä»¶é¡¹ç›®ç»“æ„**

  ```
  vllm-custom-plugins/
  â”œâ”€â”€ setup.py
  â”œâ”€â”€ vllm_custom_patches/
  â”‚   â”œâ”€â”€ __init__.py
  â”‚   â””â”€â”€ priority_scheduler.py
  â””â”€â”€ README.md
  ```

  **æ­¥éª¤2ï¼šå®ç°æ’ä»¶**ï¼ˆ`priority_scheduler.py`ï¼‰

  ```python
  from vllm.core.scheduler import Scheduler
  from vllm.plugin import VLLMPatch, min_vllm_version
  from typing import List
  import logging

  logger = logging.getLogger(__name__)

  class PrioritySchedulerPatch(VLLMPatch[Scheduler]):
      """
      è‡ªå®šä¹‰è°ƒåº¦ç­–ç•¥ï¼šä¼˜å…ˆå¤„ç†é«˜ä¼˜å…ˆçº§è¯·æ±‚

      ä½¿ç”¨æ–¹æ³•ï¼š
      1. åœ¨è¯·æ±‚ä¸­æ·»åŠ  'priority' å­—æ®µ
      2. schedulerå°†æŒ‰priorityæ’åºï¼ˆæ•°å€¼è¶Šå¤§è¶Šä¼˜å…ˆï¼‰
      """

      @min_vllm_version("0.6.0")
      def _schedule(self) -> List:
          """é‡å†™è°ƒåº¦æ–¹æ³•ï¼Œæ·»åŠ ä¼˜å…ˆçº§é€»è¾‘"""

          # è·å–å½“å‰ç­‰å¾…çš„è¯·æ±‚
          scheduled = self._schedule_original()

          if not scheduled:
              return scheduled

          # æŒ‰priorityæ’åºï¼ˆå¦‚æœæœ‰ï¼‰
          def get_priority(request):
              return request.get('priority', 0)

          scheduled.sort(key=get_priority, reverse=True)

          logger.info(f"Scheduled {len(scheduled)} requests with priority")

          return scheduled
  ```

  **æ­¥éª¤3ï¼šæ³¨å†Œæ’ä»¶**ï¼ˆ`__init__.py`ï¼‰

  ```python
  def register_patches():
      from .priority_scheduler import PrioritySchedulerPatch

      return [
          PrioritySchedulerPatch,
      ]
  ```

  **æ­¥éª¤4ï¼šå®‰è£…æ’ä»¶**

  ```bash
  # å¼€å‘æ¨¡å¼å®‰è£…
  cd vllm-custom-plugins
  pip install -e .

  # æˆ–è€…æ„å»ºwheelåå®‰è£…
  python setup.py bdist_wheel
  pip install dist/vllm_custom_plugins-0.1.0-py3-none-any.whl
  ```

  **æ­¥éª¤5ï¼šæ¿€æ´»æ’ä»¶**

  ```bash
  # æ–¹å¼1ï¼šç¯å¢ƒå˜é‡ï¼ˆæ¨èï¼‰
  export VLLM_CUSTOM_PATCHES="vllm_custom_patches"

  # æ–¹å¼2ï¼šåœ¨Pythonä»£ç ä¸­
  import os
  os.environ['VLLM_CUSTOM_PATCHES'] = 'vllm_custom_patches'

  from vllm import LLM

  # å¯åŠ¨vLLMï¼Œæ’ä»¶ä¼šè‡ªåŠ¨åŠ è½½
  llm = LLM(model="meta-llama/Llama-3.1-8B")
  ```

  **æ­¥éª¤6ï¼šä½¿ç”¨æ’ä»¶**

  ```python
  from vllm import LLM, SamplingParams

  llm = LLM(model="meta-llama/Llama-3.1-8B")

  # é«˜ä¼˜å…ˆçº§è¯·æ±‚
  prompts_high = [
      {"prompt": "ç´§æ€¥ä»»åŠ¡", "priority": 100},
      {"prompt": "VIPç”¨æˆ·", "priority": 90},
  ]

  # æ™®é€šè¯·æ±‚
  prompts_normal = [
      {"prompt": "æ™®é€šä»»åŠ¡", "priority": 0},
  ]

  # é«˜ä¼˜å…ˆçº§è¯·æ±‚ä¼šå…ˆè¢«å¤„ç†
  outputs = llm.generate(prompts_high + prompts_normal)
  ```

- 10.11.5 ç‰ˆæœ¬ç®¡ç†ä¸å…¼å®¹æ€§

  **ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥**ï¼š
  - ä½¿ç”¨`@min_vllm_version`è£…é¥°å™¨
  - vLLMå¯åŠ¨æ—¶ä¼šè‡ªåŠ¨æ£€æŸ¥
  - ç‰ˆæœ¬ä¸åŒ¹é…æ—¶ç»™å‡ºæ¸…æ™°çš„é”™è¯¯ä¿¡æ¯

  ```python
  from vllm.plugin import min_vllm_version

  class MyPatch(VLLMPatch[Scheduler]):
      @min_vllm_version("0.6.0")
      def my_method(self):
          # è¿™ä¸ªæ–¹æ³•åªåœ¨vLLM >= 0.6.0æ—¶ç”Ÿæ•ˆ
          pass

      @min_vllm_version("0.6.3")
      def another_method(self):
          # è¿™ä¸ªæ–¹æ³•éœ€è¦vLLM >= 0.6.3
          pass
  ```

  **å¤šç‰ˆæœ¬æ”¯æŒ**ï¼š

  ```python
  class MySchedulerPatch(VLLMPatch[Scheduler]):
      def _schedule(self):
          # æ ¹æ®vLLMç‰ˆæœ¬é€‰æ‹©ä¸åŒå®ç°
          if self._vllm_version >= (0, 6, 3):
              return self._schedule_v2()
          else:
              return self._schedule_v1()

      def _schedule_v2(self):
          # 0.6.3+çš„æ–°å®ç°
          pass

      def _schedule_v1(self):
          # 0.6.0-0.6.2çš„æ—§å®ç°
          pass
  ```

  **å‡çº§vLLMæ—¶çš„æ³¨æ„äº‹é¡¹**ï¼š
  1. æµ‹è¯•æ’ä»¶æ˜¯å¦ä»æ­£å¸¸å·¥ä½œ
  2. æŸ¥çœ‹vLLM changelogï¼Œæ£€æŸ¥APIå˜åŒ–
  3. æ›´æ–°`@min_vllm_version`çº¦æŸ
  4. å¿…è¦æ—¶æ›´æ–°æ’ä»¶ä»£ç 

- 10.11.6 ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

  **1. æ’ä»¶é¡¹ç›®ç»“æ„**

  ```
  company-vllm-plugins/
  â”œâ”€â”€ plugins/
  â”‚   â”œâ”€â”€ scheduler/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â””â”€â”€ priority.py
  â”‚   â”œâ”€â”€ logging/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â””â”€â”€ custom.py
  â”‚   â””â”€â”€ auth/
  â”‚       â”œâ”€â”€ __init__.py
  â”‚       â””â”€â”€ rbac.py
  â”œâ”€â”€ setup.py
  â”œâ”€â”€ requirements.txt
  â”œâ”€â”€ README.md
  â””â”€â”€ tests/
  ```

  **2. Dockeré›†æˆ**

  ```dockerfile
  # Dockerfile
  FROM vllm/vllm-openai:v0.6.0

  # å®‰è£…è‡ªå®šä¹‰æ’ä»¶
  COPY company-vllm-plugins /app/plugins
  RUN pip install /app/plugins

  # æ¿€æ´»æ’ä»¶
  ENV VLLM_CUSTOM_PATCHES="company_vllm_plugins"

  # å¯åŠ¨vLLM
  CMD ["--model", "meta-llama/Llama-3.1-8B"]
  ```

  ```yaml
  # Kubernetes deployment
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: vllm-with-plugins
  spec:
    template:
      spec:
        containers:
        - name: vllm
          image: your-registry/vllm-custom:latest
          env:
          - name: VLLM_CUSTOM_PATCHES
            value: "company_vllm_plugins"
          - name: ENABLE_CUSTOM_PLUGINS
            value: "true"
  ```

  **3. æ’ä»¶å¼€å‘è§„èŒƒ**

  ```python
  """
  company_vllm/plugins/scheduler/priority.py

  å…¬å¸å†…éƒ¨ä¼˜å…ˆçº§è°ƒåº¦æ’ä»¶

  ä½¿ç”¨æ–¹æ³•ï¼š
  1. å®‰è£…ï¼špip install company-vllm-plugins
  2. æ¿€æ´»ï¼šexport VLLM_CUSTOM_PATCHES="company_vllm_plugins"
  3. æµ‹è¯•ï¼špytest tests/test_priority_scheduler.py

  ç‰ˆæœ¬è¦æ±‚ï¼švLLM >= 0.6.0
  ç»´æŠ¤è€…ï¼šinfra-team@company.com
  """

  from vllm.core.scheduler import Scheduler
  from vllm.plugin import VLLMPatch, min_vllm_version

  class PrioritySchedulerPatch(VLLMPatch[Scheduler]):
      """ä¼˜å…ˆçº§è°ƒåº¦æ’ä»¶"""

      # æ–‡æ¡£å­—ç¬¦ä¸²
      """
      ä¿®æ”¹vLLMè°ƒåº¦ç­–ç•¥ï¼Œæ”¯æŒåŸºäºpriorityå­—æ®µçš„ä¼˜å…ˆçº§è°ƒåº¦ã€‚

      Priorityå­—æ®µï¼š
      - 0ï¼šæ™®é€šè¯·æ±‚ï¼ˆé»˜è®¤ï¼‰
      - 1-50ï¼šä½ä¼˜å…ˆçº§
      - 51-90ï¼šä¸­ä¼˜å…ˆçº§
      - 91-100ï¼šé«˜ä¼˜å…ˆçº§
      - 101+ï¼šç´§æ€¥è¯·æ±‚

      ç¤ºä¾‹ï¼š
          prompts = [
              {"text": "hello", "priority": 100},  # ç´§æ€¥
              {"text": "world", "priority": 0},    # æ™®é€š
          ]
      """

      @min_vllm_version("0.6.0")
      def _schedule(self):
          # å®ç°é€»è¾‘
          pass

      def _validate_priority(self, priority):
          """å‚æ•°éªŒè¯"""
          if not isinstance(priority, int):
              raise TypeError(f"Priority must be int, got {type(priority)}")
          if priority < 0 or priority > 1000:
              raise ValueError(f"Priority must be 0-1000, got {priority}")
          return True
  ```

  **4. æµ‹è¯•æ’ä»¶**

  ```python
  # tests/test_priority_scheduler.py
  import pytest
  from vllm import LLM, SamplingParams

  @pytest.mark.unit
  def test_priority_scheduler():
      """æµ‹è¯•ä¼˜å…ˆçº§è°ƒåº¦"""
      llm = LLM(model="meta-llama/Llama-3.1-8B")

      # æµ‹è¯•é«˜ä¼˜å…ˆçº§ä¼˜å…ˆæ‰§è¡Œ
      prompts = [
          {"prompt": "low", "priority": 1},
          {"prompt": "high", "priority": 100},
          {"prompt": "medium", "priority": 50},
      ]

      outputs = llm.generate(prompts)

      # éªŒè¯æ‰§è¡Œé¡ºåº
      assert outputs[0].prompt == "high"  # ä¼˜å…ˆçº§100
      assert outputs[1].prompt == "medium"  # ä¼˜å…ˆçº§50
      assert outputs[2].prompt == "low"  # ä¼˜å…ˆçº§1
  ```

  **5. ç›‘æ§å’Œæ—¥å¿—**

  ```python
  import logging

  class MySchedulerPatch(VLLMPatch[Scheduler]):
      def __init__(self, *args, **kwargs):
          super().__init__(*args, **kwargs)
          # è‡ªå®šä¹‰logger
          self.logger = logging.getLogger("vllm.custom.scheduler")

      def _schedule(self):
          self.logger.info("Custom scheduler active")
          self.logger.debug(f"Scheduling {len(self.waiting)} requests")

          # é‡‡é›†è‡ªå®šä¹‰æŒ‡æ ‡
          self.metrics.custom_schedule_calls += 1

          return super()._schedule()
  ```

  **6. æ’ä»¶å‘å¸ƒæµç¨‹**

  ```bash
  # 1. ç‰ˆæœ¬å·ç®¡ç†
  # setup.py
  setup(
      name="company-vllm-plugins",
      version="1.2.0",  # éµå¾ªè¯­ä¹‰åŒ–ç‰ˆæœ¬
      # ...
  )

  # 2. æ„å»ºå‘å¸ƒ
  python setup.py sdist bdist_wheel

  # 3. æµ‹è¯•
  twine check dist/*
  pip install dist/company_vllm_plugins-1.2.0-py3-none-any.whl

  # 4. å‘å¸ƒåˆ°å†…éƒ¨PyPI
  twine upload --repository-url https://pypi.company.com/ dist/*

  # 5. åœ¨vLLMæœåŠ¡ä¸­ä½¿ç”¨
  pip install --index-url https://pypi.company.com/ company-vllm-plugins==1.2.0
  ```

  **7. æ’ä»¶æ¸…å•ç®¡ç†**

  ```markdown
  # README.md

  ## å…¬å¸vLLMæ’ä»¶æ¸…å•

  ### å·²å®‰è£…æ’ä»¶

  | æ’ä»¶å | ç‰ˆæœ¬ | ç”¨é€” | ç»´æŠ¤è€… | çŠ¶æ€ |
  |--------|------|------|--------|------|
  | priority-scheduler | 1.2.0 | ä¼˜å…ˆçº§è°ƒåº¦ | infra-team | âœ… ç”Ÿäº§ |
  | custom-logger | 0.9.0 | ç»Ÿä¸€æ—¥å¿— | platform-team | âœ… ç”Ÿäº§ |
  | rbac-auth | 2.1.0 | RBACè®¤è¯ | security-team | ğŸ§ª æµ‹è¯• |

  ### ä½¿ç”¨æ–¹æ³•

  1. å®‰è£…æ‰€æœ‰æ’ä»¶ï¼š
      ```bash
      pip install -r requirements.txt
      ```

  2. æ¿€æ´»æ’ä»¶ï¼š
      ```bash
      export VLLM_CUSTOM_PATCHES="company_vllm_plugins"
      ```

  3. éªŒè¯æ’ä»¶åŠ è½½ï¼š
      ```bash
      python -c "import vllm; print(vllm.__version__)"
      ```

  ### ç‰ˆæœ¬å…¼å®¹æ€§

  | æ’ä»¶ | vLLM 0.5.x | vLLM 0.6.x | vLLM 0.7.x |
  |------|-----------|-----------|-----------|
  | priority-scheduler | âŒ | âœ… | âœ… |
  | custom-logger | âœ… | âœ… | âŒ |
  | rbac-auth | âŒ | âœ… | ğŸ§ª |
  ```

  **8. æ•…éšœæ’æŸ¥**

  ```bash
  # æ£€æŸ¥æ’ä»¶æ˜¯å¦åŠ è½½
  python -c "
  import os
  os.environ['VLLM_CUSTOM_PATCHES'] = 'company_vllm_plugins'
  from vllm import LLM
  print('Plugins loaded successfully')
  "

  # æŸ¥çœ‹æ’ä»¶æ—¥å¿—
  export VLLM_LOGGING_LEVEL=DEBUG
  vllm serve ... 2>&1 | grep -i plugin

  # å¸¸è§é—®é¢˜
  # 1. æ’ä»¶æœªç”Ÿæ•ˆï¼šæ£€æŸ¥VLLM_CUSTOM_PATCHESç¯å¢ƒå˜é‡
  # 2. ç‰ˆæœ¬ä¸å…¼å®¹ï¼šæ£€æŸ¥@min_vllm_versionè£…é¥°å™¨
  # 3. æ–¹æ³•åé”™è¯¯ï¼šæ£€æŸ¥ç›®æ ‡ç±»æ˜¯å¦æœ‰æ­¤æ–¹æ³•
  # 4. å¯¼å…¥å¤±è´¥ï¼šæ£€æŸ¥entry_pointsé…ç½®
  ```

  **9. æ€§èƒ½è€ƒè™‘**

  - **æ’ä»¶å¼€é”€**ï¼šæ’ä»¶ç³»ç»Ÿçš„å¼€é”€æå°ï¼ˆ<1%ï¼‰
  - **é¿å…è¿‡åº¦é‡å†™**ï¼šåªé‡å†™å¿…è¦çš„æ–¹æ³•
  - **æ€§èƒ½æµ‹è¯•**ï¼šä½¿ç”¨`--help`æŸ¥çœ‹æ˜¯å¦æœ‰æ€§èƒ½å½±å“

  ```python
  # æ€§èƒ½åŸºå‡†æµ‹è¯•
  import time

  # æ— æ’ä»¶
  start = time.time()
  llm = LLM(model="meta-llama/Llama-3.1-8B")
  # ... è¿è¡Œbenchmark
  no_plugin_time = time.time() - start

  # æœ‰æ’ä»¶
  os.environ['VLLM_CUSTOM_PATCHES'] = 'company_vllm_plugins'
  start = time.time()
  llm = LLM(model="meta-llama/Llama-3.1-8B")
  # ... è¿è¡Œbenchmark
  with_plugin_time = time.time() - start

  print(f"Overhead: {(with_plugin_time/no_plugin_time - 1)*100:.2f}%")
  ```

#### å¸¸è§è¯¯åŒºä¸“æ 
#### å®æˆ˜æ£€æŸ¥æ¸…å•
#### åŠ¨æ‰‹ç»ƒä¹ 
- ç»ƒä¹ 10.1ï¼šéƒ¨ç½²vLLMåˆ°Kubernetes
- ç»ƒä¹ 10.2ï¼šæ­å»ºå®Œæ•´çš„ç›‘æ§ç³»ç»Ÿ
- ç»ƒä¹ 10.3ï¼šå»ºç«‹ROIç›‘æ§ä»ªè¡¨ç›˜
- ç»ƒä¹ 10.4ï¼šä½¿ç”¨slimeéƒ¨ç½²ç®€å•RLä»»åŠ¡ â­
- ç»ƒä¹ 10.5ï¼šå¼€å‘å¹¶éƒ¨ç½²vLLMè‡ªå®šä¹‰æ’ä»¶ â­â­

---

### ç¬¬11ç«  é«˜çº§è¯é¢˜

> **ğŸ’° æˆæœ¬å½±å“**ï¼ˆåŸºäºè¡Œä¸šæ•°æ®ï¼‰
> - **MoEæ¨¡å‹**ï¼šç¨€ç–æ¿€æ´»å¯é™ä½30-50%æ¨ç†æˆæœ¬
> - **å¤šæ¨¡æ€**ï¼šå›¾åƒ+æ–‡æœ¬æ¨ç†ï¼Œæ–°çš„æˆæœ¬ä¼˜åŒ–ç»´åº¦
> - **è¾¹ç¼˜éƒ¨ç½²**ï¼šå°†æ¨ç†ç§»åˆ°è¾¹ç¼˜ï¼Œé™ä½ä¸­å¿ƒæˆæœ¬å’Œå»¶è¿Ÿ
> - **å¼‚æ„éƒ¨ç½²**ï¼šè®­ç»ƒç”¨H100ï¼Œæ¨ç†ç”¨H200ï¼Œå……åˆ†åˆ©ç”¨ç¡¬ä»¶ï¼ˆæœ±ç«‹è€•@NVIDIAï¼‰

#### 11.1 AgentåŸºç¡€è®¾æ–½ âš ï¸ å¼€æºç”Ÿæ€ç¼ºå¤±

> **ğŸ’¡ 2025å¹´æŠ€æœ¯è¶‹åŠ¿**ï¼ˆæ¥æºï¼š2025"é’ç¨"AIå˜‰å¹´å - å¼ æ˜æ˜Ÿ@æ¸…åã€æœ±ç«‹è€•@NVIDIAï¼‰
>
> **æ ¸å¿ƒæ´å¯Ÿ**ï¼š2025å¹´ä¸‹åŠå¹´Agentå¿«é€Ÿå…´èµ·ï¼ˆGoogle NotebookLMã€Gemini Nanoï¼‰ï¼Œä½†å¼€æºAgent SystemåŸºæœ¬æ˜¯è´Ÿåˆ†ã€‚è¿™æ˜¯å½“å‰æœ€å¤§çš„æœºä¼šä¹‹ä¸€ã€‚

- 11.1.1 ä¸ºä»€ä¹ˆAgent Infraå¾ˆé‡è¦
  - **2025å¹´çš„çˆ†å‘**ï¼š
    - Google: NotebookLMã€Gemini Flashã€Gemini Nano
    - å›½å†…: AutoJamã€å¤šå®ä¹¦è®°
    - å±•ç¤ºäº†agentçš„å®é™…ä»·å€¼
  - **æ ¸å¿ƒä»·å€¼**ï¼ˆå¼ åšæ¶µ@æµ™å¤§ï¼‰ï¼š
    - Geminiå®Œå…¨å¯åšç§‘ç ”åŠ©æ‰‹
    - å¯ä»¥å°‘é›‡ä¸€äº›inference
  - **ç‹¬ç‰¹æŒ‘æˆ˜**ï¼š
    - ä¸åƒä¼ ç»Ÿæ¨ç†åªæœ‰text input/output
    - éœ€è¦å¤æ‚çš„ç¯å¢ƒäº¤äº’

- 11.1.2 Agent Systemçš„ç¼ºå¤±ï¼ˆæœ±ç«‹è€•@NVIDIAï¼‰
  - **å½“å‰çŠ¶æ€**ï¼š
    - å¼€æºagent systemæ˜¯è´Ÿæ•°
    - åœ¨å…¬å¸å†…éƒ¨æ­å»ºJupyter agentéƒ½å¾ˆéš¾
    - éœ€è¦manage K8Sã€è‡ªåŠ¨èµ·virtual environment
  - **éœ€æ±‚**ï¼š
    - Scalable and easy to useçš„sandbox system
    - åƒinference engineä¸€æ ·ç»™ä¸ªURL
    - å‘HTTP requestå°±èƒ½å®Œæˆæ‰€æœ‰äº‹æƒ…
  - **ç°çŠ¶**ï¼š
    - åªèƒ½ç”¨dirtyæ–¹æ³•ï¼ˆmock pythonè¿›ç¨‹ï¼‰
    - æ— æ³•å¾ˆå¥½åœ°åšagent
    - å­¦æœ¯ç•Œå‡ ä¹æ²¡æœ‰ä½¿ç”¨ç»éªŒ

- 11.1.3 Agentç¯å¢ƒçš„å¤æ‚æ€§ï¼ˆå¼ æ˜æ˜Ÿ@æ¸…åï¼‰
  - **æ–‡ä»¶ç³»ç»Ÿ**ï¼š
    - Agentéœ€è¦æ“ä½œæ–‡ä»¶ç³»ç»Ÿ
    - å¯èƒ½æŒ‚è½½å¤±è´¥éœ€è¦å¤„ç†
  - **ç½‘ç»œ**ï¼š
    - HTTPè¯·æ±‚ã€APIè°ƒç”¨
    - è¶…æ—¶ã€é‡è¯•ã€é”™è¯¯å¤„ç†
  - **è™šæ‹Ÿæœº**ï¼š
    - å¯èƒ½éœ€è¦åµŒå¥—VM
    - å¤æ‚çš„workflowæ„é€ 
  - **CPUçš„é‡è¦æ€§**ï¼š
    - å¤§å®¶å¯¹CPUçš„å…³æ³¨ä¸å¤Ÿ
    - Agentç¯å¢ƒéœ€è¦å¤§é‡CPU
    - å¼€æºç”Ÿæ€CPUæ”¯æŒæ˜¯è´Ÿåˆ†

- 11.1.4 Agentç¯å¢ƒçš„ç±»å‹
  - **ç®€å•ç¯å¢ƒ**ï¼š
    - Dockerå®¹å™¨
    - åŸºæœ¬çš„æ–‡ä»¶ç³»ç»Ÿæ“ä½œ
  - **ä¸­ç­‰å¤æ‚**ï¼š
    - K8Sä¸Šçš„è™šæ‹Ÿç¯å¢ƒ
    - ç½‘ç»œè°ƒç”¨
  - **é«˜å¤æ‚**ï¼š
    - åµŒå¥—VM
    - å¤æ‚workflow
    - å¤šä¸ªæœåŠ¡ååŒ

- 11.1.5 Agentéƒ¨ç½²æ¶æ„
  - **å•æœºéƒ¨ç½²**ï¼š
    - é€‚åˆå¼€å‘å’Œå®éªŒ
  - **K8Séƒ¨ç½²**ï¼š
    - éœ€è¦Operatorç®¡ç†
    - è‡ªåŠ¨èµ·åœç¯å¢ƒ
  - **äº‘åŸç”Ÿéƒ¨ç½²**ï¼š
    - ä½¿ç”¨AWS Lambdaã€GCP Cloud Functions
    - Serverlessæ¶æ„

- 11.1.6 å®æˆ˜æ¡ˆä¾‹
  - **æ¡ˆä¾‹1**ï¼šæ­å»ºç®€å•çš„Jupyter Agent
  - **æ¡ˆä¾‹2**ï¼šä½¿ç”¨Dockeréƒ¨ç½²Agentç¯å¢ƒ
  - **æ¡ˆä¾‹3**ï¼šç”Ÿäº§çº§Agent Systemçš„æŒ‘æˆ˜

- 11.1.7 Context Engineeringæœ€ä½³å®è·µ âš¡ï¸ 2025æ–°å¢

  > **æ¥æº**ï¼š[Manus - Context Engineering for AI Agents](https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus)
  >
  > **æ ¸å¿ƒè§‚ç‚¹**ï¼šContext Engineeringæ˜¯Agentç³»ç»Ÿçš„"Stochastic Gradient Descent"â€”â€”é€šè¿‡å®éªŒå’Œè¿­ä»£æ‰¾åˆ°å±€éƒ¨æœ€ä¼˜è§£ã€‚Manuså›¢é˜Ÿé‡å»ºäº†4æ¬¡Agentæ¡†æ¶æ‰æ€»ç»“å‡ºè¿™äº›æ¨¡å¼ã€‚

  **11.1.7.1 å…­å¤§æ ¸å¿ƒåŸåˆ™**

  **åŸåˆ™1ï¼šDesign Around the KV-Cache** â­â­â­

  - **æ ¸å¿ƒæ´å¯Ÿ**ï¼š
    - KV-cache hit rateæ˜¯ç”Ÿäº§çº§agentæœ€é‡è¦çš„å•ä¸€æŒ‡æ ‡
    - ç›´æ¥å½±å“latencyï¼ˆTTFTï¼‰å’Œcost
    - Agentçš„è¾“å…¥è¾“å‡ºæ¯”ä¾‹100:1ï¼ˆvs chatbot 1:1ï¼‰

  - **ä¸‰å¤§å®è·µ**ï¼š
    1. **ç¨³å®šçš„Prompt Prefix**
       - é¿å…timestampç­‰åŠ¨æ€å†…å®¹
       - ä½¿ç”¨ç›¸å¯¹æ—¶é—´
       - å•tokenå·®å¼‚ç ´ååç»­æ‰€æœ‰cache

    2. **Append-only Context**
       - ä¸ä¿®æ”¹å†å²actions/observations
       - ç¡®å®šæ€§åºåˆ—åŒ–ï¼ˆJSON key orderï¼‰
       - é¿å…åŠ¨æ€å·¥å…·å®šä¹‰

    3. **Cache Breakpointsç­–ç•¥**
       - æ˜¾å¼æ ‡è®°å¯å¤ç”¨çš„æ–­ç‚¹
       - vLLM prefix caching + session IDè·¯ç”±
       - è€ƒè™‘cache expiration

  **åŸåˆ™2ï¼šMask, Don't Remove** â­â­â­

  - **é—®é¢˜**ï¼šå·¥å…·æ•°é‡çˆ†ç‚¸
    - MCPåè®®è®©ç”¨æˆ·plugæ•°ç™¾ä¸ªå·¥å…·
    - å·¥å…·è¿‡å¤šå¯¼è‡´æ¨¡å‹é€‰æ‹©é”™è¯¯action
    - åŠ¨æ€æ·»åŠ /åˆ é™¤å·¥å…·ç ´åKV-cache

  - **Solution**ï¼šContext-aware State Machine
    - ä¿æŒå·¥å…·å®šä¹‰ç¨³å®šï¼ˆä¿æŠ¤KV-cacheï¼‰
    - ä½¿ç”¨response prefillæ§åˆ¶action space
    - é€šè¿‡logit maskingè€Œéä¿®æ”¹context

  - **ä¸‰ç§Function Callingæ¨¡å¼**ï¼š
    ```python
    # Mode 1: Auto - æ¨¡å‹è‡ªä¸»é€‰æ‹©
    prefix = "<|im_start|>assistant\n"

    # Mode 2: Required - å¿…é¡»è°ƒç”¨å·¥å…·
    prefix = "<|im_start|>assistant\n<|tool|>"

    # Mode 3: Specified - å¿…é¡»è°ƒç”¨ç‰¹å®šå·¥å…·ç»„
    prefix = "<|im_start|>assistant\n<|tool|>{\"name\": \"browser_"
    # åªèƒ½é€‰æ‹©browser_å¼€å¤´çš„å·¥å…·
    ```

  - **å®æˆ˜æŠ€å·§**ï¼š
    - å·¥å…·å‘½åä½¿ç”¨å‰ç¼€åˆ†ç»„ï¼ˆbrowser_*, shell_*ï¼‰
    - æ ¹æ®agent stateåŠ¨æ€mask token logits
    - ä¿æŒcontextç¨³å®šçš„åŒæ—¶ç²¾ç¡®æ§åˆ¶è¡Œä¸º

  **åŸåˆ™3ï¼šFile System as Ultimate Context** â­â­

  - **é•¿contextçš„ä¸‰å¤§ç—›ç‚¹**ï¼š
    1. **Observationså·¨å¤§**ï¼šç½‘é¡µã€PDFå¯èƒ½æ•°ä¸‡tokens
    2. **æ€§èƒ½ä¸‹é™**ï¼šè¶…è¿‡ä¸€å®šé•¿åº¦åæ¨¡å‹æ€§èƒ½degrade
    3. **æˆæœ¬é«˜æ˜‚**ï¼šå³ä½¿æœ‰cacheï¼Œé•¿contextä»è´µ

  - **Solution**ï¼šæ–‡ä»¶ç³»ç»Ÿä½œä¸ºå¤–éƒ¨memory
    - **æ— é™å®¹é‡**ï¼šä¸å—context windowé™åˆ¶
    - **æŒä¹…åŒ–**ï¼šå¤©ç„¶persistent
    - **Agentå¯æ§**ï¼šæ¨¡å‹å­¦ä¼šread/write files

  - **å¯æ¢å¤å‹ç¼©ç­–ç•¥**ï¼š
    ```python
    # ç½‘é¡µå†…å®¹ â†’ ä¿å­˜åˆ°æ–‡ä»¶
    web_content = fetch_page(url)
    file_path = agent.filesystem.write(web_content)

    # Contextåªä¿ç•™å¼•ç”¨
    context.append({
        "type": "web_page",
        "url": url,
        "file_path": file_path,  # éœ€è¦æ—¶å¯è¯»å–
        "summary": summarize(web_content)  # 100 tokens
    })
    ```

  - **å‹ç¼©åŸåˆ™**ï¼š
    - ç½‘é¡µï¼šä¿ç•™URL
    - PDFï¼šä¿ç•™æ–‡ä»¶è·¯å¾„
    - æ•°æ®åº“ï¼šä¿ç•™æŸ¥è¯¢è¯­å¥
    - å…³é”®ï¼šå¯æ¢å¤æ€§ï¼ˆinformation not lost, just externalizedï¼‰

  **åŸåˆ™4ï¼šManipulate Attention Through Recitation** â­â­

  - **é—®é¢˜**ï¼š
    - å…¸å‹Agentä»»åŠ¡ï¼š~50æ­¥tool calls
    - Contextå¿«é€Ÿå¢é•¿åˆ°æ•°ä¸‡tokens
    - æ¨¡å‹å®¹æ˜“"lost-in-the-middle"æˆ–åç§»ç›®æ ‡

  - **Solution**ï¼štodo.mdæœºåˆ¶
    ```python
    # Agentè‡ªåŠ¨åˆ›å»ºå’Œæ›´æ–°todo.md
    todo_content = """
    # Task: Research and book flight to Tokyo

    - [ ] Search flights to Tokyo (Mar 1-7, 2025)
    - [ ] Compare prices across airlines
    - [ ] Check hotel availability
    - [x] Get user preferences (budget, dates)
    - [ ] Book best option
    - [ ] Send confirmation

    Current step: Comparing prices...
    """
    ```

  - **åŸç†**ï¼š
    - å°†å…¨å±€planå¤è¿°åˆ°contextæœ«å°¾
    - æ¨å…¥æ¨¡å‹çš„recent attention span
    - é¿å…"lost-in-the-middle"
    - ç”¨è‡ªç„¶è¯­è¨€biasä»»åŠ¡ç›®æ ‡

  **åŸåˆ™5ï¼šKeep the Wrong Stuff In** â­â­

  - **å¸¸è§é”™è¯¯**ï¼š
    - Agentå‡ºé”™ â†’ æ¸…ç†trace â†’ é‡è¯•
    - ä½¿ç”¨temperature"é‡å¯"
    - éšè—é”™è¯¯è®©context"å¹²å‡€"

  - **ä¸ºä»€ä¹ˆé”™è¯¯**ï¼š
    - ç§»é™¤å¤±è´¥ = ç§»é™¤è¯æ®
    - æ¨¡å‹æ— æ³•ä»é”™è¯¯ä¸­å­¦ä¹ 
    - æ— æ³•æ›´æ–°å†…éƒ¨beliefs
    - å®¹æ˜“é‡å¤åŒæ ·é”™è¯¯

  - **æ­£ç¡®åšæ³•**ï¼š
    ```python
    # ä¿ç•™å®Œæ•´traceï¼ˆåŒ…æ‹¬é”™è¯¯ï¼‰
    context = [
        {"role": "user", "content": "Extract data from PDF"},
        {"role": "assistant", "tool_call": {
            "name": "pdf_parse",
            "args": {"file": "wrong.pdf"}  # é”™è¯¯ï¼
        }},
        {"role": "tool", "content": "Error: File not found"},
        {"role": "assistant", "tool_call": {
            "name": "pdf_parse",
            "args": {"file": "correct.pdf"}  # ä¿®æ­£
        }},
        # æ¨¡å‹çœ‹åˆ°é”™è¯¯ â†’ å­¦ä¹ é¿å‘
    ]
    ```

  - **å…³é”®æ´å¯Ÿ**ï¼š
    - **é”™è¯¯æ¢å¤æ˜¯true agentic behaviorçš„æ ‡å¿—**
    - å­¦æœ¯ç•Œå¿½è§†çš„æŒ‡æ ‡
    - äººç±»ä»é”™è¯¯ä¸­å­¦ä¹ ï¼ŒAgentä¹Ÿåº”å¦‚æ­¤

  **åŸåˆ™6ï¼šDon't Get Few-Shotted** â­

  - **é—®é¢˜**ï¼š
    - LLMæ˜¯ä¼˜ç§€çš„mimic
    - Few-shotåœ¨Agentä¸­å¯èƒ½é€‚å¾—å…¶å
    - Contextå……æ»¡ç›¸ä¼¼action-observation pairs
    - æ¨¡å‹é™·å…¥æ¨¡å¼ï¼Œå¤±å»çµæ´»æ€§

  - **æ¡ˆä¾‹**ï¼š
    - æ‰¹é‡å¤„ç†20ä»½ç®€å†
    - Agenté™·å…¥èŠ‚å¥ï¼šé‡å¤ç›¸ä¼¼åŠ¨ä½œ
    - ç»“æœï¼šdriftã€overgeneralizationã€hallucination

  - **Solution**ï¼šå¢åŠ å¤šæ ·æ€§
    ```python
    # å¼•å…¥å¾®å°å˜åŒ–
    templates = [
        "Action: {tool}",
        "Execute: {tool}",
        "Calling {tool}...",
        "{tool}()",
    ]
    # éšæœºä½¿ç”¨ä¸åŒæ¨¡æ¿
    ```

  - **å…³é”®**ï¼š
    - é¿å…uniform context
    - å¢åŠ ç»“æ„åŒ–å¤šæ ·æ€§
    - è®©æ¨¡å‹ä¿æŒæ³¨æ„åŠ›

  **11.1.7.2 å®æˆ˜æ¡ˆä¾‹ï¼šManusçš„Contextè®¾è®¡**

  - **å…¸å‹ä»»åŠ¡ç‰¹å¾**ï¼š
    - å¹³å‡50æ­¥tool calls
    - Contextå¿«é€Ÿå¢é•¿åˆ°20K+ tokens
    - å®¹æ˜“"lost-in-the-middle"æˆ–åç§»ç›®æ ‡

  - **Manusçš„å®Œæ•´æ–¹æ¡ˆ**ï¼š

    1. **è‡ªåŠ¨åˆ›å»ºtodo.md**
       - ä»»åŠ¡å¼€å§‹æ—¶ç”Ÿæˆ
       - æ¯æ­¥updateè¿›åº¦
       - å‹¾é€‰å·²å®Œæˆé¡¹
       - ä¿æŒç›®æ ‡å¯¹é½

    2. **File System Integration**
       - ç½‘é¡µå†…å®¹ä¿å­˜åˆ°`/tmp/pages/`
       - PDFä¿å­˜åˆ°`/tmp/docs/`
       - Contextåªä¿ç•™pathå’Œsummary
       - éœ€è¦æ—¶å†read

    3. **Error Traceä¿ç•™**
       - ä¸æ¸…ç†é”™è¯¯
       - ä¿ç•™stack trace
       - è®©æ¨¡å‹å­¦ä¹ é¿å‘
       - æå‡error recoveryèƒ½åŠ›

    4. **Context Diversity**
       - é¿å…é‡å¤serializationæ¨¡æ¿
       - éšæœºåŒ–phrasing
       - å¢åŠ å¾®å°å™ªå£°
       - ä¿æŒæ¨¡å‹flexibility

  **11.1.7.3 å¼€æºç”Ÿæ€çš„æœºä¼š**

  - **å½“å‰ç¼ºå¤±**ï¼š
    - âŒ æ²¡æœ‰æ ‡å‡†åŒ–çš„context management
    - âŒ æ¯ä¸ªagentéƒ½è¦re-inventè¿™äº›æ¨¡å¼
    - âŒ ç¼ºä¹best practicesæ–‡æ¡£
    - âŒ æ²¡æœ‰agent-orientedçš„profilingå·¥å…·

  - **å¯ä»¥åšçš„äº‹æƒ…**ï¼š

    1. **å¼€æºContext Management Library**
       ```python
       class AgentContext:
           def __init__(self):
               self.kv_cache_aware = True
               self.append_only = True
               self.deterministic_serialization = True

           def add_observation(self, obs, compressible=False):
               if compressible:
                   return self.externalize(obs)  # æ–‡ä»¶ç³»ç»Ÿ
               return self.append(obs)  # Context

           def mask_tools(self, allowed_prefixes):
               return self.logit_mask(allowed_prefixes)
       ```

    2. **æ ‡å‡†åŒ–Metrics**
       - KV-cache hit rate
       - Context length distribution
       - Tool call success rate
       - **Error recovery rate**ï¼ˆå­¦æœ¯ç•Œå¿½è§†ï¼ï¼‰
       - Session stickiness

    3. **Agent-oriented Profiling**
       - Context growth rate
       - Token cost breakdownï¼ˆby stepï¼‰
       - Tool call latency
       - File system usage
       - Cache effectiveness

    4. **Context Optimization Framework**
       - Auto-detect cache-breakers
       - Suggest compression strategies
       - Monitor hit rate in real-time
       - A/B test context designs

  **11.1.7.4 æ€»ç»“ï¼šContext Engineeringæ˜¯æœªæ¥**

  - **ä¸ºä»€ä¹ˆé‡è¦**ï¼š
    - æ¨¡å‹è¶Šæ¥è¶Šå¼ºã€å¿«ã€ä¾¿å®œ
    - ä½†contextè®¾è®¡ä»æ˜¯ç“¶é¢ˆ
    - å¥½çš„context = å¥½çš„agent behavior

  - **æ ¸å¿ƒæ•™è®­**ï¼š
    - å›´ç»•KV-cacheè®¾è®¡ï¼ˆæœ€é‡è¦ï¼‰
    - ä¿æŒcontextç¨³å®šå’Œå¯é¢„æµ‹
    - å¤–éƒ¨åŒ–å¤§å‹observations
    - ä¿ç•™é”™è¯¯traceï¼ˆè®©æ¨¡å‹å­¦ä¹ ï¼‰
    - é¿å…æ¨¡å¼åƒµåŒ–ï¼ˆå¢åŠ å¤šæ ·æ€§ï¼‰

  - **è¡ŒåŠ¨æŒ‡å—**ï¼š
    - ç«‹å³ï¼šæµ‹é‡KV-cache hit rate
    - æœ¬å‘¨ï¼šç§»é™¤cache breakers
    - æœ¬æœˆï¼šå®æ–½file system fallback
    - æŒç»­ï¼šA/Bæµ‹è¯•contextç­–ç•¥

#### 11.2 å¼‚æ„ç¡¬ä»¶éƒ¨ç½² â­

> **ğŸ’¡ 2025å¹´æŠ€æœ¯è¶‹åŠ¿**ï¼ˆæ¥æºï¼š2025"é’ç¨"AIå˜‰å¹´å - æœ±ç«‹è€•@NVIDIAï¼‰
>
> **æ ¸å¿ƒæ´å¯Ÿ**ï¼šTrainingå’ŒRolloutçš„ç®—åŠ›éœ€æ±‚å·®å¼‚2-3ä¸ªæ•°é‡çº§ï¼ˆTraining: 10^5 flops/byte, Rollout: ~80 flops/byteï¼‰ã€‚RLå¤©ç”Ÿé€‚åˆç”¨ä¸åŒç¡¬ä»¶ã€‚

- 11.2.1 è®­ç»ƒvsæ¨ç†çš„ç®—åŠ›å·®å¼‚
  - **è®­ç»ƒ**ï¼ˆæœ±ç«‹è€•@NVIDIAï¼‰ï¼š
    - Flops per byte â‰ˆ 10^5
    - è®¡ç®—å¯†é›†
  - **æ¨ç†**ï¼š
    - Flops per byte â‰ˆ 80
    - å¸¦å®½å¯†é›†
  - **å·®è·**ï¼š2-3ä¸ªæ•°é‡çº§
  - **å¯ç¤º**ï¼šåº”è¯¥ç”¨ä¸åŒçš„ç¡¬ä»¶

- 11.2.2 å¼‚æ„éƒ¨ç½²çš„æœºä¼šï¼ˆæœ±ç«‹è€•@NVIDIAï¼‰
  - **ä¹‹å‰çš„é—®é¢˜**ï¼š
    - å¤§å®¶éƒ½åœ¨SPMDæ—¶ä¸ä¼šè€ƒè™‘
    - ç‰©ç†ä¸Šåœ¨åŒä¸€é›†ç¾¤ä½†æƒé™ä¸åŒ
  - **ç°åœ¨çš„æœºä¼š**ï¼š
    - H100è®­ç»ƒ + H200æ¨ç†
    - å›½äº§å¡æ¨ç† + NVè®­ç»ƒ
    - å¯ä»¥æŠŠè¿™äº›å¡æ›´å¥½åˆ©ç”¨èµ·æ¥
  - **ä¸ºä»€ä¹ˆç°åœ¨å¯ä»¥**ï¼š
    - RLæŠŠtrainingå’Œrolloutåˆ†å¼€äº†
    - æ¨ç†ä¹‹é—´æ²¡æœ‰å¼‚æ„é€šä¿¡
    - å¯ä»¥ç‹¬ç«‹æ“ä½œ

- 11.2.3 ä¸åŒGPUçš„åº”ç”¨åœºæ™¯
  - **H100**ï¼š
    - è®­ç»ƒä¼˜åŒ–
    - é«˜è®¡ç®—èƒ½åŠ›
  - **H200/L40s**ï¼š
    - æ¨ç†ä¼˜åŒ–
    - é«˜å¸¦å®½
  - **å›½äº§å¡**ï¼ˆæœ±ç«‹è€•@NVIDIAï¼‰ï¼š
    - æ¨ç†åœºæ™¯å¯é€‰æ‹©ç¡¬ä»¶å¤š
    - è®­ç»ƒä»æ˜¯NVçš„privilege

- 11.2.4 å®¹ç¾å’Œæ··éƒ¨çš„æœºä¼šï¼ˆæœ±å­æ—@è´¨æœ´ï¼‰
  - **ä¹‹å‰çš„é—®é¢˜**ï¼š
    - NCCL/MPIä¸å¤ªèƒ½å®¹ç¾
    - ä¸€ä¸ªèŠ‚ç‚¹æŒ‚äº†å°±æ•´ä½“å¤¯æ­»
    - å¤§å®¶å…¨æ€æ‰é‡å¯
  - **ç°åœ¨çš„æœºä¼š**ï¼š
    - æ¨ç†engineå¯ä»¥ç‹¬ç«‹æ“ä½œ
    - æ¨ç†ä¹‹é—´æ²¡æœ‰å¼‚æ„é€šä¿¡
    - å¯ä»¥åšå®¹ç¾ã€æ··éƒ¨ã€æ‰©ç¼©å®¹
  - **åº”ç”¨åœºæ™¯**ï¼š
    - æ½®æ±é˜Ÿåˆ—ï¼šç™½å¤©æ¨ç†ï¼Œå¤œé—´RL
    - SMPå’ŒRLçš„å¤§é›†ç¾¤æ··ç”¨
    - æå‡æ•´ä½“ç¡¬ä»¶åˆ©ç”¨ç‡

- 11.2.5 å¼‚æ„éƒ¨ç½²çš„æŒ‘æˆ˜
  - **Checkpointç®¡ç†**ï¼š
    - ä¸åŒç¡¬ä»¶é—´checkpointè½¬æ¢
    - Tçº§åˆ«æ¨¡å‹checkpointå·¨å¤§ï¼ˆå¼ åšæ¶µ@æµ™å¤§ï¼‰
  - **é€šä¿¡**ï¼š
    - è·¨é›†ç¾¤çš„é€šä¿¡
    - ç½‘ç»œå¸¦å®½ç“¶é¢ˆ
  - **ç›‘æ§**ï¼š
    - ç»Ÿä¸€ç›‘æ§ä¸åŒç¡¬ä»¶
    - èµ„æºè°ƒåº¦å¤æ‚

- 11.2.6 å®æˆ˜æ¡ˆä¾‹
  - **æ¡ˆä¾‹1**ï¼šH100è®­ç»ƒ + H200æ¨ç†
  - **æ¡ˆä¾‹2**ï¼šè·¨é›†ç¾¤è®­ç»ƒå’Œæ¨ç†
  - **æ¡ˆä¾‹3**ï¼šæ½®æ±é˜Ÿåˆ—çš„å®è·µ

#### 11.3 MoEæ¨¡å‹æ¨ç†ä¼˜åŒ–
- 11.3.1 MoEæ¶æ„ç®€ä»‹
- 11.3.2 MoEæ¨ç†çš„ç‰¹æ®ŠæŒ‘æˆ˜
- 11.3.3 ä¸“å®¶è·¯ç”±ä¼˜åŒ–
- 11.3.4 Checkpointç®¡ç†ï¼ˆå¼ åšæ¶µ@æµ™å¤§ï¼‰
  - Tçº§åˆ«æ¨¡å‹checkpointå·¨å¤§
  - Partial checkpointä¿å­˜å’ŒåŠ è½½
  - æ•…éšœæ¢å¤ï¼šå±è”½æŒ‚æ‰çš„ä¸“å®¶
- 11.3.5 å®æˆ˜ï¼šMixtraléƒ¨ç½²

#### 11.4 å¤šæ¨¡æ€æ¨¡å‹æ¨ç†
- 11.4.1 å¤šæ¨¡æ€æ¨¡å‹æ¦‚è¿° (LLaVAç­‰)
- 11.4.2 è§†è§‰ç¼–ç å™¨ä¼˜åŒ–
- 11.4.3 å¤šæ¨¡æ€æ¨ç†æµæ°´çº¿
- 11.4.4 Video Generationçš„æŒ‘æˆ˜ï¼ˆå¼ åšæ¶µ@æµ™å¤§ï¼‰
  - **Diffusion RLçš„å°´å°¬**ï¼š
    - åšç®—æ³•çš„ï¼šinfraå¤ªæ…¢ï¼Œè®­ç»ƒæ—¶é—´å¤ªé•¿
    - åšç³»ç»Ÿçš„ï¼šç®—æ³•è¿˜æ²¡æˆç†Ÿï¼Œç­‰ç®—æ³•æˆç†Ÿå†è¯´
    - ä¸¤è¾¹å¤§çœ¼çªå°çœ¼
  - **æŠ€æœ¯ç–‘é—®**ï¼š
    - Diffusionçš„è®­ç»ƒæ¨ç†åˆ†ç¦»æ˜¯å¦æˆç«‹ï¼Ÿ
    - è®­ç»ƒ: computation bound
    - æ¨ç†: I/O bound
  - **å¸‚åœºç©ºç™½**ï¼š
    - Video generationæ²¡æœ‰å¥½çš„å¼€æºè®­ç»ƒæ¡†æ¶
    - å¸‚é¢ä¸Šæ²¡æœ‰å¾ˆå¥½çš„Diffusion RLç³»ç»Ÿ

#### 11.5 Torch Compileä¼˜åŒ–
- 11.5.1 torch.compileåŸç†
- 11.5.2 åœ¨æ¨ç†ä¸­çš„åº”ç”¨
- 11.5.3 ä¸vLLMç»“åˆ
- 11.5.4 å®æˆ˜æ•ˆæœ

#### 11.6 Flash Attention
- 11.6.1 Flash AttentionåŸç†
- 11.6.2 Flash Attention 2
- 11.6.3 Sparse Attention vs Linear Attentionï¼ˆå¼ åšæ¶µ@æµ™å¤§ï¼‰
  - **è¶‹åŠ¿**ï¼š
    - å¤§å‚é€æ¸æ”¾å¼ƒlinear attention
    - æ”¶æ•›åˆ°sparse attention
  - **åŸå› **ï¼š
    - Agentåœºæ™¯æ˜¯multi-turnçš„long context
    - ç†æƒ³æƒ…å†µï¼šå…¨å­˜ï¼Œsparse retrieval
    - Make sense
  - **æŒ‘æˆ˜**ï¼š
    - åœ¨long context reasoningåœºæ™¯ä¸‹
    - æ€ä¹ˆæŠŠsparse attentionåšä¸æ‰ç‚¹ï¼Ÿ
    - ä¾‹å¦‚ï¼šNeedle In A Haystackï¼ˆå¤§æµ·æå¤šé’ˆï¼‰
      - Claude 3ç²¾åº¦åªæœ‰20-30%
- 11.6.4 æ€§èƒ½æå‡
- 11.6.5 åœ¨vLLMä¸­çš„ä½¿ç”¨

#### 11.7 è‡ªå®šä¹‰ç®—å­å¼€å‘
- 11.7.1 ä½•æ—¶éœ€è¦è‡ªå®šä¹‰ç®—å­
- 11.7.2 CUDAç¼–ç¨‹åŸºç¡€
- 11.7.3 Tritonè¯­è¨€ç®€ä»‹
- 11.7.4 å¼€å‘æµç¨‹
- 11.7.5 å‰ç«¯æ€§èƒ½ä¼˜åŒ–ï¼ˆåˆ˜æµ·è¶…@vLLMï¼‰
  - Pythonå†™web serviceæ€§èƒ½å·®
  - éœ€è¦åŠ rest
  - Inferenceçš„CPUä¼˜åŒ–
  - æ˜¯å¦ç”¨C++ï¼ˆPyTorchä¹Ÿåœ¨è€ƒè™‘ï¼‰

#### 11.8 æŠ€æœ¯å‘å±•ä¸å±•æœ›

> **ğŸ’¡ 2025å¹´æŠ€æœ¯è¶‹åŠ¿**ï¼šMoEæ¶æ„çš„å¤§è§„æ¨¡éƒ¨ç½²æˆä¸ºçƒ­ç‚¹ï¼Œä»å•ä¸€æ¨¡å‹åˆ°åˆ†å¸ƒå¼ä¸“å®¶ç³»ç»Ÿï¼Œæ–°çš„æ¶æ„æ¨¡å¼æ­£åœ¨æ¶Œç°ã€‚

##### 11.8.1 å¤§è§„æ¨¡MoEæœåŠ¡ (Large-scale Expert Parallelism) â­â­â­

> **æ¥æº**ï¼š[vLLM Blog - Large-scale Serving](https://blog.vllm.ai/2025/12/17/large-scale-serving.html)
>
> **æ ¸å¿ƒä»·å€¼**ï¼šè§£å†³ä¸‡äº¿å‚æ•°MoEæ¨¡å‹çš„éƒ¨ç½²éš¾é¢˜

- **ä»€ä¹ˆæ˜¯Large EP**
  - ä¼ ç»Ÿçš„Tensor Parallelismåœ¨MoEä¸Šçš„å±€é™
  - Expert Parallelismï¼šå°†ä¸åŒä¸“å®¶åˆ†é…åˆ°ä¸åŒGPU
  - è·¨èŠ‚ç‚¹çš„ä¸“å®¶è·¯ç”±å’Œè´Ÿè½½å‡è¡¡
  - All-to-Allé€šä¿¡ä¼˜åŒ–

- **å…³é”®æŠ€æœ¯æŒ‘æˆ˜**
  - **ä¸“å®¶è´Ÿè½½å‡è¡¡**ï¼š
    - ä¸åŒä¸“å®¶çš„è®¿é—®é¢‘ç‡å·®å¼‚
    - åŠ¨æ€è·¯ç”±ç­–ç•¥
    - é¿å…çƒ­ç‚¹ä¸“å®¶è¿‡è½½
  - **é€šä¿¡ä¼˜åŒ–**ï¼š
    - å‡å°‘è·¨èŠ‚ç‚¹All-to-Allé€šä¿¡
    - é€šä¿¡è®¡ç®—é‡å 
    - RDMAåŠ é€Ÿ
  - **å®¹é”™å’Œå¼¹æ€§**ï¼š
    - ä¸“å®¶å¤±è´¥çš„å¤„ç†
    - åŠ¨æ€æ‰©ç¼©å®¹ä¸“å®¶æ•°é‡

- **vLLMçš„å®ç°**
  - åˆ†å¸ƒå¼è°ƒåº¦å™¨è®¾è®¡
  - ä¸“å®¶è·¯ç”±ç®—æ³•
  - æ€§èƒ½åŸºå‡†æµ‹è¯•
  - ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

##### 11.8.2 EPDï¼šExpert-Parallel Data Parallelism â­â­â­

> **æ¥æº**ï¼š[vLLM Blog - EPD](https://blog.vllm.ai/2025/12/15/vllm-epd.html)
>
> **æ ¸å¿ƒä»·å€¼**ï¼šç»“åˆä¸“å®¶å¹¶è¡Œå’Œæ•°æ®å¹¶è¡Œï¼Œæå‡MoEæ¨ç†æ•ˆç‡

- **EPDçš„æ ¸å¿ƒæ€æƒ³**
  - **ä¼ ç»ŸMoEéƒ¨ç½²çš„é—®é¢˜**ï¼š
    - å•çº¯Expert Parallelismï¼šGPUåˆ©ç”¨ç‡ä¸å‡
    - å•çº¯Data Parallelismï¼šæ— æ³•å¤„ç†è¶…å¤§MoE
  - **EPDçš„åˆ›æ–°**ï¼š
    - æ¯ä¸ªGPUï¼šå¤šä¸ªä¸“å®¶çš„å‰¯æœ¬ + Dataå¹¶è¡Œ
    - æ›´å¥½çš„è´Ÿè½½å‡è¡¡
    - æå‡æ•´ä½“GPUåˆ©ç”¨ç‡

- **EPDæ¶æ„è®¾è®¡**
  - ä¸“å®¶åˆ†ç»„ç­–ç•¥
  - è¯·æ±‚è°ƒåº¦ç®—æ³•
  - KV Cacheå…±äº«
  - è·¨GPUé€šä¿¡ä¼˜åŒ–

- **æ€§èƒ½æå‡**
  - ååé‡æå‡ï¼š2-3x
  - å»¶è¿Ÿé™ä½ï¼šP95æ”¹å–„40%
  - GPUåˆ©ç”¨ç‡ï¼šä»60%æå‡åˆ°85%+

- **å®æˆ˜åº”ç”¨**
  - DeepSeek-V3çš„éƒ¨ç½²
  - Mixtral 8x22Bçš„ä¼˜åŒ–
  - æˆæœ¬èŠ‚çœæ¡ˆä¾‹

##### 11.8.3 Elastic Expert Parallelism â­â­

> **æ¥æº**ï¼š[vLLM Issue #20323](https://github.com/vllm-project/vllm/issues/20323)
>
> **æ ¸å¿ƒä»·å€¼**ï¼šåŠ¨æ€è°ƒæ•´ä¸“å®¶å¹¶è¡Œåº¦ï¼Œé€‚åº”ä¸åŒè´Ÿè½½

- **ä»€ä¹ˆæ˜¯Elastic EP**
  - é™æ€EPçš„é—®é¢˜ï¼šæ— æ³•é€‚åº”æµé‡æ³¢åŠ¨
  - Elastic EPï¼šæ ¹æ®è´Ÿè½½åŠ¨æ€è°ƒæ•´ä¸“å®¶å‰¯æœ¬æ•°
  - å¼¹æ€§æ‰©ç¼©å®¹ä¸“å®¶

- **æŠ€æœ¯æŒ‘æˆ˜**
  - ä¸“å®¶å‰¯æœ¬çš„åŠ¨æ€åˆ›å»ºå’Œé”€æ¯
  - è·¯ç”±è¡¨çš„å®æ—¶æ›´æ–°
  - æ— ç¼è¿ç§»è¯·æ±‚
  - ä¸€è‡´æ€§ä¿è¯

- **åº”ç”¨åœºæ™¯**
  - æµé‡æ³¢åŠ¨å¤§çš„æœåŠ¡
  - å¤šç§Ÿæˆ·ç¯å¢ƒ
  - æˆæœ¬æ•æ„Ÿçš„éƒ¨ç½²

##### 11.8.4 åˆ†ç¦»å¼æ¶æ„ï¼šMoonCakeèŒƒå¼ â­â­â­

> **æ¥æº**ï¼š[MoonCake GitHub](https://github.com/kvcache-aif/MoonCake)
>
> **æ ¸å¿ƒä»·å€¼**ï¼šå½»åº•è§£è€¦Prefillå’ŒDecodeï¼Œå®ç°ä¸“ç”¨çš„æ¨ç†é›†ç¾¤

- **MoonCakeçš„æ ¸å¿ƒè®¾è®¡**
  - ** disaggregated architecture**ï¼š
    - Prefillé›†ç¾¤ï¼šè®¡ç®—ä¼˜åŒ–å‹GPUï¼ˆH100ï¼‰
    - Decodeé›†ç¾¤ï¼šå¸¦å®½ä¼˜åŒ–å‹GPUï¼ˆH200ã€L40sï¼‰
    - KV Cacheé›†ç¾¤ï¼šé«˜å†…å­˜å¸¦å®½
  - **ä¸ºä»€ä¹ˆåˆ†ç¦»**ï¼š
    - Prefillå’ŒDecodeçš„è®¡ç®—æ¨¡å¼å®Œå…¨ä¸åŒ
    - ç»Ÿä¸€éƒ¨ç½²å¯¼è‡´èµ„æºæµªè´¹
    - åˆ†ç¦»åå¯åˆ†åˆ«ä¼˜åŒ–

- **å…³é”®æŠ€æœ¯**
  - **KV Cacheä¼ è¾“åè®®**ï¼š
    - é«˜æ•ˆçš„åºåˆ—åŒ–å’Œååºåˆ—åŒ–
    - å¢é‡ä¼ è¾“
    - å‹ç¼©ç®—æ³•
  - **è¯·æ±‚è°ƒåº¦**ï¼š
    - Prefillé˜Ÿåˆ—ç®¡ç†
    - Decodeé˜Ÿåˆ—ç®¡ç†
    - ä¸¤è€…ä¹‹é—´çš„é€Ÿç‡åŒ¹é…
  - **å®¹é”™æœºåˆ¶**ï¼š
    - KV Cacheçš„æŒä¹…åŒ–
    - æ•…éšœæ¢å¤
    - é‡æ–°è®¡ç®—ç­–ç•¥

- **æ€§èƒ½ä¼˜åŠ¿**
  - **æˆæœ¬é™ä½**ï¼š40-60%
  - **ååæå‡**ï¼š2-3x
  - **èµ„æºåˆ©ç”¨ç‡**ï¼šä»50%æå‡åˆ°80%+
  - **å¼¹æ€§æ‰©å±•**ï¼šPrefillå’ŒDecodeç‹¬ç«‹æ‰©ç¼©å®¹

- **ç”Ÿäº§å®è·µ**
  - æ¸…åå¤§å­¦MoonCakeç³»ç»Ÿï¼ˆå¼ æ˜æ˜Ÿ@æ¸…åï¼‰
  - Kitchenæ¨ç†å¹³å°
  - ä¸vLLMçš„é›†æˆ

- **å¯¹æ¯”å…¶ä»–æ–¹æ¡ˆ**
  - vLLM Integrated Serving
  - TGIçš„åˆ†ç¦»å¼æ¶æ„
  - å„è‡ªçš„é€‚ç”¨åœºæ™¯

##### 11.8.5 æŠ€æœ¯æ ˆæ·±åŒ–ï¼šä»æ¡†æ¶åˆ°ç½‘ç»œ â­â­

> **æ¥æº**ï¼šåˆ˜æµ·è¶…@vLLM (2025"é’ç¨"AIå˜‰å¹´å)
>
> **æ ¸å¿ƒæ´å¯Ÿ**ï¼š2025å¹´çš„ä¼˜åŒ–å·²ç»è¶…å‡ºäº†æ¨ç†æ¡†æ¶æœ¬èº«

- **2024 vs 2025å¯¹æ¯”**
  - **2024å¹´**ï¼šæ¡†æ¶å±‚é¢ä¼˜åŒ–ï¼ˆvLLMã€TGIï¼‰
  - **2025å¹´**ï¼šéœ€è¦æ·±å…¥åˆ°æ›´ä½å±‚æ¬¡
    - RDMAä¼˜åŒ–
    - Networkingå±‚ä¼˜åŒ–
    - Kernelå±‚ä¼˜åŒ–

- **ä¸ºä»€ä¹ˆéœ€è¦æ›´æ·±å±‚**
  - æ¡†æ¶å±‚çš„ä¼˜åŒ–å·²ç»æ¥è¿‘æé™
  - ç“¶é¢ˆè½¬ç§»åˆ°ç½‘ç»œå’Œé€šä¿¡
  - éœ€è¦å…¨æ ˆååŒä¼˜åŒ–

- **æŠ€æœ¯è¦æ±‚**
  - éœ€è¦æ‡‚ï¼šç®—æ³• + ç¡¬ä»¶ + ç³»ç»Ÿ + ç½‘ç»œ
  - è·¨é¢†åŸŸåä½œæˆä¸ºå¸¸æ€
  - äººæ‰ç¨€ç¼ºæ€§å¢åŠ 

##### 11.8.6 ä»SPMDåˆ°Event Driven â­

> **æ¥æº**ï¼šå¼ æ˜æ˜Ÿ@æ¸…å (2025"é’ç¨"AIå˜‰å¹´å)
>
> **æ ¸å¿ƒæ´å¯Ÿ**ï¼šä¼ ç»ŸSPMDæ¨¡å¼ä¸é€‚åˆæ‰€æœ‰åœºæ™¯

- **SPMD (Single Program Multiple Data)**
  - ä¼ ç»Ÿçš„æ•°æ®å¹¶è¡Œæ¨¡å¼
  - Workflowäº‹å…ˆprogramå¥½
  - é€‚åˆå¤§è§„æ¨¡æ‰¹é‡å¤„ç†

- **Event Drivenæ¨¡å¼**
  - åŠ¨æ€è°ƒåº¦å’Œæ‰§è¡Œ
  - é€‚åˆbatch sizeè¾¾ä¸åˆ°çš„åœºæ™¯
  - æ›´çµæ´»ä½†ç¼–ç¨‹å¤æ‚åº¦é«˜

- **é€‚ç”¨åœºæ™¯å¯¹æ¯”**
  - **SPMDé€‚åˆ**ï¼š
    - é«˜ååé‡åœºæ™¯
    - è¯·æ±‚æ¨¡å¼ç¨³å®š
    - æ‰¹å¤„ç†ä»»åŠ¡
  - **Event Drivené€‚åˆ**ï¼š
    - ä½å»¶è¿Ÿè¦æ±‚
    - è¯·æ±‚æ¨¡å¼å¤šå˜
    - äº¤äº’å¼åº”ç”¨

##### 11.8.7 ç®—æ³•å’Œç³»ç»Ÿçš„Co-Design â­â­

> **æ¥æº**ï¼šå¼ åšæ¶µ@æµ™å¤§ (2025"é’ç¨"AIå˜‰å¹´å)
>
> **æ ¸å¿ƒæ´å¯Ÿ**ï¼šç®—æ³•å’Œç³»ç»Ÿéœ€è¦åŒæ­¥èºæ—‹å¼ä¸Šå‡

- **ä¼ ç»Ÿæ¨¡å¼çš„é—®é¢˜**
  - ç³»ç»Ÿå›¢é˜Ÿï¼šç­‰ç®—æ³•æˆç†Ÿå†åšä¼˜åŒ–
  - ç®—æ³•å›¢é˜Ÿï¼šç­‰ç³»ç»Ÿä¼˜åŒ–å¥½å†å®éªŒ
  - ç»“æœï¼šä¸¤è¾¹éƒ½åœ¨ç­‰ï¼Œè¿›åº¦ç¼“æ…¢

- **Co-Designæ–¹æ³•**
  - **åŒæ­¥èºæ—‹å¼ä¸Šå‡**ï¼š
    - ç®—æ³•å’Œç³»ç»ŸåŒæ­¥æ¼”è¿›
    - æ¯ä¸ªç‰ˆæœ¬éƒ½äº’ç›¸åé¦ˆ
    - å¿«é€Ÿè¿­ä»£éªŒè¯
  - **æ¡ˆä¾‹**ï¼š
    - INT4 QATï¼šç®—æ³•åˆ›æ–° + ç³»ç»Ÿä¼˜åŒ–
    - PDåˆ†ç¦»ï¼šæ¶æ„åˆ›æ–° + å·¥ç¨‹å®ç°

- **å®è·µå»ºè®®**
  - å»ºç«‹è”åˆå¼€å‘å›¢é˜Ÿ
  - å…±äº«æ€§èƒ½åŸºå‡†
  - å®šæœŸæŠ€æœ¯åŒæ­¥

#### å¸¸è§è¯¯åŒºä¸“æ 
#### å®æˆ˜æ£€æŸ¥æ¸…å•

---

## é™„å½• (Appendices)

### é™„å½•Aï¼šå·¥å…·ä¸èµ„æº

#### A.1 æ¨ç†æ¡†æ¶å¯¹æ¯”
- A.1.1 vLLM
- A.1.2 TGI (Text Generation Inference)
- A.1.3 TensorRT-LLM
- A.1.4 TensorRT-LLM vs vLLM
- A.1.5 é€‰æ‹©å»ºè®®

#### A.2 æ¨¡å‹èµ„æº
- A.2.1 å¼€æºæ¨¡å‹ä»“åº“
- A.2.2 é‡åŒ–æ¨¡å‹ä¸‹è½½
- A.2.3 æ•°æ®é›†èµ„æº
- A.2.4 åŸºå‡†æµ‹è¯•ç»“æœ

#### A.3 å¼€å‘å·¥å…·é›†
- A.3.1 æ€§èƒ½åˆ†æå·¥å…·
- A.3.2 å¯è§†åŒ–å·¥å…·
- A.3.3 è°ƒè¯•å·¥å…·
- A.3.4 éƒ¨ç½²å·¥å…·

#### A.4 å­¦ä¹ èµ„æº
- A.4.1 æ¨èè®ºæ–‡
- A.4.2 åšå®¢å’Œæ–‡ç« 
- A.4.3 è§†é¢‘è¯¾ç¨‹
- A.4.4 ç¤¾åŒºèµ„æº

#### A.5 æœ¯è¯­è¡¨
- A.5.1 LLMæœ¯è¯­
- A.5.2 GPUæœ¯è¯­
- A.5.3 æ¨ç†ä¼˜åŒ–æœ¯è¯­

---

### é™„å½•Bï¼šæ•…éšœæ’æŸ¥æŒ‡å—

#### B.1 å¸¸è§é”™è¯¯åŠè§£å†³
- B.1.1 CUDAç›¸å…³é”™è¯¯
- B.1.2 æ˜¾å­˜ä¸è¶³ (OOM)
- B.1.3 æ€§èƒ½é—®é¢˜
- B.1.4 æ¨¡å‹åŠ è½½å¤±è´¥
- B.1.5 æ¨ç†é€Ÿåº¦æ…¢

#### B.2 è°ƒè¯•æŠ€å·§
- B.2.1 æ—¥å¿—åˆ†æ
- B.2.2 æ€§èƒ½profiling
- B.2.3 é€æ­¥æ’æŸ¥æ³•
- B.2.4 ç¤¾åŒºæ±‚åŠ©æŠ€å·§

#### B.3 æ€§èƒ½é—®é¢˜è¯Šæ–­æ¸…å•
- B.3.1 ç¡¬ä»¶å±‚é¢
- B.3.2 è½¯ä»¶å±‚é¢
- B.3.3 é…ç½®å±‚é¢
- B.3.4 åº”ç”¨å±‚é¢

---

### é™„å½•Cï¼šæ€§èƒ½åŸºå‡†æµ‹è¯•ä¸ROIæ¡ˆä¾‹

#### C.1 æµ‹è¯•ç¯å¢ƒè¯´æ˜
- C.1.1 ç¡¬ä»¶é…ç½®
- C.1.2 è½¯ä»¶ç‰ˆæœ¬
- C.1.3 æµ‹è¯•æ–¹æ³•

#### C.2 æ¨¡å‹æ€§èƒ½å¯¹æ¯”
- C.2.1 ä¸åŒæ¨¡å‹åœ¨åŒä¸€GPUä¸Šçš„è¡¨ç°
- C.2.2 åŒä¸€æ¨¡å‹åœ¨ä¸åŒGPUä¸Šçš„è¡¨ç°
- C.2.3 é‡åŒ–å‰åçš„æ€§èƒ½å¯¹æ¯”

#### C.3 ä¼˜åŒ–æŠ€æœ¯æ•ˆæœå¯¹æ¯”
- C.3.1 KV Cacheçš„å½±å“
- C.3.2 ä¸åŒè°ƒåº¦ç­–ç•¥çš„ååé‡
- C.3.3 é‡åŒ–çš„æ€§èƒ½æå‡
- C.3.4 æŠ•æœºé‡‡æ ·çš„åŠ é€Ÿæ•ˆæœ

#### C.4 çœŸå®åœºæ™¯åŸºå‡†
- C.4.1 Chatåº”ç”¨
- C.4.2 æ‰¹å¤„ç†ä»»åŠ¡
- C.4.3 æ··åˆè´Ÿè½½
- C.4.4 æˆæœ¬åˆ†æ

#### C.5 ROIæ¡ˆä¾‹é›†
- C.5.1 AIå®¢æœä»£ç† - Toastçš„100å€ROI
- C.5.2 AIå†™ä½œåŠ©æ‰‹ - è°ƒåº¦ä¼˜åŒ–é™ä½å»¶è¿Ÿ60%
- C.5.3 ä»£ç ç”Ÿæˆå·¥å…· - é‡åŒ–é™ä½GPUæˆæœ¬75%
- C.5.4 å¤šæ¨¡æ€æœç´¢ - MoEæ¶æ„é™ä½æ¨ç†æˆæœ¬40%
- C.5.5 SaaSå¹³å° - æˆæœ¬ç›‘æ§æ¯æœˆèŠ‚çœ$15,000
- C.5.6 DeepSeek - RTX 4090è¿è¡ŒGPT-o1çº§åˆ«æ¨¡å‹

---

## å®Œæ•´ç»Ÿè®¡

### å†…å®¹è§„æ¨¡
- **æ€»ç« èŠ‚æ•°**ï¼š10ç«  + 3ä¸ªé™„å½•ï¼ˆæ–°å¢ç¬¬2ç« ï¼‰
- **æ€»èŠ‚æ•°**ï¼šçº¦160èŠ‚
- **æ€»å°èŠ‚æ•°**ï¼šçº¦420å°èŠ‚
- **é¢„è®¡æ€»å­—æ•°**ï¼š35,000-45,000å­—ï¼ˆæ‰©å¤§ï¼‰

### ç‰¹è‰²å†…å®¹
- **å¸¸è§è¯¯åŒºä¸“æ **ï¼šæ¯ç« 1ä¸ªï¼Œå…±10ä¸ª
- **å®æˆ˜æ£€æŸ¥æ¸…å•**ï¼šæ¯ç« 1ä¸ªï¼Œå…±10ä¸ª
- **åŠ¨æ‰‹ç»ƒä¹ **ï¼šæ¯ç« 2ä¸ªï¼Œå…±20ä¸ª
- **æˆæœ¬å½±å“è¯´æ˜**ï¼šç¬¬3-10ç« æ¯ç« 1ä¸ª
- **ROIæ¡ˆä¾‹**ï¼šè´¯ç©¿å…¨ä¹¦çš„çœŸå®å•†ä¸šæ¡ˆä¾‹
- **æ–‡æ˜è§†è§’**ï¼šç¬¬1ç« å¼•å…¥"äººç±»å½“é‡"ç†è®º
- **å†å²ç±»æ¯”**ï¼šé©¬å°”è¨æ–¯é™·é˜±ç­‰å†å²è§†è§’

### é…å¥—èµ„æº
- **ä»£ç ç¤ºä¾‹**ï¼šæ¯ç« å¯¹åº”ä»£ç ç›®å½•
- **Dockeré…ç½®**ï¼šä¸€é”®è¿è¡Œ
- **è§†é¢‘æ•™ç¨‹**ï¼š20ä¸ªåŸºç¡€è§†é¢‘ + 10ä¸ªé«˜çº§è§†é¢‘
- **ç¤¾åŒºæ”¯æŒ**ï¼šDiscordåˆ†ç« è®¨è®º

---

## V2+V3èåˆç‰ˆä¸»è¦å˜åŒ–

### ç»“æ„å˜åŒ–
- âœ… æ–°å¢ç¬¬2ç« ï¼š"æŠ€æœ¯å…¨æ™¯ä¸å­¦ä¹ è·¯å¾„"
- âœ… å°†åŸç¬¬1ç« æ‹†åˆ†ä¸º2ç« ï¼Œæ›´åŠ åˆç†
- âœ… ç¬¬1ç« èšç„¦"ä¸ºä»€ä¹ˆé‡è¦"ï¼Œç¬¬2ç« èšç„¦"å¦‚ä½•å­¦ä¹ "
- âœ… æ€»ç« èŠ‚æ•°ä»9ç« å¢åŠ åˆ°10ç« 

### ç¬¬1ç« ï¼šèåˆæ–‡æ˜è§†è§’ä¸å•†ä¸šæ¡ˆä¾‹
- âœ… å¼•å…¥"äººç±»å½“é‡"æ¦‚å¿µï¼ˆ50,000å€éœ‡æ’¼ï¼‰
- âœ… ä¿ç•™Toastæ¡ˆä¾‹ï¼ˆ100å€ROIï¼‰
- âœ… ä¸‰é‡è¯æ®ï¼šå†å²+å¸‚åœº+éœ€æ±‚
- âœ… ç®€æ´æœ‰åŠ›ï¼š4ä¸ªå°èŠ‚ï¼Œæ¯èŠ‚3ä¸ªè¦ç‚¹

### ç¬¬2ç« ï¼šæŠ€æœ¯å…¨æ™¯ä¸è·¯å¾„
- âœ… äº”å¤§ä¼˜åŒ–æ–¹å‘é€Ÿè§ˆ
- âœ… è¯»è€…å®šä½ä¸å­¦ä¹ è·¯å¾„
- âœ… é…å¥—èµ„æºè¯´æ˜
- âœ… 3ä¸ªå°èŠ‚ï¼Œå¿«é€Ÿè¿‡æ¸¡åˆ°æŠ€æœ¯å†…å®¹

### å…¶ä»–ç« èŠ‚å¢å¼º
- âœ… æ¯ç« å¼€å¤´å¢åŠ "ğŸ’° æˆæœ¬å½±å“"è¯´æ˜
- âœ… æŠ€æœ¯ç« èŠ‚å¢åŠ ROIæ¡ˆä¾‹
- âœ… ç¬¬9ç« æ–°å¢"ROIç›‘æ§ä¸æˆæœ¬è¿½è¸ª"
- âœ… é™„å½•Cæ–°å¢6ä¸ªå®Œæ•´æ¡ˆä¾‹ï¼ˆå«DeepSeekï¼‰

### æ•°æ®æ¥æº
- å¼ ç¬‘å®‡ã€ŠAIæ–‡æ˜å²Â·å‰å²ã€‹ï¼ˆäººç±»å½“é‡ç†è®ºï¼‰
- ARK Invest Big Ideas 2026ï¼ˆå¸‚åœºæ•°æ®ï¼‰
- Boaz Barak - Windows on Theoryï¼ˆç»æµå­¦è§†è§’ï¼‰
- METRç ”ç©¶ï¼ˆAIèƒ½åŠ›æŒ‡æ•°çº§å¢é•¿ï¼‰
- è¡Œä¸šåŸºå‡†æµ‹è¯•æ•°æ®
- çœŸå®ä¼ä¸šæ¡ˆä¾‹

---

**æœ¬ä¹¦ç‰¹è‰²ï¼ˆV2+V3èåˆç‰ˆï¼‰**ï¼š
- ğŸ“Š æ•°æ®é©±åŠ¨ï¼šç”¨éœ‡æ’¼æ•°å­—å»ºç«‹åŠ¨æœº
- ğŸ’¼ å•†ä¸šå¯¼å‘ï¼šToastæ¡ˆä¾‹è¯æ˜ROI
- ğŸ›ï¸ æ–‡æ˜è§†è§’ï¼šäººç±»å½“é‡ + å†å²ç±»æ¯”
- ğŸ”§ å®æˆ˜å¯¼å‘ï¼šæ¯ä¸ªæŠ€æœ¯éƒ½æœ‰ä»£ç å’Œæ¡ˆä¾‹
- ğŸ“ˆ æˆæœ¬æ„è¯†ï¼šæ¯ç« éƒ½è¿æ¥ä¼˜åŒ–ä¸ä»·å€¼
- ğŸ¯ ç»“æ„æ¸…æ™°ï¼šåŠ¨æœº â†’ è·¯å¾„ â†’ åŸºç¡€ â†’ æŠ€æœ¯ â†’ éƒ¨ç½²
